{
  "Aesthetic Gradients": "美學梯度",
  "Allows training an embedding from one or few pictures, specifically meant for applying styles. Also, allows use of these specific embeddings to generated images.": "允許從一張或多張圖像中訓練一個嵌入（embedding），專門用於套用風格。同時，也允許使用這些特定的嵌入來產生圖像。",
  "Dreambooth": "Dreambooth",
  "Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.": "基於 Shivam Shiaro 的代碼移植的 Dreambooth 訓練，為低顯示卡記憶體（VRAM）顯示卡做了優化",
  "training-picker": "training-picker",
  "Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.": "向 webui 加入一個頁籤，允許用戶自動從影片中提取關鍵幀，並手動裁剪 512x512 大小以用於模型訓練",
  "Dataset Tag Editor": "數據集標記編輯器",
  "Feature-rich UI tab that allows image viewing, search-filtering and editing.": "功能豐富的用戶介面標籤，允許查看圖像、搜尋過濾和編輯。",
  "DreamArtist": "夢想家（DreamArtist）",
  "Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.": "通過對比調整提示詞，實現可控的一次性文字文件到圖像生成",
  "WD 1.4 Tagger": "WD 1.4 標記器",
  "Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.": "使用各種替代模型檢查單一或多個圖像檔，類似於 deepdanbooru 的檢查。",
  "Hypernetwork-Monkeypatch-Extension": "Hypernetwork-Monkeypatch-擴充套件",
  "Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.": "提供超網絡訓練的額外訓練功能的擴充套件。也支援同時使用多個超網絡進行推論。",
  "Custom Diffusion": "自訂擴散",
  "Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.": "簡而言之，自訂擴散是用 TI 的微調代替整個模型的微調。速度和記憶體需求類似 TI，並且在較少步驟內獲得更好的結果。",
  "Smart Process": "智慧預處理",
  "Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.": "智慧預處理，包括自動識別主體、切換描述文字主體和放大／面部恢復",
  "Embeddings editor": "多個嵌入編輯器",
  "Allows you to manually edit textual inversion embeddings using sliders.": "讓你可以手動用滑桿編輯風格遷移多個嵌入的參數",
  "embedding-inspector": "嵌入檢查器",
  "Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.": "檢查任何標記（一個單詞）或文本反轉嵌入並找出相似的嵌入。您可以在幾秒鐘內混合，修改或創建嵌入。",
  "Merge Board": "合併面板",
  "Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.": "支援多條道路合併(多達10條)，可以將合併組合儲存為「食譜」，食譜是一個簡單的文字檔案。",
  "Model Converter": "模型轉換器",
  "Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.": "將模型轉換為 fp16/bf16 no-ema/ema-only safetensors。轉換/複製/刪除模型的任何部分：unet，文字編碼器（剪貼），vae。",
  "Kohya-ss Additional Networks": "Kohya-ss 附加網路",
  "Allows the Web UI to use LoRAs (1.X and 2.X) to generate images. Also allows editing .safetensors networks prompt metadata.": "允許使用者介面使用 LoRAs（1.X 和 2.X）產生圖像。同時，還允許編輯 .safetensors 網路提示詞中繼資料。",
  "Merge Block Weighted": "合併塊加權",
  "Merge models with separate rate for each 25 U-Net block (input, middle, output).": "合併模型，每 25 個 U-Net 塊（輸入、中間、輸出）有獨立的比率。",
  "Embedding Merge": "嵌入合併",
  "Merging Textual Inversion embeddings at runtime from string literals. Phrases and weight values also supported.": "在運行時從字符串文字中合併文本反轉嵌入。也支援短語和權重值。",
  "SuperMerger": "超級融合器",
  "Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more.": "無需儲存到硬碟合併並執行。按順序進行 XY 合併；提取並合併 LoRAs，將 LoRAs 綁定到模型權重存檔點，合併區塊權重以及更多。",
  "LoRA Block Weight": "LoRA 區塊權重",
  "Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.": "在執行時逐塊的套用 LoRA 強度。包括預設值、權重分析、隨機化以及 XY 圖。",
  "Image browser": "圖庫瀏覽器",
  "Provides an interface to browse created images in the web browser.": "在網頁瀏覽器裡提供一個瀏覽已產生的圖像使用者介面",
  "Infinite image browsing": "Infinite image browsing",
  "A fast image browser that allows you to browse all images without paging, with a layout similar to VS Code, and optional transfer with Baidu netdisk.": "A fast image browser that allows you to browse all images without paging, with a layout similar to VS Code, and optional transfer with Baidu netdisk.",
  "Inspiration": "靈感",
  "Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.": "隨機顯示一位藝術家或某藝術流派的圖像，選擇後會顯示更多該藝術家或藝術流派的圖像。所以你不用擔心在創作時難以選擇出想要的藝術風格",
  "Artists to study": "藝術家圖庫",
  "Shows a gallery of generated pictures by artists separated into categories.": "將藝術家按類別劃分，並顯示其產生出來的圖像",
  "Prompt Gallery": "提示詞畫廊",
  "Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.": "建立一個使用您的角色提示的 yaml 檔，點擊產生，並快速通過其字屬性和修飾符預覽它們。",
  "Infinity Grid Generator": "無限網格產生器",
  "Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.": "建立一個使用選定的參數的 yaml 檔，並產生無限維的網格。內建能力將描述文字添加到字段中。有關用法細節，請參閱 readme。",
  "Config-Presets": "配置預設值",
  "Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.": "在文生圖和圖生圖頁面中添加可設定下拉菜單，以允許您更改 UI 預設設定。",
  "Preset Utilities": "預設工具",
  "Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit)": "預設工具，用於 ui。提供與自定義腳本的兼容性。（有限制）",
  "openOutpaint extension": "openOutpaint 擴展",
  "A tab with the full openOutpaint UI. Run with the --api flag.": "具有完整 openOutpaint UI 的選項卡。使用 --api 標誌運行。",
  "quick-css": "快速 CSS",
  "Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.": "用於快速選擇和應用 custom.css 文件的擴展，以自定義 ui 中元素的外觀和位置。",
  "Aspect Ratio selector": "長寬比選擇器",
  "Adds image aspect ratio selector buttons.": "添加圖像長寬比選擇按鈕。",
  "Catppuccin Theme": "Catppuccin 主題",
  "Adds various custom themes": "添加多種自定義主題。",
  "Kitchen Theme": "Kitchen 主題",
  "Custom Theme.": "自定義主題。",
  "Bilingual Localization": "雙語翻譯對照",
  "Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.": "雙語翻譯，無需擔心如何尋找原文按鈕。與語言包擴充功能相容，無需重新導入。",
  "Dynamic Prompts": "動態提示詞",
  "Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.": "為隨機或組合式提示詞的生成實現了一種表達性模板語言，並支持深層目錄結構中的萬用字元",
  "Unprompted": "非文本（代碼化）提示詞",
  "Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.": "允許您在提示詞中包含各種短碼。您可以從文件中提取文本，設定自己的變數，通過條件函數處理文字等 ，就像是在類固醇中的萬用字元。它現在包括了一些整合，如硬提示詞（hard-prompts）、ControlNet、文生圖生圖和文生遮罩。",
  "StylePile": "樣式積累",
  "An easy way to mix and match elements to prompts that affect the style of the result.": "方便地組合不同元素，並影響結果的樣式。",
  "Booru tag autocompletion": "Booru 標記自動補齊",
  "Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.": "顯示來自圖像板塊（如 Danbooru）的標記自動補齊。使用本地標記CSV 檔案，並包含可用於自定義配置的檔案",
  "novelai-2-local-prompt": "novelai-2-local-prompt",
  "Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.": "加入一個按鈕以將 NovelAI 中使用的提示詞轉換為在 WebUI 中使用。此外，加入一個按鈕，讓你可以調用以前使用過的提示詞",
  "tokenizer": "標記解析器",
  "Adds a tab that lets you preview how CLIP model would tokenize your text.": "新增一個頁籤讓你能夠預覽 CLIP 模型如何對你的文本進行標記拆分",
  "Randomize": "隨機化",
  "Allows for random parameters during txt2img generation. This script will function with others as well. Original author: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize": "允許在文生圖產生過程中使用隨機參數。此指令碼也可以與其他指令碼一起執行。原作者：https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize",
  "conditioning-highres-fix": "高解析度修復原圖調節",
  "This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt": "這是在運行時重新實現的局部重繪圖像調節遮罩強度（相對於重繪強度）的擴充功能。這對於局部重繪專用的模型（例如 sd-v1-5-inpainting.ckpt）很有用",
  "model-keyword": "模型關鍵字",
  "Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.": "自動將匹配關鍵字插入提示。更新此擴展以獲取最新的「模型+關鍵字」映射。",
  "Prompt Generator": "提示產生器",
  "generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.": "使用 distilgpt2 從小基礎提示產生提示。添加一個具有模型額外控制的選項卡。",
  "Promptgen": "提示詞生成器",
  "Use transformers models to generate prompts.": "使用 transformers 模型產生提示詞。",
  "text2prompt": "文生提示詞",
  "Generates anime tags using databases and models for tokenizing.": "使用資料庫和分詞模型產生動漫標籤。",
  "Prompt Translator": "提示詞翻譯器",
  "A integrated translator for translating prompts to English using Deepl or Baidu.": "一個使用 Deepl 或 Baidu 翻譯提示至英文的統整翻譯器。",
  "Deforum": "Deforum",
  "The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.": "Deforum 的官方移植，一個用於 2D 和 3D 動畫的擴展指令碼，支持關鍵幀序列、動態數學參數（甚至可用於提示詞內）、動態遮罩、深度預測和變形",
  "Animator": "動畫製作器",
  "A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.": "一個簡單的圖生圖腳本，將輸出幀並建立視訊檔案。適合製作有趣的縮放曲折電影。這是一個多用途的工具組，可幫助您自動化一些圖生圖任務。",
  "gif2gif": "GIF生GIF",
  "A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif": "圖生圖的腳本，逐幀提取圖生圖以生成 gif，並將它們重新組合成動畫gif",
  "Video Loopback": "Video Loopback",
  "A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.": "一個嘗試改善普通 vid2vid 的時間一致性和靈活性的 video2video 指令碼。",
  "seed travel": "種子變遷",
  "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.": "一個用於生成不同隨機種子之間的漸變過程的小指令碼",
  "shift-attention": "shift-attention",
  "Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.": "根據提示詞產生一系列關注逐漸轉移的圖像。此指令碼使你能夠在提示詞中為標記的權重指定一個範圍，然後產生從一端到另一端的一系列圖像",
  "prompt travel": "提示詞變遷",
  "Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.": "一個在潛在變數中對不同提示詞之間進行插值漸變，並生成其漸變過程的擴充功能指令碼",
  "Steps Animation": "步驟動畫",
  "Create animation sequence from denoised intermediate steps.": "從降噪過程中的中間步驟建立動畫序列。",
  "auto-sd-paint-ext": "畫圖工具擴充",
  "Krita Plugin.": "Krita 套件",
  "Detection Detailer": "檢測細緻化",
  "An object detection and auto-mask extension for Stable Diffusion web UI.": "一個物件檢測與自適應遮罩擴充功能",
  "Batch Face Swap": "批次臉部交換",
  "Automatically detects faces and replaces them.": "自動偵測臉部並進行替換。",
  "Depth Maps": "深度圖",
  "Depth Maps, Stereo Image, 3D Mesh and Video generator extension.": "深度圖、立體圖像、3D網格和影片生成器擴展。",
  "multi-subject-render": "多主題繪製",
  "It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.": "它是一個深度感知延伸，可以幫助在單張圖像上創建多個復雜主題。它先產生背景，再產生多個前景主題，根據深度分析切割它們的背景，將它們粘貼到背景上，最後進行圖生圖，得到一個乾淨的結果。",
  "depthmap2mask": "深度圖生遮罩",
  "Create masks for img2img based on a depth estimation made by MiDaS.": "根據 MiDaS 的深度估計為圖生圖創建遮罩。",
  "ABG_extension": "ABG_擴展",
  "Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.": "自動刪除背景。使用為動漫圖像微調的 onnx 模型。在 GPU 上運行。",
  "Pixelization": "像素化",
  "Using pre-trained models, produce pixel art out of images in the extras tab.": "使用預先訓練的模型，在附加標籤中將圖像轉換為像素藝術。",
  "haku-img": "HAKU 圖像工具",
  "Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.": "圖像工具擴充套件。允許混合、分層、色調和顏色調整、模糊和素描效果，以及基本的像素化。",
  "Asymmetric Tiling": "非對稱平舖",
  "An always visible script extension to configure seamless image tiling independently for the X and Y axes.": "一個始終可見的腳本擴充套件，用於分別配置 X 和 Y 軸上的無縫圖像鋪貼。",
  "Latent Mirroring": "鏡像潛在變數",
  "Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections": "將圖像的潛在變數狀態進行鏡像和翻轉，以產生從輕度平衡的構圖到完全對稱的任何圖像",
  "Sonar": "聲納",
  "Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.": "提高產生的圖像品質，在某個已知圖像的附近搜索類似（甚至更好！）的圖像，專注於單個提示的優化，而不是在多個提示之間旅行。",
  "Depth Image I/O": "深度影像輸入/輸出",
  "An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.": "一個擴充套件，允許管理自訂深度輸入到 Stable Diffusion depth2img 模型。",
  "Ultimate SD Upscale": "終極 SD 放大",
  "More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).": "比 SD 放大的更為進階的選項，使用更高的降噪比率 (0.3-0.5)，比原始的更少的人工假象。",
  "Prompt Fusion": "Prompt Fusion",
  "Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.": "加入提示旅行和類似位移注意力的插值（請參閱 exts），但在採樣步驟中進行。始終啟用 + 可與現有提示編輯語法一起使用。各種插值模式。有關更多信息，請參閱其 wiki。",
  "Dynamic Thresholding": "動態閾值",
  "Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.": "加入可自訂的動態閾值，以允許高 CFG Scale 值，而不會有燒焦或「流行藝術」效果。",
  "anti-burn": "反燒機",
  "Smoothing generated images by skipping a few very last steps and averaging together some images before them.": "跳過最後幾步並將之前的一些圖像平均在一起，以平滑生成的圖像。",
  "sd-webui-controlnet": "sd-webui-controlnet",
  "WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.": "ControlNet 的 WebUI 擴充功能。注意：由於仍在開發中，因此不保證種子的再現性，因為更新可能會更改內容。",
  "Latent Couple": "潛在變數伴侶",
  "An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts. Note: New maintainer, uninstall prev. ext if needed.": "內置 Composable Diffusion 擴充功能，能使您將子提示詞反映在特定的潛在變數空間區域。注意：如有必要，請解除安裝先前的擴充功能。",
  "Composable LoRA": "Composable LoRA",
  "Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.": "允許使用 AND 關鍵字（composable diffusion）來限制 LoRA 到子提示詞。當與潛在變數伴侶擴充功能搭配使用時非常有用。",
  "Auto TLS-HTTPS": "自動使用安全性傳輸協定（https）",
  "Allows you to easily, or even completely automatically start using HTTPS.": "讓你可以很簡單的自動配置安全性傳輸協定（https）",
  "booru2prompt": "booru轉提示詞",
  "This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.": "這個 SD 延伸可以將各種圖像 boorus 的文章轉換為穩定擴散提示。它通過從API下載標籤列表來完成此操作。您可以自行複製粘貼您想要的文章的網址，或使用內置的搜索功能在不離開 SD 的情況下完成所有操作。",
  "Gelbooru Prompt": "Gelbooru 提示",
  "Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui": "擴充功能，可獲取在 AUTOMATIC1111 的 Stable Diffusion webui 中儲存的 Gelbooru 圖像的標籤",
  "NSFW checker": "NSFW 檢查器",
  "Replaces NSFW images with black.": "用黑色替換 NSFW 圖像。",
  "Diffusion Defender": "擴散防御者",
  "Prompt blacklist, find and replace, for semi-private and public instances.": "提示黑名單，查找並替換半私人和公共實例。",
  "DH Patch": "DH 更新檔",
  "Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.": "D8ahazard 的隨機修補程式。自動加載 v2、2.1 模型的 YAML 配置文件；修補 2.1 模型的潛在變數擴散以修復注意力（沒有 no-half 的黑盒子），以及其他任何我想到的。",
  "Riffusion": "Riffusion",
  "Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.": "使用 Riffusion 模型在 gradio 中產生音樂。要重現原始插值技巧，請將提示旅行擴展輸出幀輸入到 Riffusion 頁面中。",
  "Save Intermediate Images": "儲存中間圖像",
  "Save intermediate images during the sampling process. You can also make videos from the intermediate images.": "在採樣過程中儲存中間圖像。您也可以從中間圖像製作影片。",
  "Add image number to grid": "將圖像編號添加到網格中",
  "Add the image's number to its picture in the grid.": "將圖像的編號添加到網格中的圖片中。",
  "Multiple Hypernetworks": "多個超網絡",
  "Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.": "增加同時應用多個超網絡的能力。連續應用多個超網絡，具有不同的權重。",
  "System Info": "系統資訊",
  "System Info tab for WebUI which shows realtime information of the server. Also supports sending crowdsourced inference data as an option.": "System Info tab for WebUI which shows realtime information of the server. Also supports sending crowdsourced inference data as an option.",
  "OpenPose Editor": "OpenPose編輯器",
  "This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.": "可添加多個姿勢角色，從圖像中檢測姿勢，儲存為 PNG 並發送到 ControlNet 擴充功能。",
  "Stable Horde Worker": "Stable Horde 工作端",
  "Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.": "Stable Horde 工作端。使用您的 PC 為其他使用者產生圖片。請閱讀說明以獲取其他指示。",
  "Stable Horde Client": "Stable Horde 客戶端",
  "Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.": "Stable Horde 客戶端。使用其他用戶的 PC 產生圖片。如果自己沒有 GPU 的話，這很有用。",
  "Discord Rich Presence": "Discord 豐富存在",
  "Provides connection to Discord RPC, showing a fancy table in the user profile.": "提供與 Discord RPC 的連接，在用戶資料頁面顯示漂亮的表格。",
  "mine-diffusion": "mine-diffusion",
  "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.": "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.",
  "Aesthetic Image Scorer": "美學圖像評分器",
  "Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer": "為產生出來的圖像計算其美學分數。基於 Chad Scorer 使用 CLIP+MLP 美學分數預測器",
  "Aesthetic Scorer": "美學評分器",
  "Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.": "使用現有的 CLiP 模型和額外的小型預訓練模型來計算圖像的感知美學分數。",
  "cafe-aesthetic": "咖啡審美器",
  "Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.": "預先訓練的模型，用於判斷美學/非美學，進行五種不同樣式的識別模式，以及 Waifu 確認。此外還有批次處理的標籤。",
  "Clip Interrogator": "Clip Interrogator",
  "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.": "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.",
  "Visualize Cross-Attention": "可視化跨注意力",
  "Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.": "根據輸入提示詞產生輸入圖像的突出顯示區域。需與 Tokenizer 擴充功能一起使用。詳細資訊請參閱自述文件。",
  "DAAM": "擴散注意力歸因圖（DAAM）",
  "DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image.": "DAAM 代表擴散注意力歸因圖（Diffusion Attentive Attribution Maps）。輸入注意力文（必須是提示詞中包含的字串）並運行。將生成一張與原始圖像重疊的圖像，每個注意力將附帶一個熱度圖。",
  "Dump U-Net": "Dump U-Net",
  "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547": "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547",
  "posex": "posex",
  "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.": "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.",
  "LLuL": "潛空間區域放大",
  "Local Latent Upscaler. Target an area to selectively enhance details.": "潛在變數區域放大。指定一個範圍以選擇性增強細節。",
  "CFG-Schedule-for-Automatic1111-SD": "CFG-Schedule-for-Automatic1111-SD",
  "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.": "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.",
  "ebsynth_utility": "ebsynth_utility",
  "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.": "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.",
  "VRAM Estimator": "VRAM 估量器",
  "Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.": "執行遞增的圖像尺寸與批次數量文生圖、圖生圖以及高解析修復直到將記憶體耗盡，並輸出資料圖表。",
  "MultiDiffusion with Tiled VAE": "多重擴散與分塊 VAE",
  "Seamless Image Fusion, along with vram efficient tiled vae script.": "無縫圖像融合以及提升 VRAM 效率的分塊 VAE 指令碼。",
  "3D Model&Pose Loader": "3D 模型與姿勢載入器",
  "Load your 3D model/animation inside webui, or edit model pose as well, then send screenshot to txt2img or img2img to ControlNet.": "載入你的 3D 模型 / 動畫到網頁使用者介面，或編輯模型姿勢，然後傳送截圖至文生圖或圖生圖的 ControlNet。",
  "Corridor Crawler Outpainting": "Corridor Crawler Outpainting",
  "Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.": "使用解析度為 512 的深度圖像模型產生畫廊。它可以調整以適應其他模型 / 解析度。",
  "Panorama Viewer": "全景圖像查看器",
  "Provides a tab to display equirectangular images in interactive 3d-view.": "提供一個分頁以顯示互動式 3D 視圖中的等矩形圖像。",
  "db-storage1111": "資料庫儲存",
  "Allows to store pictures and their metadata in a database. (supports MongoDB)": "允許將圖像及其中繼資料存儲在資料庫中（支援MongoDB）。",
  "stable-diffusion-webui-rembg": "stable-diffusion-webui-rembg",
  "Removes backgrounds from pictures.": "從圖片移除背景。",
  "sd-webui-tunnels": "sd-webui-tunnels",
  "Add alternatives to the default tunneling methods. (including cloudflared)": "加入使用預設 tunneling 方法以外的替代方法（包括 cloudflared）",
  "3D Openpose Editor": "3D Openpose Editor",
  "Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.": "在網頁使用者介面上編輯 3D 模型的姿勢，並為 ControlNet 產生 Openpose/Depth/Normal/Canny 圖。",
  "sd-webui-enable-checker": "sd-webui-enable-checker",
  "Switch background color by clicking the Enable buttons in SD Web UI": "透過在網頁使用者介面中點擊啟用按鈕來切換背景顏色。",
  "stable-diffusion-webui-state": "stable-diffusion-webui-state",
  "Preserves the UI state after reload/restart.": "Preserves the UI state after reload/restart.",
  "text2video": "text2video",
  "Implementation of text2video diffusion models, such as ModelScope or VideoCrafter, using only Auto1111 webui dependencies.": "Implementation of text2video diffusion models, such as ModelScope or VideoCrafter, using only Auto1111 webui dependencies.",
  "Aspect Ratio Helper": "長寬比小幫手",
  "Easily scale dimensions while retaining the same aspect ratio.": "Easily scale dimensions while retaining the same aspect ratio.",
  "Canvas Zoom": "Canvas Zoom",
  "Added the ability to scale Inpaint, Sketch, and Inpaint Sketch. Adds useful hotkeys": "Added the ability to scale Inpaint, Sketch, and Inpaint Sketch. Adds useful hotkeys",
  "Regional Prompter": "Regional Prompter",
  "Specify different prompts for different regions; an alternative method and potential improvement to latent couple.": "Specify different prompts for different regions; an alternative method and potential improvement to latent couple.",
  "Auto Translate": "自動翻譯",
  "Language extension allows users to write prompts in their native language and automatically translate UI, without the need to manually download configuration files. New plugins can also be translated.": "Language extension allows users to write prompts in their native language and automatically translate UI, without the need to manually download configuration files. New plugins can also be translated.",
  "Allows users to generate images based on prompts written in 50 different languages. It translates the prompts to english from a selected source language before generating the image.": "允許使用者根據用50種不同語言寫成的提示詞來產生圖像。在產生圖像之前，它會將來自所選源語言的提示翻譯成英語。",
  "Abysz LAB": "Abysz LAB",
  "Temporal Coherence Tools": "Temporal Coherence Tools",
  "Negative Prompt Weight": "反向提示詞權重",
  "Allows users to set a global weight for the negative prompt.": "允許使用者設定反向提示詞的全域權重",
  "Discord - Dynamic Rich Presence": "Discord 動態狀態訊息",
  "Will show your current sd model selected. Also showing if you are idle, or generating something - in that case, total image/s being generated.": "在 Discord 動態狀態顯示目前選用的模型名稱。另外也會顯示閒置中或正在產生圖像等訊息。",
  "PBRemTools": "PBRemTools",
  "PBRemTools(Precise background remover tools) is a collection of tools to crop backgrounds from a single picture with high accuracy.": "PBRemTools(Precise background remover tools) is a collection of tools to crop backgrounds from a single picture with high accuracy.",
  "a1111-sd-webui-lycoris": "a1111-sd-webui-lycoris",
  "Load lycoris: non-conventional rank adapters; in separate networks gallery tab.": "Load lycoris: non-conventional rank adapters; in separate networks gallery tab.",
  "sd-canvas-editor": "sd-canvas-editor",
  "A full capability canvas editor which you can use layer, text, image, elements and so on.": "A full capability canvas editor which you can use layer, text, image, elements and so on.",
  "Infinite Zoom": "無限縮放",
  "allows users to create infinite zoom effect videos using stable diffusion outpainting method.": "使用 stable diffusion 向外繪製建立無限縮放效果影片。",
  "zh_CN Localization": "簡體中文本地化語言包",
  "Simplified Chinese localization, recommend using with Bilingual Localization.": "簡體中文本地化，推薦搭配雙語翻譯對照擴充功能使用。",
  "zh_TW Localization": "正體中文在地化語言包",
  "Traditional Chinese localization": "正體中文本地化",
  "ko_KR Localization": "韓文在地化語言包",
  "Korean localization": "韓語本地化",
  "th_TH Localization": "泰語本地化語言包",
  "Thai localization": "泰語本地化",
  "es_ES Localization": "西班牙語本地化語言包",
  "Spanish localization": "西班牙語本地化",
  "it_IT Localization": "義大利語本地化語言包",
  "Italian localization": "義大利語本地化",
  "de_DE Localization": "德語本地化語言包",
  "German localization": "德語本地化",
  "ja_JP Localization": "日文本地化語言包",
  "Japanese localization": "日語本地化",
  "pt_BR Localization": "巴西葡萄牙語本地化語言包",
  "Brazillian portuguese localization": "巴西葡萄牙語本地化",
  "tr_TR Localization": "土耳其語本地化語言包",
  "Turkish localization": "土耳其語本地化",
  "no_NO Localization": "挪威語本地化語言包",
  "Norwegian localization": "挪威語本地化",
  "ru_RU Localization": "俄語本地化語言包",
  "Russian localization": "俄語本地化",
  "fi_FI Localization": "芬蘭語本地化語言包",
  "Finnish localization": "芬蘭語本地化",
  "zh_Hans Localization": "簡體中文本地化語言包",
  "Simplified Chinese localization.": "簡體中文本地化。",
  "old localizations": "過時的本地化語言包",
  "Old unmaintained localizations that used to be a part of main repository": "曾經在主分支上但現在不再維護的舊語言包",
  "Loading...": "載入中…",
  "Use via API": "使用API",
  "Built with Gradio": "使用 Gradio 構建",
  "Stable Diffusion checkpoint": "Stable Diffusion 模型權重存檔點",
  "txt2img": "文生圖",
  "img2img": "圖生圖",
  "Extras": "附加功能",
  "PNG Info": "圖片資訊",
  "Checkpoint Merger": "模型權重存檔點合併",
  "Train": "訓練",
  "Settings": "設定",
  "Extensions": "擴充功能",
  "Prompt": "提示詞",
  "Negative prompt": "反向提示詞",
  "Interrupt": "中止",
  "Skip": "跳過",
  "Generate": "產生",
  "Generate forever": "無限產生",
  "Cancel generate forever": "取消無限產生",
  "Run": "執行",
  "Styles": "樣式",
  "Label": "標記",
  "File": "檔案",
  "Drop File Here": "拖曳檔案到此",
  "- or -": "- 或 -",
  "Click to Upload": "點選以上傳",
  "Textual Inversion": "文本反轉（Textual Inversion）",
  "Hypernetworks": "超網路（Hypernetwork）",
  "Checkpoints": "模型權重存檔點",
  "Lora": "LoRA",
  "Refresh": "重新整理",
  "Nothing here. Add some content to the following directories:": "這裡什麼都沒有。加入一些內容至以下目錄：",
  "replace preview": "取代預覽",
  "Textbox": "文字方塊",
  "Save preview": "儲存預覽",
  "Sampling method": "取樣方法",
  "Euler a": "Euler a",
  "Sampling steps": "取樣步驟",
  "Restore faces": "面部修復",
  "Tiling": "可平鋪",
  "Hires. fix": "高解析度修正（Hires. fix）",
  "Upscaler": "放大演算法",
  "Latent": "潛在變數",
  "Latent (antialiased)": "潛在變數（抗鋸齒）",
  "Latent (bicubic)": "潛在變數（雙立方）",
  "Latent (bicubic antialiased)": "潛在變數（雙立方抗鋸齒）",
  "Latent (nearest)": "潛在變數（最接近）",
  "Latent (nearest-exact)": "潛在變數（最接近精確）",
  "None": "無",
  "Hires steps": "高解析步驟",
  "Denoising strength": "重繪幅度",
  "Upscale by": "放大至",
  "Resize width to": "將寬度調整至",
  "Resize height to": "將高度調整至",
  "Width": "寬度",
  "Height": "高度",
  "Batch count": "產生批次",
  "Batch size": "每批數量",
  "CFG Scale": "提示詞相關性（CFG）",
  "Seed": "隨機種子",
  "Extra": "▼",
  "Variation seed": "差異隨機種子",
  "Variation strength": "差異強度",
  "Resize seed from width": "寬度（縮放種子）",
  "Resize seed from height": "高度（縮放種子）",
  "Override settings": "覆寫設定",
  "Script": "指令碼",
  "Prompt matrix": "提示詞矩陣",
  "Prompts from file or textbox": "從文字方塊或檔案載入提示詞",
  "X/Y/Z plot": "X/Y/Z 圖表",
  "Put variable parts at start of prompt": "把可變部分放在提示詞的開頭",
  "Use different seed for each picture": "對每張圖片使用不同的種子",
  "Select prompt": "選擇提示詞",
  "positive": "正向",
  "negative": "反向",
  "Select joining char": "選擇接合字母",
  "comma": "逗號",
  "space": "空間",
  "Grid margins (px)": "網格邊距（px）",
  "Iterate seed every line": "每行輸入都換一個隨機種子",
  "Use same random seed for all lines": "每行輸入都使用同一個隨機種子",
  "List of prompt inputs": "提示詞輸入列表",
  "Upload prompt inputs": "上傳提示詞輸入檔案",
  "Nothing": "無",
  "Var. seed": "差異隨機種子",
  "Var. strength": "差異強度",
  "Steps": "疊代步數",
  "Prompt S/R": "提示詞搜索 / 替換",
  "Prompt order": "提示詞順序",
  "Sampler": "取樣器",
  "Checkpoint name": "模型權重存檔點的名稱",
  "Sigma Churn": "希格瑪流失量（Sigma Churn）",
  "Sigma min": "希格瑪最小值（Sigma min）",
  "Sigma max": "希格瑪最大值（Sigma max）",
  "Sigma noise": "希格瑪噪點量（Sigma noise）",
  "Eta": "Eta",
  "Clip skip": "Clip 跳過層",
  "Denoising": "重繪幅度",
  "Hires upscaler": "高解析度放大工具",
  "VAE": "VAE",
  "UniPC Order": "UniPC 取樣順序。",
  "Face restore": "面部修復",
  "X type": "X 軸類型",
  "X values": "X 軸值",
  "Y type": "Y 軸類型",
  "Y values": "Y 軸值",
  "Z type": "Z 軸類型",
  "Z values": "Z 軸值",
  "Draw legend": "在圖表中包括軸類型和值",
  "Keep -1 for seeds": "保持隨機種子為 -1",
  "Include Sub Images": "包括子圖像",
  "Include Sub Grids": "包括子網格",
  "Swap X/Y axes": "交換 X/Y 軸",
  "Swap Y/Z axes": "交換 Y/Z 軸",
  "Swap X/Z axes": "交換 X/Z 軸",
  "Save": "儲存",
  "Zip": "Zip",
  "Send to img2img": ">> 圖生圖",
  "Send to inpaint": ">> 局部重繪",
  "Send to extras": ">> 附加功能",
  "Interrogate\nCLIP": "CLIP\n反推提示詞",
  "Interrogate\nDeepBooru": "DeepBooru\n反推提示詞",
  "Sketch": "素描",
  "Inpaint": "局部重繪",
  "Inpaint sketch": "修復素描",
  "Inpaint upload": "修復上傳",
  "Batch": "批次",
  "Image for img2img": "圖生圖的圖像",
  "Drop Image Here": "拖曳圖像到此",
  "Copy image to:": "複製圖片到：",
  "sketch": "素描",
  "inpaint": "修復",
  "inpaint sketch": "修復草圖",
  "Image for inpainting with mask": "用於局部重繪並手動畫遮罩的圖像",
  "Color sketch inpainting": "彩繪修復",
  "Mask": "遮罩",
  "Process images in a directory on the same machine where the server is running.": "處理伺服器主機上的某一個目錄中的圖像。",
  "Use an empty output directory to save pictures normally instead of writing to the output directory.": "輸出圖像到一個空目錄，而非設定裡指定的輸出目錄。",
  "Add inpaint batch mask directory to enable inpaint batch processing.": "新增修補批次遮罩目錄以啟用批次處理修補功能。",
  "Input directory": "輸入目錄",
  "Output directory": "輸出目錄",
  "Inpaint batch mask directory (required for inpaint batch processing only)": "修補批次遮罩目錄（僅適用於批次處理修補功能）",
  "Resize mode": "縮放模式",
  "Just resize": "拉伸",
  "Crop and resize": "裁剪",
  "Resize and fill": "填充",
  "Just resize (latent upscale)": "僅重新調整大小（潛在變數放大）",
  "Mask blur": "遮罩模糊",
  "Mask transparency": "遮罩透明度",
  "Mask mode": "遮罩模式",
  "Inpaint masked": "重繪遮罩內容",
  "Inpaint not masked": "重繪非遮罩內容",
  "Masked content": "遮罩內容",
  "fill": "填充",
  "original": "原圖",
  "latent noise": "潛在變數噪點",
  "latent nothing": "潛在變數數值零",
  "Inpaint area": "修復區域",
  "Whole picture": "全圖",
  "Only masked": "僅被遮罩",
  "Only masked padding, pixels": "僅填充遮罩部分（像素）",
  "Image CFG Scale": "圖像提示詞相關性",
  "img2img alternative test": "圖生圖的另一種測試",
  "Loopback": "回送",
  "Outpainting mk2": "向外繪製第二版",
  "Poor man's outpainting": "效果稍差的向外繪製",
  "SD upscale": "使用 SD 放大",
  "should be 2 or lower.": "必須小於等於 2",
  "Override `Sampling method` to Euler?(this method is built for it)": "覆寫「採樣方法」為 Euler？（這個方法就是為它設計的）",
  "Override `prompt` to the same value as `original prompt`?(and `negative prompt`)": "覆寫「提示詞」為「初始提示詞」？（「反向提示詞」同理）",
  "Original prompt": "初始提示詞",
  "Original negative prompt": "初始反向提示詞",
  "Override `Sampling Steps` to the same value as `Decode steps`?": "覆寫「取樣疊代步數」為「解碼疊代步數」？",
  "Decode steps": "解碼疊代步數",
  "Override `Denoising strength` to 1?": "覆寫「重繪幅度」為 1？",
  "Decode CFG scale": "解碼提示詞相關性",
  "Randomness": "隨機度",
  "Sigma adjustment for finding noise for image": "為尋找圖中噪點的希格瑪（Sigma）調整",
  "Loops": "疊代次數",
  "Final denoising strength": "最終重繪幅度",
  "Denoising strength curve": "降噪強度曲線",
  "Linear": "線性（Linear）",
  "Append interrogated prompt at each iteration": "在每次疊代中附加詢問提示。",
  "CLIP": "CLIP",
  "DeepBooru": "DeepBooru",
  "Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8": "推薦設定：取樣疊代步數：80-100，取樣器：Euler a，重繪幅度：0.8",
  "Pixels to expand": "拓展的畫素數",
  "Outpainting direction": "向外繪製的方向",
  "left": "左",
  "right": "右",
  "up": "上",
  "down": "下",
  "Fall-off exponent (lower=higher detail)": "衰減指數（越小細節越好）",
  "Color variation": "色彩變化",
  "Will upscale the image by the selected scale factor; use width and height sliders to set tile size": "將會通過所選擇的縮放因子將圖像放大；使用寬度和高度滑塊設定磚大小",
  "Tile overlap": "圖塊重疊的畫素",
  "Scale Factor": "比例因子",
  "Lanczos": "Lanczos",
  "Nearest": "最鄰近整數縮放（Nearest）",
  "ESRGAN_4x": "ESRGAN_4x",
  "LDSR": "LDSR",
  "R-ESRGAN 4x+": "R-ESRGAN 4x+",
  "R-ESRGAN 4x+ Anime6B": "R-ESRGAN 4x+ Anime6B",
  "ScuNET GAN": "ScuNET GAN",
  "ScuNET PSNR": "ScuNET PSNR",
  "SwinIR 4x": "SwinIR 4x",
  "Single Image": "單張圖像",
  "Batch Process": "批次處理",
  "Batch from Directory": "從目錄進行批量處理",
  "Source": "來源",
  "Show result images": "顯示輸出圖像",
  "Scale by": "等比縮放",
  "Scale to": "指定解析度縮放",
  "Resize": "縮放比例",
  "Crop to fit": "裁剪以適應寬高比",
  "Upscaler 1": "放大演算法 1",
  "Upscaler 2": "放大演算法 2",
  "Upscaler 2 visibility": "放大演算法 2 可見度",
  "GFPGAN visibility": "GFPGAN 可見度",
  "CodeFormer visibility": "CodeFormer 可見度",
  "CodeFormer weight (0 = maximum effect, 1 = minimum effect)": "CodeFormer 權重 （為 0 時效果最大，為 1 時效果最小）",
  "Send to txt2img": ">> 文生圖",
  "A weighted sum will be used for interpolation. Requires two models; A and B. The result is calculated as A * (1 - M) + B * M": "插值將使用加權和。需要兩個模型；A和B。結果為A *（1-M）+ B * M計算。",
  "Primary model (A)": "主要模型（A）",
  "Secondary model (B)": "次要模型（B）",
  "Tertiary model (C)": "第三模型（C）",
  "Custom Name (Optional)": "自訂名稱 （可選）",
  "Multiplier (M) - set to 0 to get model A": "倍率（M）- 設為 0 等價於模型 A",
  "Interpolation Method": "插值方法",
  "No interpolation": "無插值",
  "Weighted sum": "加權和",
  "Add difference": "加入差分",
  "Checkpoint format": "模型權重檢查點格式",
  "ckpt": "ckpt",
  "safetensors": "safetensors",
  "Save as float16": "以 float16 儲存",
  "Copy config from": "複製配置自",
  "A, B or C": "A, B or C",
  "B": "B",
  "C": "C",
  "Don't": "不要",
  "Bake in VAE": "嵌入VAE",
  "Discard weights with matching name": "丟棄名稱相符的權重",
  "Merge": "合併",
  "See": "檢視",
  "wiki": "wiki 文件",
  "for detailed explanation.": "以了解詳細說明",
  "Create embedding": "建立嵌入",
  "Create hypernetwork": "建立超網路（Hypernetwork）",
  "Preprocess images": "圖像預處理",
  "Name": "名稱",
  "Initialization text": "初始化文字",
  "Number of vectors per token": "每個標記的向量數",
  "Overwrite Old Embedding": "覆寫舊的嵌入",
  "Modules": "模組",
  "Enter hypernetwork layer structure": "輸入超網路（Hypernetwork）層結構",
  "Select activation function of hypernetwork. Recommended : Swish / Linear(none)": "選擇超網路（Hypernetwork）的激活函數。建議：Swish／Linear（線性，等於不用）",
  "linear": "線性（linear）",
  "relu": "relu",
  "leakyrelu": "leakyrelu",
  "elu": "elu",
  "swish": "swish",
  "tanh": "tanh",
  "sigmoid": "sigmoid",
  "celu": "celu",
  "gelu": "gelu",
  "glu": "glu",
  "hardshrink": "hardshrink",
  "hardsigmoid": "hardsigmoid",
  "hardtanh": "hardtanh",
  "logsigmoid": "logsigmoid",
  "logsoftmax": "logsoftmax",
  "mish": "mish",
  "prelu": "prelu",
  "rrelu": "rrelu",
  "relu6": "relu6",
  "selu": "selu",
  "silu": "silu",
  "softmax": "softmax",
  "softmax2d": "softmax2d",
  "softmin": "softmin",
  "softplus": "softplus",
  "softshrink": "softshrink",
  "softsign": "softsign",
  "tanhshrink": "tanhshrink",
  "threshold": "閾值",
  "Select Layer weights initialization. Recommended: Kaiming for relu-like, Xavier for sigmoid-like, Normal otherwise": "選擇初始化層權重的方案。建議：類relu 用 Kaiming；類sigmoid 用 Xavier，其它就用正態",
  "Normal": "正態",
  "KaimingUniform": "Kaiming 均勻",
  "KaimingNormal": "Kaiming 正態",
  "XavierUniform": "Xavier 均勻",
  "XavierNormal": "Xavier 正態",
  "Add layer normalization": "加入層歸一化",
  "Use dropout": "採用 dropout 防止過擬合",
  "Enter hypernetwork Dropout structure (or empty). Recommended : 0~0.35 incrementing sequence: 0, 0.05, 0.15": "輸入 Hypernetwork Dropout 結構（或空）。推薦：0~0.35 的遞增序列：0、0.05、0.15",
  "Overwrite Old Hypernetwork": "覆寫舊的超網路（Hypernetwork）",
  "Source directory": "來源目錄",
  "Destination directory": "目標目錄",
  "Existing Caption txt Action": "對現有的文字文件進行描述文字的動作",
  "ignore": "無視",
  "copy": "複製",
  "prepend": "放前面",
  "append": "放後面",
  "Create flipped copies": "建立鏡像副本",
  "Split oversized images": "分割過大的圖像",
  "Auto focal point crop": "自動焦點裁切",
  "Auto-sized crop": "自動選擇大小的剪裁",
  "Use BLIP for caption": "使用 BLIP 產生描述（自然語言描述）",
  "Use deepbooru for caption": "使用 deepbooru 產生描述（標記）",
  "Split image threshold": "圖像分割閾值",
  "Split image overlap ratio": "分割圖像重疊的比率",
  "Focal point face weight": "焦點面部權重",
  "Focal point entropy weight": "焦點熵權重",
  "Focal point edges weight": "焦點線條權重",
  "Create debug image": "建立除錯圖像",
  "Each image is center-cropped with an automatically chosen width and height.": "每個圖像以自動選擇的寬度和高度為中心進行裁剪。",
  "Dimension lower bound": "維度下限",
  "Dimension upper bound": "維度上限",
  "Area lower bound": "面積下限",
  "Area upper bound": "面積上限",
  "Resizing objective": "調整大小目標",
  "Maximize area": "最大化面積",
  "Minimize error": "最小化誤差",
  "Error threshold": "誤差閾值",
  "Preprocess": "預處理",
  "Train an embedding or Hypernetwork; you must specify a directory with a set of 1:1 ratio images": "訓練嵌入或者超網路；必須指定一個具有一組 1:1 比例圖像的目錄",
  "[wiki]": "[wiki]",
  "Embedding": "嵌入",
  "Hypernetwork": "超網路",
  "Embedding Learning rate": "嵌入學習率",
  "Hypernetwork Learning rate": "超網路學習率",
  "Gradient Clipping": "梯度修剪",
  "disabled": "停用",
  "value": "值",
  "norm": "範數",
  "Gradient accumulation steps": "梯度累加步數",
  "Dataset directory": "資料集目錄",
  "Log directory": "日誌目錄",
  "Prompt template": "提示模板",
  "Do not resize images": "不要調整影像大小",
  "Max steps": "最大疊代步數",
  "Save an image to log directory every N steps, 0 to disable": "每 N 步儲存一張圖像到記錄目錄，0 表示停用",
  "Save a copy of embedding to log directory every N steps, 0 to disable": "每 N 步將嵌入的副本儲存到記錄目錄，0 表示停用",
  "Use PNG alpha channel as loss weight": "使用 PNG 透明通道作為損失權重",
  "Save images with embedding in PNG chunks": "儲存圖像，並在 PNG 圖片檔案中嵌入檔案",
  "Read parameters (prompt, etc...) from txt2img tab when making previews": "進行預覽時，從文生圖頁籤中讀取參數（提示詞等）",
  "Shuffle tags by ',' when creating prompts.": "在建立提示時用 ',' 洗牌標籤",
  "Drop out tags when creating prompts.": "在建立提示時刪除標籤",
  "Choose latent sampling method": "選擇潛在變數取樣方法",
  "once": "一次",
  "deterministic": "確定",
  "random": "隨機",
  "Train Embedding": "訓練嵌入",
  "Train Hypernetwork": "訓練超網路",
  "Apply settings": "套用設定",
  "Reload UI": "重新載入 UI",
  "Saving images/grids": "儲存圖像 / 宮格圖",
  "Paths for saving": "儲存路徑",
  "Saving to a directory": "儲存到目錄",
  "Upscaling": "放大",
  "Face restoration": "面部修復",
  "System": "系統",
  "Training": "訓練",
  "Stable Diffusion": "Stable Diffusion",
  "Compatibility": "相容性",
  "Interrogate Options": "反推提示詞選項",
  "Extra Networks": "額外網路",
  "User interface": "使用者介面",
  "Live previews": "即時預覽",
  "Sampler parameters": "取樣器參數",
  "Postprocessing": "後處理",
  "Actions": "動作",
  "Licenses": "授權",
  "Always save all generated images": "始終儲存所有產生的圖像",
  "File format for images": "圖像的檔案格式",
  "Images filename pattern": "圖像檔案名格式",
  "Add number to filename when saving": "儲存的時候在檔案名里加入數字",
  "Always save all generated image grids": "始終儲存所有產生的宮格圖",
  "File format for grids": "宮格圖的檔案格式",
  "Add extended info (seed, prompt) to filename when saving grid": "儲存宮格圖時，將擴展資訊（隨機種子，提示詞）加入到檔案名",
  "Do not save grids consisting of one picture": "只有一張圖片時不要儲存宮格圖",
  "Prevent empty spots in grid (when set to autodetect)": "（啟用自動偵測時）防止宮格圖中出現空位",
  "Grid row count; use -1 for autodetect and 0 for it to be same as batch size": "宮格圖行數； 使用 -1 進行自動檢測，使用 0 使其與每批數量相同",
  "Save text information about generation parameters as chunks to png files": "將有關生成參數的文本資訊，作為塊儲存到 PNG 圖片檔案中",
  "Create a text file next to every image with generation parameters.": "儲存圖像時，在每個圖像旁邊建立一個文本檔案儲存生成參數",
  "Save a copy of image before doing face restoration.": "在進行面部修復之前儲存圖像副本",
  "Save a copy of image before applying highres fix.": "在做高解析度修復之前儲存初始圖像副本",
  "Save a copy of image before applying color correction to img2img results": "在對圖生圖結果套用顏色校正之前儲存圖像副本",
  "For inpainting, save a copy of the greyscale mask": "對於局部重繪，保存一份灰度遮罩的副本。",
  "For inpainting, save a masked composite": "對於修補，保存一個遮罩合成圖像。",
  "Quality for saved jpeg images": "儲存的 JPEG 圖像的品質",
  "Use lossless compression for webp images": "對 webp 圖像使用無損壓縮",
  "If the saved image file size is above the limit, or its either width or height are above the limit, save a downscaled copy as JPG": "如果儲存的圖像檔案容量超過下列上限，則額外儲存一個縮小比例的 JPG",
  "File size limit for the above option, MB": "檔案容量上限（MB）",
  "Width/height limit for the above option, in pixels": "解析度寬高上限（px）",
  "Maximum image size, in megapixels": "最大像素值",
  "Use original name for output filename during batch process in extras tab": "在更多頁籤中的批量處理過程中，使用原始名稱作為輸出檔案名",
  "Use upscaler name as filename suffix in the extras tab": "使用上色器名稱作為附加檔的檔名後綴",
  "When using 'Save' button, only save a single selected image": "使用「儲存」按鈕時，只儲存一個選定的圖像",
  "Do not add watermark to images": "不要給圖像加浮水印",
  "Directory for temporary images; leave empty for default": "暫存影像的目錄；留空以使用預設值",
  "Cleanup non-default temporary directory when starting webui": "在啟動網頁介面時清除非預設的暫存目錄",
  "Output directory for images; if empty, defaults to three directories below": "圖像的輸出目錄； 如果為空，則預設為以下三個目錄",
  "Output directory for txt2img images": "文生圖的輸出目錄",
  "Output directory for img2img images": "圖生圖的輸出目錄",
  "Output directory for images from extras tab": "更多頁籤的輸出目錄",
  "Output directory for grids; if empty, defaults to two directories below": "宮格圖的輸出目錄； 如果為空，則預設為以下兩個目錄",
  "Output directory for txt2img grids": "文生圖宮格的輸出目錄",
  "Output directory for img2img grids": "圖生圖宮格的輸出目錄",
  "Directory for saving images using the Save button": "使用「儲存」按鈕儲存圖像的目錄",
  "Save images to a subdirectory": "將圖像儲存到子目錄",
  "Save grids to a subdirectory": "將宮格圖儲存到子目錄",
  "When using \"Save\" button, save images to a subdirectory": "使用「儲存」按鈕時，將圖像儲存到子目錄",
  "Directory name pattern": "目錄名稱格式",
  "Max prompt words for [prompt_words] pattern": "[prompt_words] 格式的最大提示詞數量",
  "Tile size for ESRGAN upscalers. 0 = no tiling.": "ESRGAN 的圖塊尺寸。0 為不分塊",
  "Tile overlap, in pixels for ESRGAN upscalers. Low values = visible seam.": "ESRGAN 的圖塊重疊畫素。較小時可見接縫",
  "Upscaler for img2img": "圖生圖的放大演算法",
  "LDSR processing steps. Lower = faster": "LDSR 處理疊代步數。越少越快",
  "Cache LDSR model in memory": "將 LDSR 模型快取在記憶體中",
  "Tile size for all SwinIR.": "適用所有 SwinIR 系演算法的圖塊尺寸",
  "Tile overlap, in pixels for SwinIR. Low values = visible seam.": "SwinIR 的圖塊重疊畫素。較小時可見接縫",
  "CodeFormer weight parameter; 0 = maximum effect; 1 = minimum effect": "CodeFormer 權重參數；為 0 時效果最大；為 1 時效果最小",
  "Move face restoration model from VRAM into RAM after processing": "面部修復處理完成後，將此模型從顯存（VRAM）移至內存（RAM）",
  "Show warnings in console.": "在控制台顯示警告訊息。",
  "VRAM usage polls per second during generation. Set to 0 to disable.": "生成圖像時每秒輪詢顯存（VRAM）使用情況的次數。設定為 0 以停用",
  "Always print all generation info to standard output": "始終將所有產生資訊輸出到 standard output （一般為控制台）",
  "Add a second progress bar to the console that shows progress for an entire job.": "向控制台加入第二個進度列，顯示整個作業的進度",
  "Print extra hypernetwork information to console.": "將額外的超網路資訊印到控制台。",
  "Move VAE and CLIP to RAM when training if possible. Saves VRAM.": "訓練時將 VAE 和 CLIP 從顯存（VRAM）移放到內存（RAM）如果可行的話，節省顯存（VRAM）",
  "Turn on pin_memory for DataLoader. Makes training slightly faster but can increase memory usage.": "對 DataLoader 開啟 pin_memory。使訓練略快，但可能會增加記憶體使用量。",
  "Saves Optimizer state as separate *.optim file. Training of embedding or HN can be resumed with the matching optim file.": "將優化器狀態儲存為獨立的 *.optim 檔。嵌入或超網路的訓練可以使用相匹配的優化檔恢復。",
  "Save textual inversion and hypernet settings to a text file whenever training starts.": "每次訓練開始時，將文本反轉和超網路設定儲存到一個文字檔案中。",
  "Filename word regex": "檔案名用詞的正則表達式",
  "Filename join string": "檔案名連接用字串",
  "Number of repeats for a single input image per epoch; used only for displaying epoch number": "每期（epoch）中單個輸入圖像的重複次數； 僅用於顯示期（epoch）數",
  "Save an csv containing the loss to log directory every N steps, 0 to disable": "每 N 步儲存一個包含 loss 的 CSV 檔案到記錄目錄，0 表示停用",
  "Use cross attention optimizations while training": "訓練時開啟 cross attention 最佳化",
  "Enable tensorboard logging.": "啟用 TensorBoard 日誌記錄。",
  "Save generated images within tensorboard.": "在 TensorBoard 中儲存產生的圖像。",
  "How often, in seconds, to flush the pending tensorboard events and summaries to disk.": "多少秒刷新一次待辦 TensorBoard 事件和摘要到磁盤上",
  "Checkpoints to cache in RAM": "暫存在內存（RAM）中的模型權重存檔點數",
  "VAE Checkpoints to cache in RAM": "在快取記憶體中快取 VAE 模型權重存檔點",
  "SD VAE": "模型的 VAE",
  "Automatic": "自動化",
  "Ignore selected VAE for stable diffusion checkpoints that have their own .vae.pt next to them": ".vae.pt 模型權重存檔點在名稱相同時，忽略掉選中的 VAE",
  "Inpainting conditioning mask strength": "局部重繪時圖像調節的遮罩屏蔽強度",
  "Noise multiplier for img2img": "圖生圖的噪聲乘數",
  "Apply color correction to img2img results to match original colors.": "對圖生圖結果套用顏色校正以匹配原始顏色",
  "With img2img, do exactly the amount of steps the slider specifies (normally you'd do less with less denoising).": "在進行圖生圖的時候，確切地執行滑桿指定的疊代步數（正常情況下更弱的重繪幅度需要更少的疊代步數）",
  "With img2img, fill image's transparent parts with this color.": "在 img2img 中，以此顏色填滿圖片的透明部分。",
  "Enable quantization in K samplers for sharper and cleaner results. This may change existing seeds. Requires restart to apply.": "在 K 取樣器中啟用量化以獲得更清晰，乾淨的結果。這可能會改變現有的隨機種子。需要儲存設定並重新啟動才能套用",
  "Emphasis: use (text) to make model pay more attention to text and [text] to make it pay less attention": "強調符：使用 (文字) 使模型更關注該文本，使用 [文字] 使其減少關注",
  "Make K-diffusion samplers produce same images in a batch as when making a single image": "使 K-diffusion 取樣器批量生成與生成單個圖像時，產出相同的圖像",
  "Increase coherency by padding from the last comma within n tokens when using more than 75 tokens": "當使用超過 75 個標記時，通過從 n 個標記中的最後一個逗號填補來提高一致性",
  "Upcast cross attention layer to float32": "將交叉注意層升級為 float32",
  "Use old emphasis implementation. Can be useful to reproduce old seeds.": "使用舊的強調符實作。可用於復現舊隨機種子",
  "Use old karras scheduler sigmas (0.1 to 10).": "使用舊的 karras 調度器 sigma（0.1 至 10）",
  "Do not make DPM++ SDE deterministic across different batch sizes.": "不要使 DPM++ SDE 在不同的批次大小之間具有確定性。",
  "For hires fix, use width/height sliders to set final resolution rather than first pass (disables Upscale by, Resize width/height to).": "為了 hires fix，使用寬度/高度滑桿設定最終解析度，而不是第一遍（停用放大比例、調整寬度/高度）",
  "Interrogate: keep models in VRAM": "反推：將模型儲存在顯存（VRAM）中",
  "Interrogate: include ranks of model tags matches in results (Has no effect on caption-based interrogators).": "反推：在生成結果中包含與模型標記相匹配的等級（對基於生成自然語言描述的反推沒有影響）",
  "Interrogate: num_beams for BLIP": "反推：BLIP 的 num_beams",
  "Interrogate: minimum description length (excluding artists, etc..)": "反推：最小描述長度（不包括藝術家，等…）",
  "Interrogate: maximum description length": "反推：最大描述長度",
  "CLIP: maximum number of lines in text file (0 = No limit)": "CLIP：文本檔案中的最大行數（0 為無限制）",
  "CLIP: skip inquire categories": "CLIP：跳過詢問類別",
  "Interrogate: deepbooru score threshold": "反推：deepbooru 分數閾值",
  "Interrogate: deepbooru sort alphabetically": "反推：deepbooru 按字母順序排序",
  "use spaces for tags in deepbooru": "在 deepbooru 中為標記使用空格",
  "escape (\\) brackets in deepbooru (so they are used as literal brackets and not for emphasis)": "在 deepbooru 中使用轉義（\\）括號（使括號作為字串使用而不是強調符號）",
  "filter out those tags from deepbooru output (separated by comma)": "從 deepbooru 輸出中過濾掉那些標籤（以逗號分隔）",
  "Default view for Extra Networks": "額外網絡的默認視圖",
  "cards": "卡片",
  "Multiplier for extra networks": "額外網絡的乘數",
  "Card width for Extra Networks (px)": "額外網絡的卡片寬度（像素）",
  "Card height for Extra Networks (px)": "額外網絡的卡片高度（像素）",
  "Extra text to add before <...> when adding extra network to prompt": "在添加額外網絡到提示之前添加的額外文本 <...>",
  "Add hypernetwork to prompt": "將超網路加入至提示詞",
  "Add Lora to prompt": "將 LoRA 添加到提示詞",
  "Show grid in results for web": "在網頁的結果中顯示宮格圖",
  "For inpainting, include the greyscale mask in results for web": "對於局部重繪，將灰度遮罩包含在網頁結果中",
  "For inpainting, include masked composite in results for web": "對於局部重繪，將遮罩合成包含在網頁結果中。",
  "Do not show any images in results for web": "不在網頁的結果中顯示任何圖像",
  "Add model hash to generation information": "將模型的雜湊值加入到生成資訊",
  "Add model name to generation information": "將模型名稱加入到生成資訊",
  "When reading generation parameters from text into UI (from PNG info or pasted text), do not change the selected model/checkpoint.": "從文本讀取生成參數到使用者介面（從 PNG 圖片資訊或粘貼文本）時，不要更改選定的模型權重存檔點",
  "Send seed when sending prompt or image to other interface": "將提示詞或者圖像發送到 >> 其他界面時，把隨機種子也傳送過去",
  "Send size when sending prompt or image to another interface": "發送提示或圖片到其他介面時，發送大小",
  "Font for image grids that have text": "有文字的宮格圖使用的字體",
  "Enable full page image viewer": "啟用整頁圖像檢視器",
  "Show images zoomed in by default in full page image viewer": "在整頁圖像檢視器中，預設放大顯示圖像",
  "Show generation progress in window title.": "在視窗標題中顯示生成進度",
  "Use dropdown for sampler selection instead of radio group": "使用下拉式選單代替單選群組選擇取樣器",
  "Show Width/Height and Batch sliders in same row": "在同一列中顯示寬度 / 高度和批量滑塊",
  "Ctrl+up/down precision when editing (attention:1.1)": "編輯時使用 Ctrl + up/down 調整精度 (注意：1.1)",
  "Ctrl+up/down precision when editing <extra networks:0.9>": "編輯時使用 Ctrl + up/down 調整精度 <額外網路：0.9>",
  "Quicksettings list": "快捷設定列表",
  "Hidden UI tabs (requires restart)": "隱藏介面頁籤（需要儲存設定並重新啟動）",
  "txt2img/img2img UI item order": "文生圖 / 圖生圖 UI 項目順序",
  "Extra networks tab order": "額外網絡標籤順序",
  "Localization (requires restart)": "本地化翻譯（需要儲存設定並重新啟動）",
  "Show progressbar": "顯示進度列",
  "Show live previews of the created image": "顯示所創建的圖像的實時預覽",
  "Show previews of all images generated in a batch as a grid": "以宮格圖的形式，預覽批量產生的所有圖像",
  "Show new live preview image every N sampling steps. Set to -1 to show after completion of batch.": "每隔 N 次採樣步驟顯示一次新的實時預覽圖像。 設定為 -1 以在批次完成後顯示。",
  "Image creation progress preview mode": "圖像創建進度預覽模式",
  "Full": "完整",
  "Approx NN": "Approx NN",
  "Approx cheap": "Approx cheap",
  "Live preview subject": "實時預覽主題",
  "Combined": "結合",
  "Progressbar/preview update period, in milliseconds": "進度條 / 預覽更新周期，以毫秒為單位",
  "Hide samplers in user interface (requires restart)": "在使用者介面中隱藏取樣器（需要儲存設定並重新啟動）",
  "Euler": "Euler",
  "LMS": "LMS",
  "Heun": "Heun",
  "DPM2": "DPM2",
  "DPM2 a": "DPM2 a",
  "DPM++ 2S a": "DPM++ 2S a",
  "DPM++ 2M": "DPM++ 2M",
  "DPM++ SDE": "DPM++ SDE",
  "DPM fast": "DPM fast",
  "DPM adaptive": "DPM adaptive",
  "LMS Karras": "LMS Karras",
  "DPM2 Karras": "DPM2 Karras",
  "DPM2 a Karras": "DPM2 a Karras",
  "DPM++ 2S a Karras": "DPM++ 2S a Karras",
  "DPM++ 2M Karras": "DPM++ 2M Karras",
  "DPM++ SDE Karras": "DPM++ SDE Karras",
  "DDIM": "DDIM",
  "PLMS": "PLMS",
  "UniPC": "UniPC",
  "eta (noise multiplier) for DDIM": "DDIM 的 eta （噪點乘數）",
  "eta (noise multiplier) for ancestral samplers": "ancestral 取樣器的 eta （噪點乘數）",
  "img2img DDIM discretize": "圖生圖 DDIM 離散化",
  "uniform": "均勻",
  "quad": "二階",
  "sigma churn": "希格瑪流失量（sigma churn）",
  "sigma tmin": "希格瑪最小值（sigma tmin）",
  "sigma noise": "希格瑪噪點量（sigma noise）",
  "Eta noise seed delta": "Eta 噪點種子偏移（ENSD）",
  "Always discard next-to-last sigma": "始終丟棄倒數第二個 sigma",
  "UniPC variant": "UniPC 變體",
  "bh1": "bh1",
  "bh2": "bh2",
  "vary_coeff": "vary_coeff",
  "UniPC skip type": "UniPC 跳過類型",
  "time_uniform": "time_uniform",
  "time_quadratic": "time_quadratic",
  "logSNR": "logSNR",
  "UniPC order (must be < sampling steps)": "UniPC 取樣順序（必須小於取樣疊代步數）",
  "UniPC lower order final": "UniPC 最終步採用低階取樣。",
  "Enable postprocessing operations in txt2img and img2img tabs": "啟用文生圖和圖生圖選項卡中的後處理操作",
  "Postprocessing operation order": "後處理操作順序",
  "Maximum number of images in upscaling cache": "放大快取中圖像的最大數量",
  "Request browser notifications": "請求瀏覽器通知",
  "Download localization template": "下載本地化模板",
  "Reload custom script bodies (No ui updates, No restart)": "重新載入自訂指令碼主體（使用者介面不刷新，不重新啟動）",
  "Unload SD checkpoint to free VRAM": "卸載模型權重存檔點以釋放 VRAM",
  "Reload the last SD checkpoint back into VRAM": "重新載入上一個模型權重存檔點至 VRAM",
  "Show all pages": "顯示所有頁面",
  "Installed": "已安裝",
  "Available": "可用",
  "Install from URL": "從網址安裝",
  "Apply and restart UI": "更新並重新啟動使用者介面",
  "Check for updates": "檢查更新",
  "Disable all extensions": "停用所有擴充功能",
  "none": "無",
  "extra": "額外的",
  "all": "全部",
  "Extension": "擴充功能",
  "Use checkbox to enable the extension; it will be enabled or disabled when you click apply button": "勾選要啟用的擴充功能並按下套用以啟用，取消勾選則停用",
  "URL": "網址",
  "Version": "版本",
  "Extension version": "擴充功能版本",
  "Update": "更新",
  "Use checkbox to mark the extension for update; it will be updated when you click apply button": "勾選要更新的擴充功能並按下套用以更新",
  "built-in": "內建的",
  "latest": "最新",
  "behind": "有可用更新",
  "Error": "錯誤",
  "unknown": "未知",
  "ScuNET": "ScuNET",
  "prompt-bracket-checker": "提示括號檢查器",
  "Load from:": "載入自",
  "Extension index URL": "擴充列表網址",
  "Hide extensions with tags": "隱藏含有以下標記的擴充工具",
  "script": "指令碼",
  "ads": "含廣告",
  "localization": "本地化",
  "installed": "已安裝",
  "Description": "描述",
  "Action": "動作",
  "dropdown": "下拉式清單",
  "UI related": "使用者介面相關",
  "tab": "頁籤",
  "animation": "動畫",
  "online": "線上",
  "extras": "附加功能",
  "science": "科學",
  "models": "模型",
  "query": "查詢",
  "training": "訓練",
  "Fusion": "融合",
  "editing": "編輯",
  "Waiting...": "等待中...",
  "Time taken:": "用時：",
  "prompting": "提示詞",
  "manipulations": "操作",
  "Order": "排序",
  "newest first": "最新的在最前面",
  "oldest first": "最舊的在最前面",
  "a-z": "字母順序：從a到z",
  "z-a": "字母順序：從z到a",
  "internal order": "內部順序",
  "Search": "搜尋",
  "URL for extension's git repository": "擴充功能的 git 倉庫網址",
  "Local directory name": "本地目錄名稱",
  "Install": "安裝",
  "N/A": "N/A",
  "Change checkpoint": "切換模型權重存檔點",
  "Remove All": "全部移除",
  "Prompt (press Ctrl+Enter or Alt+Enter to generate)": "提示詞（按 Ctrl+Enter 或 Alt+Enter 產生）",
  "Negative prompt (press Ctrl+Enter or Alt+Enter to generate)": "反向提示詞（按 Ctrl+Enter 或 Alt+Enter 產生）",
  "Stop processing images and return any results accumulated so far.": "停止處理圖像，並返回迄今為止累積的任何結果",
  "Stop processing current image and continue processing.": "停止處理當前圖像，並繼續處理下一個",
  "Read generation parameters from prompt or last generation if prompt is empty into user interface.": "從提示詞中讀取生成參數，如果提示詞為空，則讀取上一次的生成參數到使用者介面",
  "Clear prompt": "清除提示詞",
  "Show/hide extra networks": "顯示 / 隱藏額外的網路",
  "Apply selected styles to current prompt": "將所選樣式套用於當前提示",
  "Save style": "儲存樣式",
  "Search...": "搜尋...",
  "Which algorithm to use to produce the image": "使用哪種演算法生成圖像",
  "Euler Ancestral - very creative, each can get a completely different picture depending on step count, setting steps higher than 30-40 does not help": "Euler Ancestral - 非常具創意，每個人都可以根據步數獲得完全不同的圖片，將步數設定高於 30-40 並沒有太大幫助",
  "How many times to improve the generated image iteratively; higher values take longer; very low values can produce bad results": "疊代改進產生的圖像多少次；更高的值需要更長的時間；非常低的值會產生不好的結果",
  "Produce an image that can be tiled.": "生成可用於平舖的圖像",
  "Use a two step process to partially create an image at smaller resolution, upscale, and then improve details in it without changing composition": "使用兩步處理的時候，以較小的解析度生成初步圖像，接著放大圖像，然後在不更改構圖的情況下改進其中的細節",
  "Number of sampling steps for upscaled picture. If 0, uses same as for original.": "放大圖片的取樣步數。如果為0，則使用與原始圖片相同的值。",
  "Determines how little respect the algorithm should have for image's content. At 0, nothing will change, and at 1 you'll get an unrelated image. With values below 1.0, processing will take less steps than the Sampling Steps slider specifies.": "決定演算法對圖像內容的影響程度。設定 0 時，什麼都不會改變，而在 1 時，你將獲得不相關的圖像。\n值低於 1.0 時，處理的疊代步數將少於「取樣疊代步數」滑桿指定的步數",
  "Adjusts the size of the image by multiplying the original width and height by the selected value. Ignored if either Resize width to or Resize height to are non-zero.": "通過乘以選定值來調整圖像的大小。如果「將寬度調整至」或「將高度調整至」不為零，則會忽略。",
  "Resizes image to this width. If 0, width is inferred from either of two nearby sliders.": "將圖像調整到此寬度。如果為0，則寬度會從兩個附近的滑塊之一推斷。",
  "Resizes image to this height. If 0, height is inferred from either of two nearby sliders.": "將圖像調整到此高度。如果為0，則高度會從兩個附近的滑塊之一推斷。",
  "How many batches of images to create (has no impact on generation performance or VRAM usage)": "要產生多少批圖像（對產生效能或 VRAM 使用沒有影響）。",
  "How many image to create in a single batch (increases generation performance at cost of higher VRAM usage)": "在一個批次中產生的圖像數量，增加這個數量可以加快圖像產生速度，但會增加顯存的使用量。",
  "Classifier Free Guidance Scale - how strongly the image should conform to prompt - lower values produce more creative results": "無分類器指導訊息影響尺度（Classifier Free Guidance Scale）- 圖像應在多大程度上服從提示詞 - 較低的值會產生更有創意的結果",
  "A value that determines the output of random number generator - if you create an image with same parameters and seed as another image, you'll get the same result": "一個固定隨機數生成器輸出的值 — 以相同參數和隨機種子生成的圖像會得到相同的結果\n🎲 將隨機種子設定為負數（預設-1），則每次都會使用一個非負數的隨機整數\n♻️ 重用上一次使用的隨機種子，如果想要固定輸出結果的話這很有用",
  "Set seed to -1, which will cause a new random number to be used every time": "將隨機種子設定為 -1，則每次都會使用一個新的隨機數",
  "Reuse seed from last generation, mostly useful if it was randomed": "重用上一次使用的隨機種子，如果想要固定結果就會很有用",
  "Seed of a different picture to be mixed into the generation.": "將要參與生成的另一張圖的隨機種子",
  "How strong of a variation to produce. At 0, there will be no effect. At 1, you will get the complete picture with variation seed (except for ancestral samplers, where you will just get something).": "想要產生多強烈的變化。設為 0 時，將沒有效果。設為 1 時，你將獲得完全產自差異隨機種子的圖像（此功能對帶有 a 後綴的取樣器無效）",
  "Make an attempt to produce a picture similar to what would have been produced with same seed at specified resolution": "在相同隨機種子但不同解析度的情況下，嘗試生成與指定解析度的生成結果相似的圖片",
  "Do not do anything special": "什麼都不做",
  "Separate values for X axis using commas.": "使用逗號分隔 X 軸的值",
  "Paste available values into the field": "將可用的值貼上到字段中",
  "Separate values for Y axis using commas.": "使用逗號分隔 Y 軸的值",
  "Open images output directory": "打開圖像輸出目錄",
  "Write image to a directory (default - log/images) and generation parameters into csv file.": "將圖像寫入目錄（預設 — log/images）並將生成參數寫入CSV表格檔案",
  "Resize image to target resolution. Unless height and width match, you will get incorrect aspect ratio.": "將圖像大小調整為目標解析度。除非高度和寬度匹配，否則你將獲得不正確的縱橫比",
  "Resize the image so that entirety of target resolution is filled with the image. Crop parts that stick out.": "調整圖像大小，使整個目標解析度都被圖像填充。裁剪多出來的部分",
  "Resize the image so that entirety of image is inside target resolution. Fill empty space with image's colors.": "調整圖像大小，使整個圖像在目標解析度內。用圖像的顏色填充空白區域",
  "How much to blur the mask before processing, in pixels.": "處理前要對遮罩進行多強的模糊，以畫素為單位",
  "What to put inside the masked area before processing it with Stable Diffusion.": "在使用 Stable Diffusion 處理遮罩區域之前要在遮罩區域內放置什麼",
  "fill it with colors of the image": "用圖像的顏色（高強度模糊）填充它",
  "keep whatever was there originally": "保留原來的圖像，不進行預處理",
  "fill it with latent space noise": "以潛在變數空間噪點填充",
  "fill it with latent space zeroes": "以潛在變數填零填充",
  "How many times to process an image. Each output is used as the input of the next loop. If set to 1, behavior will be as if this script were not used.": "設定圖像處理的迴圈次數，每次迴圈的輸出會作為下一個迴圈的輸入。若設定為1，則行為會像沒有使用此腳本一樣。",
  "The denoising strength for the final loop of each image in the batch.": "每個批次中每張圖像的最後迴圈的重繪幅度。",
  "The denoising curve controls the rate of denoising strength change each loop. Aggressive: Most of the change will happen towards the start of the loops. Linear: Change will be constant through all loops. Lazy: Most of the change will happen towards the end of the loops.": "降噪曲線控制每個迴圈中降噪強度的變化率。Aggressive（激進）：大部分的變化會發生在迴圈的開始。Linear（線性）：變化會在所有迴圈中保持恆定。Lazy（懶惰）：大部分的變化會發生在迴圈的結尾。",
  "For SD upscale, how much overlap in pixels should there be between tiles. Tiles overlap so that when they are merged back into one picture, there is no clearly visible seam.": "使用 SD 放大時，圖塊之間應該有多少畫素重疊。圖塊之間需要重疊才可以讓它們在合併回一張圖像時，沒有清晰可見的接縫",
  "A directory on the same machine where the server is running.": "伺服器主機上某一目錄",
  "Leave blank to save images to the default path.": "留空以將圖像儲存到預設路徑",
  "Result = A": "結果 = A",
  "Result = A * (1 - M) + B * M": "結果 = A * (1 - M) + B * M",
  "Result = A + (B - C) * M": "結果 = A + (B - C) * M",
  "Regular expression; if weights's name matches it, the weights is not written to the resulting checkpoint. Use ^model_ema to discard EMA weights.": "正則表達式；如果 weights 的名稱與其匹配，則不將 weights 寫入得到的檢查點。使用 ^model_ema 丟棄 EMA weights。",
  "If the number of tokens is more than the number of vectors, some may be skipped.\nLeave the textbox empty to start with zeroed out vectors": "如果標記數量大於向量數量，則可能會被跳過。\n留下文字方塊空白以開始填零的向量",
  "1st and last digit must be 1. ex:'1, 2, 1'": "第一個和最後一個數字必須是 1。例：'1, 2, 1'",
  "1st and last digit must be 0 and values should be between 0 and 1. ex:'0, 0.01, 0'": "第1和最後一個數字必須是 0，並且值應該在 0 和 1 之間。 ex：'0, 0.01, 0",
  "Gradient clip value": "梯度剪裁值",
  "Path to directory with input images": "帶有輸入圖像的目錄路徑",
  "Path to directory where to write outputs": "進行輸出的目錄路徑",
  "Use following tags to define how filenames for images are chosen: [steps], [cfg], [prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.": "使用以下標記定義如何選擇圖像的檔案名：[steps], [cfg], [prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]，預設請留空。",
  "If this option is enabled, watermark will not be added to created images. Warning: if you do not add watermark, you may be behaving in an unethical manner.": "如果啟用此選項，浮水印將不會加入到生成出來的圖像中。警告：如果你不加入浮水印，你的行為可能是不符合道德操守的",
  "Use following tags to define how subdirectories for images and grids are chosen: [steps], [cfg],[prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.": "使用以下標籤定義圖像和網格的子目錄如何選擇： [steps], [cfg],[prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; 留空為預設值。",
  "Restore low quality faces using GFPGAN neural network": "使用 GFPGAN 神經網路修復低品質面部",
  "This regular expression will be used extract words from filename, and they will be joined using the option below into label text used for training. Leave empty to keep filename text as it is.": "此正則表達式將用於從檔案名中提取單詞，並將使用以下選項將它們接合到用於訓練的標記文本中。留空以保持檔案名文本不變",
  "This string will be used to join split words into a single line if the option above is enabled.": "如果啟用了上述選項，則此處的字元會用於將拆分的單詞接合為同一行",
  "Only applies to inpainting models. Determines how strongly to mask off the original image for inpainting and img2img. 1.0 means fully masked, which is the default behaviour. 0.0 means a fully unmasked conditioning. Lower values will help preserve the overall composition of the image, but will struggle with large changes.": "僅適用於局部重繪專用的模型（模型後綴為 inpainting.ckpt 的模型）。決定了遮罩在局部重繪以及圖生圖中遮蔽原圖內容的強度。 1.0 表示完全遮蔽原圖，這是預設行為。 0.0 表示完全不遮蔽讓原圖進行圖像調節。較低的值將有助於保持原圖的整體構圖，但很難遇到較大的變化。",
  "Early stopping parameter for CLIP model; 1 is stop at last layer as usual, 2 is stop at penultimate layer, etc.": "CLIP 模型的早期停止參數；1 是按照慣例在最後一層停止，2 是在倒數第二層停止，以此類推。",
  "When adding extra network such as Hypernetwork or Lora to prompt, use this multiplier for it.": "當將額外網路（如 Hypernetwork 或 LoRA）添加到提示時，使用此乘數。",
  "List of setting names, separated by commas, for settings that should go to the quick access bar at the top, rather than the usual setting tab. See modules/shared.py for setting names. Requires restarting to apply.": "設定項名稱列表，以逗號（,）分隔，該設定會移動到頂部的快速存取列，而不是預設的設定頁籤。有關設定名稱，請參見 modules/shared.py。需要儲存設定並重新啟動才能套用",
  "Comma-separated list of tab names; tabs listed here will appear in the extra networks UI first and in order lsited.": "以逗號分隔的選項卡名稱列表；在此列出的選項卡將首先出現在額外網路的用戶界面中，並按照列出的順序。",
  "Cheap neural network approximation. Very fast compared to VAE, but produces pictures with 4 times smaller horizontal/vertical resolution and lower quality.": "低負載的神經網絡近似值。與 VAE 相比非常快，但是生成的圖片横向/縱向分辨率為正常的四倍，品質較低。",
  "Very cheap approximation. Very fast compared to VAE, but produces pictures with 8 times smaller horizontal/vertical resolution and extremely low quality.": "非常低負載的近似值。比 VAE 快得多，但是生成的圖片横縱分辨率要小 8 倍，品質非常低。",
  "Ignores step count - uses a number of steps determined by the CFG and resolution": "忽略步驟數，使用由 CFG 和解析度確定的步驟數",
  "Denoising Diffusion Implicit Models - best at inpainting": "Denoising Diffusion Implicit models - 最擅長局部重繪",
  "Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models": "統一的預測校正框架用於快速採樣擴散模型",
  "If this values is non-zero, it will be added to seed and used to initialize RNG for noises when using samplers with Eta. You can use this to produce even more variation of images, or you can use this to match images of other software if you know what you are doing.": "如果這個值不為零，它將被加入到隨機種子中，並在使用帶有 Eta 的取樣器時用於初始化隨機噪點。你可以使用它來產生更多的圖像變化，或者你可以使用它來模仿其他軟體生成的圖像，如果你知道你在做什麼",
  "Leave empty for auto": "留空時自動生成",
  "openOutpaint": "開源圖像擴展",
  "Send to openOutpaint": ">> openOutpaint",
  "openOutpaint-webUI-extension": "openOutpaint-webUI-extension",
  "Refresh openOutpaint": "重新整理開源圖像擴展",
  "https://github.com/zero01101/openOutpaint-webUI-extension.git": "https://github.com/zero01101/openOutpaint-webUI-extension.git",
  "DreamArtist Create embedding": "夢想家（DreamArtist）創建嵌入",
  "DreamArtist Train": "夢想家（DreamArtist）訓練",
  "Process Att-Map": "處理注意力圖（Att-Map）",
  "Initialization text (negative)": "初始化文本（反向）",
  "Number of negative vectors per token": "每個標記的反向向量數",
  "Unet Learning rate": "Unet 模型的學習率",
  "Train with DreamArtist": "使用夢想家（DreamArtist）訓練",
  "Train with reconstruction": "訓練時開啟重建",
  "Attention Map": "注意力圖（Att-Map）",
  "Train U-Net": "訓練 U-Net",
  "CFG scale (dynamic cfg: low,high:type e.g. 1.0-3.5:cos)": "提示詞相關性（動態 CFG：low,high:type，例如 1.0-3.5:cos）",
  "Reconstruction loss weight": "重建損失權重",
  "Negative lr weight": "反向的學習率權重",
  "Classifier path": "分類器（Classifier）的路徑",
  "Accumulation steps": "累加步數",
  "Prompt template file": "提示詞模版檔案",
  "Positive \"filewords\" only": "僅使用正向「詞彙」",
  "Experimental features (May be solve the problem of erratic training and difficult to reproduce [set EMA to 0.97])": "實驗性功能（可能解決訓練不穩定和難以重現的問題 [將 EMA 設定為 0.97]）",
  "EMA (positive)": "EMA (正)",
  "EMA replace steps (positive)": "EMA 替換步數 (正)",
  "EMA (nagetive)": "EMA (負)",
  "EMA replace steps (nagative)": "EMA 替換步數 (負)",
  "beta1": "β1",
  "beta2": "β2",
  "Since there is a self-attention operation in VAE, it may change the distribution of features. This processing will superimpose the attention map of self-attention on the original Att-Map.": "由於 VAE 中使用了自我注意力機制，這可能會改變特徵的分佈。這種處理會將自我注意力產生的注意力圖與原始的注意力圖疊加在一起。",
  "Data directory": "資料目錄",
  "Process": "行程, 程序",
  "Image": "映像檔",
  "DreamArtist-sd-webui-extension": "DreamArtist-sd-webui-extension",
  "Path to classifier ckpt, can be empty": "分類器的路徑，可以是空白",
  "https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git": "https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git",
  "Cafe Aesthetic": "Cafe Aesthetic",
  "Single": "Single",
  "Judge": "Judge",
  "Aesthetic": "Aesthetic",
  "Style": "Style",
  "Waifu": "Waifu",
  "Image Directory": "圖像目錄",
  "Output Directory": "輸出目錄",
  "Classify type": "Classify type",
  "Output style": "Output style",
  "Copy": "複製",
  "Move": "移動",
  "Copy or move captions together": "Copy or move captions together",
  "Basis": "Basis",
  "Relative": "Relative",
  "Absolute": "Absolute",
  "Threshold (Use only when basis is absolute)": "Threshold (Use only when basis is absolute)",
  "Start": "Start",
  "Status": "Status",
  "Idle": "Idle",
  "stable-diffusion-webui-cafe-aesthetic": "stable-diffusion-webui-cafe-aesthetic",
  "https://github.com/p1atdev/stable-diffusion-webui-cafe-aesthetic": "https://github.com/p1atdev/stable-diffusion-webui-cafe-aesthetic",
  "path/to/classify": "path/to/classify",
  "path/to/output": "path/to/output",
  "ControlNet": "ControlNet",
  "ControlNet-M2M": "ControlNet-M2M",
  "Config file for Control Net models": "ControlNet 模型配置文件",
  "Config file for Adapter models": "適配器模型配置文件",
  "Directory for detected maps auto saving": "檢測圖的自動儲存目錄",
  "Extra path to scan for ControlNet models (e.g. training output directory)": "掃描 ControlNet 模型的額外路徑（例如訓練輸出目錄）",
  "Path to directory containing annotator model directories (requires restart, overrides corresponding command line flag)": "包含預處理器模型的路徑（需要重新啟動，取代命令行設置）",
  "Multi ControlNet: Max models amount (requires restart)": "多個 ControlNet：最大模型數量（需要儲存設定並重新啟動）",
  "Model cache size (requires restart)": "模型緩存大小（需要儲存設定並重新啟動）",
  "Apply transfer control when loading models": "加載模型時應用轉移控制",
  "Do not append detectmap to output": "不要將檢測圖附加到輸出目錄",
  "Allow detectmap auto saving": "允許檢測圖自動儲存",
  "Allow other script to control this extension": "允許其他指令碼控制此擴充功能",
  "Skip img2img processing when using img2img initial image": "使用圖生圖初始化圖像時跳過圖生圖處理",
  "Enable optimized monocular depth estimation": "啟用單色深度估算優化",
  "Only use mid-control when inference": "僅在推論時使用中間層控制",
  "Passing ControlNet parameters with \"Send to img2img\"": "通過\"發送給img2img\"來傳遞ControlNet參數",
  "https://github.com/Mikubill/sd-webui-controlnet.git": "https://github.com/Mikubill/sd-webui-controlnet.git",
  "controlnet m2m": "controlnet m2m",
  "Video": "視訊",
  "Drop Video Here": "拖曳影片到此",
  "Save preprocessed": "儲存預處理",
  "Duration": "Duration",
  "[ControlNet] Enabled": "[ControlNet] 啟用",
  "[ControlNet] Model": "[ControlNet] 模型",
  "[ControlNet] Weight": "[ControlNet] 權重",
  "[ControlNet] Guidance Start": "[ControlNet] 引導開始",
  "[ControlNet] Guidance End": "[ControlNet] 引導結束",
  "[ControlNet] Resize Mode": "[ControlNet] 縮放模式",
  "[ControlNet] Preprocessor": "[ControlNet] 預處理器",
  "[ControlNet] Pre Resolution": "[ControlNet] 解析度",
  "[ControlNet] Pre Threshold A": "[ControlNet] 閾值 A",
  "[ControlNet] Pre Threshold B": "[ControlNet] 閾值 B",
  "Preprocessor Preview": "Preprocessor Preview",
  "Set the preprocessor to [invert] If your image has white background and black lines.": "如果您的線稿圖像是白色背景和黑色線條，請將預處理器設置為 [invert]。",
  "Enable": "啟用",
  "Low VRAM": "低 VRAM 模式",
  "Guess Mode": "猜測模式",
  "Allow Preview": "開啟預覽",
  "Preprocessor": "預處理器",
  "Model": "模型",
  "Control Weight": "Control Weight",
  "Starting Control Step": "Starting Control Step",
  "Ending Control Step": "Ending Control Step",
  "Preprocessor resolution": "Preprocessor resolution",
  "Threshold A": "閾值 A",
  "Threshold B": "閾值 B",
  "Resize Mode": "縮放模式",
  "Just Resize": "拉伸",
  "Crop and Resize": "裁剪並調整大小",
  "Resize and Fill": "調整大小並填充",
  "Drawing Canvas": "Drawing Canvas",
  "invert (from white bg & black line)": "invert (from white bg & black line)",
  "canny": "canny",
  "depth_leres": "depth_leres",
  "depth_midas": "depth_midas",
  "depth_zoe": "depth_zoe",
  "inpaint_global_harmonious": "inpaint_global_harmonious",
  "lineart_anime": "lineart_anime",
  "lineart_coarse": "lineart_coarse",
  "lineart_realistic": "lineart_realistic",
  "lineart_standard (from white bg & black line)": "lineart_standard (from white bg & black line)",
  "mediapipe_face": "mediapipe_face",
  "mlsd": "mlsd",
  "normal_bae": "normal_bae",
  "normal_midas": "normal_midas",
  "openpose": "openpose",
  "openpose_face": "openpose_face",
  "openpose_faceonly": "openpose_faceonly",
  "openpose_full": "openpose_full",
  "openpose_hand": "openpose_hand",
  "scribble_hed": "scribble_hed",
  "scribble_pidinet": "scribble_pidinet",
  "scribble_xdog": "scribble_xdog",
  "seg_ofade20k": "seg_ofade20k",
  "seg_ofcoco": "seg_ofcoco",
  "seg_ufade20k": "seg_ufade20k",
  "shuffle": "shuffle",
  "softedge_hed": "softedge_hed",
  "softedge_hedsafe": "softedge_hedsafe",
  "softedge_pidinet": "softedge_pidinet",
  "softedge_pidisafe": "softedge_pidisafe",
  "t2ia_color_grid": "t2ia_color_grid",
  "t2ia_sketch_pidi": "t2ia_sketch_pidi",
  "t2ia_style_clipvision": "t2ia_style_clipvision",
  "tile_gaussian": "tile_gaussian",
  "Canvas Width": "畫布寬度",
  "Canvas Height": "畫布高度",
  "Create blank canvas": "建立空白畫布",
  "sd-webui-depth-lib": "sd-webui-depth-lib",
  "Depth Library": "深度圖圖庫",
  "Pages:": "頁碼：",
  "Selected": "已選取",
  "Send to ControlNet": ">> ControlNet",
  "https://github.com/jexom/sd-webui-depth-lib.git": "https://github.com/jexom/sd-webui-depth-lib.git",
  "Highres. percentage chance": "高解析度修復：隨機機率",
  "Highres. Denoising Strength": "高解析度修復：重繪幅度",
  "Highres. Width": "高解析度修復：第一遍寬度",
  "Highres. Height": "高解析度修復：第一遍高度",
  "Stop at CLIP layers": "在 CLIP 模型的最後哪一層停下",
  "stable-diffusion-webui-randomize": "stable-diffusion-webui-randomize",
  "https://github.com/innightwolfsleep/stable-diffusion-webui-randomize.git": "https://github.com/innightwolfsleep/stable-diffusion-webui-randomize.git",
  "Comma separated list OR * for all": "以逗號分隔的列表或以 * 代表全部",
  "Range of stepped values (min, max, step)": "含步數的隨機範圍（最小，最大，步數）",
  "Float value from 0 to 1": "從 0 到 1 的浮點數數值",
  "Loads weights from checkpoint before making images. You can either use hash or a part of filename (as seen in settings) for checkpoint name. Recommended to use with Y axis for less switching.": "在生成圖像之前從模型權重存檔點中加載權重。你可以使用哈希值或檔案名的一部分（如設定中所示）作為模型權重存檔點名稱。建議用在Y軸上以減少過程中模型的切換",
  "Enabled": "啟用",
  "Unprompted Seed": "Unprompted Seed",
  "Functions": "Functions",
  "Select function:": "Select function:",
  "Options": "Options",
  "Example Function": "Example Function",
  "Enter a subject 🡢 subject": "Enter a subject 🡢 subject",
  "Add fluff terms? 🡢 use_fluff": "Add fluff terms? 🡢 use_fluff",
  "Auto-include this in prompt": "Auto-include this in prompt",
  "Generate Shortcode": "Generate Shortcode",
  "img2img folder": "img2img folder",
  "Image folder 🡢 folder": "Image folder 🡢 folder",
  "String to include before the filename 🡢 pre": "String to include before the filename 🡢 pre",
  "String to include after the filename 🡢 post": "String to include after the filename 🡢 post",
  "txt2img2img": "txt2img2img",
  "Subject A 🡢 subject_a": "Subject A 🡢 subject_a",
  "Subject B 🡢 subject_b": "Subject B 🡢 subject_b",
  "Shortcodes": "Shortcodes",
  "Select shortcode:": "Select shortcode:",
  "Content": "Content",
  "##": "##",
  "##: Houses a multiline comment that will not affect the final output.": "##: Houses a multiline comment that will not affect the final output.",
  "#": "#",
  "#: Houses a comment that does not affect your final prompt.": "#: Houses a comment that does not affect your final prompt.",
  "Comment 🡢 str": "Comment 🡢 str",
  "after": "after",
  "after: Processes arbitrary text following the main output.": "after: Processes arbitrary text following the main output.",
  "Order compared to other [after] blocks 🡢 int": "Order compared to other [after] blocks 🡢 int",
  "antonyms": "antonyms",
  "antonyms: Replaces the content with one or more antonyms.": "antonyms: Replaces the content with one or more antonyms.",
  "array": "array",
  "array: Manages a group or list of values.": "array: Manages a group or list of values.",
  "Name of array variable 🡢 str": "Name of array variable 🡢 str",
  "Get or set index statements 🡢 verbatim": "Get or set index statements 🡢 verbatim",
  "Custom delimiter string 🡢 _delimiter": "Custom delimiter string 🡢 _delimiter",
  "Shuffle the array 🡢 _shuffle": "Shuffle the array 🡢 _shuffle",
  "Prepend value(s) to the array 🡢 _prepend": "Prepend value(s) to the array 🡢 _prepend",
  "Append value(s) to the array 🡢 _append": "Append value(s) to the array 🡢 _append",
  "Delete value(s) from the array by index 🡢 _del": "Delete value(s) from the array by index 🡢 _del",
  "Removed specified value(s) from the array 🡢 _remove": "Removed specified value(s) from the array 🡢 _remove",
  "Find the first index of the following value(s) 🡢 _find": "Find the first index of the following value(s) 🡢 _find",
  "article": "article",
  "article: Returns the content with prefixed with a definite or indefinite article.": "article: Returns the content with prefixed with a definite or indefinite article.",
  "autocorrect": "autocorrect",
  "autocorrect: Attempts to correct the spelling of content.": "autocorrect: Attempts to correct the spelling of content.",
  "case": "case",
  "case: Use within [switch] to run different logic blocks depending on the value of a var.": "case: Use within [switch] to run different logic blocks depending on the value of a var.",
  "Matching value 🡢 str": "Matching value 🡢 str",
  "casing": "casing",
  "casing: Converts the casing of content.": "casing: Converts the casing of content.",
  "Casing method 🡢 str": "Casing method 🡢 str",
  "camelcase": "camelcase",
  "uppercase": "uppercase",
  "lowercase": "lowercase",
  "pascalcase": "pascalcase",
  "snakecase": "snakecase",
  "constcase": "constcase",
  "kebabcase": "kebabcase",
  "upperkebabcase": "upperkebabcase",
  "separatorcase": "separatorcase",
  "sentencecase": "sentencecase",
  "titlecase": "titlecase",
  "alphanumcase": "alphanumcase",
  "chance": "chance",
  "chance: Returns the content if the number you passed is greater than or equal to a random number between 1 and 100.": "chance: Returns the content if the number you passed is greater than or equal to a random number between 1 and 100.",
  "Highest possible roll 🡢 _sides": "Highest possible roll 🡢 _sides",
  "choose": "choose",
  "choose: Returns one of multiple options, delimited by newline or vertical pipe": "choose: Returns one of multiple options, delimited by newline or vertical pipe",
  "Number of times to choose 🡢 int": "Number of times to choose 🡢 int",
  "String delimiter when returning more than one choice 🡢 _sep": "String delimiter when returning more than one choice 🡢 _sep",
  "Custom weight per option 🡢 _weighted": "Custom weight per option 🡢 _weighted",
  "Override random nature of shortcode with predetermined outcome 🡢 _case": "Override random nature of shortcode with predetermined outcome 🡢 _case",
  "config": "config",
  "config: Updates your settings with the content for the duration of a run.": "config: Updates your settings with the content for the duration of a run.",
  "conjugate": "conjugate",
  "conjugate: Converts the content verb into another conjugated form.": "conjugate: Converts the content verb into another conjugated form.",
  "do": "do",
  "do: It's a do-until loop.": "do: It's a do-until loop.",
  "Until condition 🡢 until": "Until condition 🡢 until",
  "elif": "elif",
  "elif: Shorthand 'else-if.'": "elif: Shorthand 'else-if.'",
  "else": "else",
  "else: Returns content if a previous conditional shortcode failed its check, otherwise discards content.": "else: Returns content if a previous conditional shortcode failed its check, otherwise discards content.",
  "eval": "eval",
  "eval: Parses the content using the simpleeval library, returning the result. Particularly useful for arithmetic.": "eval: Parses the content using the simpleeval library, returning the result. Particularly useful for arithmetic.",
  "file": "file",
  "file: Processes the file content of 'path.'": "file: Processes the file content of 'path.'",
  "filelist": "filelist",
  "Filepath 🡢 str": "Filepath 🡢 str",
  "Expected encoding 🡢 _encoding": "Expected encoding 🡢 _encoding",
  "filelist: Returns a list of files at a given location using glob.": "filelist: Returns a list of files at a given location using glob.",
  "Result delimiter 🡢 _delimiter": "Result delimiter 🡢 _delimiter",
  "for": "for",
  "for: It's a for loop.": "for: It's a for loop.",
  "Set a variable 🡢 my_var": "Set a variable 🡢 my_var",
  "Conditional check 🡢 str": "Conditional check 🡢 str",
  "Operation to perform at the end step 🡢 str": "Operation to perform at the end step 🡢 str",
  "get": "get",
  "get: Returns the value of a variable.": "get: Returns the value of a variable.",
  "Variable to get 🡢 str": "Variable to get 🡢 str",
  "Default value if the variable doesn't exist 🡢 _default": "Default value if the variable doesn't exist 🡢 _default",
  "Separator string when returning multiple variables 🡢 _sep": "Separator string when returning multiple variables 🡢 _sep",
  "String to prepend to the variable 🡢 _before": "String to prepend to the variable 🡢 _before",
  "String to append to the variable 🡢 _after": "String to append to the variable 🡢 _after",
  "hypernyms": "hypernyms",
  "hypernyms: Replaces the content with one or more hypernyms.": "hypernyms: Replaces the content with one or more hypernyms.",
  "hyponyms": "hyponyms",
  "hyponyms: Replaces the content with one or more synonyms.": "hyponyms: Replaces the content with one or more synonyms.",
  "if": "if",
  "if: Checks whether a variable is equal to a given value.": "if: Checks whether a variable is equal to a given value.",
  "Conditional statement 🡢 my_var": "Conditional statement 🡢 my_var",
  "Evaluation method 🡢 _is": "Evaluation method 🡢 _is",
  "Invert evaluation such that a true statement will return false 🡢 _not": "Invert evaluation such that a true statement will return false 🡢 _not",
  "Return true if any one of multiple conditions are true 🡢 _any": "Return true if any one of multiple conditions are true 🡢 _any",
  "info": "info",
  "info: Returns various types of metadata about the content.": "info: Returns various types of metadata about the content.",
  "Return the character count 🡢 character_count": "Return the character count 🡢 character_count",
  "Return the word count 🡢 word_count": "Return the word count 🡢 word_count",
  "Return the sentence count 🡢 sentence_count": "Return the sentence count 🡢 sentence_count",
  "Return the filename 🡢 filename": "Return the filename 🡢 filename",
  "Return the CLIP token count (prompt complexity) 🡢 clip_count": "Return the CLIP token count (prompt complexity) 🡢 clip_count",
  "Return the count of a custom substring 🡢 string_count": "Return the count of a custom substring 🡢 string_count",
  "length": "length",
  "length: Returns the number of items in a delimited string.": "length: Returns the number of items in a delimited string.",
  "The string to evaluate 🡢 str": "The string to evaluate 🡢 str",
  "Delimiter to check for 🡢 _delimiter": "Delimiter to check for 🡢 _delimiter",
  "Maximum number to be returned 🡢 _max": "Maximum number to be returned 🡢 _max",
  "max": "max",
  "max: Returns the maximum value among the given arguments.": "max: Returns the maximum value among the given arguments.",
  "min": "min",
  "min: Returns the minimum value among the given arguments.": "min: Returns the minimum value among the given arguments.",
  "override": "override",
  "override: Force variable(s) to hold a pre-determined value the rest of the run.": "override: Force variable(s) to hold a pre-determined value the rest of the run.",
  "Arguments in variable=value format 🡢 verbatim": "Arguments in variable=value format 🡢 verbatim",
  "pluralize": "pluralize",
  "pluralize: Converts the content into plural form.": "pluralize: Converts the content into plural form.",
  "random: Returns a random number between 0 and a given max value (inclusive)": "random: Returns a random number between 0 and a given max value (inclusive)",
  "Minimum number 🡢 _min": "Minimum number 🡢 _min",
  "Maximum number 🡢 _max": "Maximum number 🡢 _max",
  "Evaluate as floats instead of integers 🡢 _float": "Evaluate as floats instead of integers 🡢 _float",
  "repeat": "repeat",
  "repeat: Returns the content an arbitrary number of times.": "repeat: Returns the content an arbitrary number of times.",
  "Number of times to repeat the content 🡢 int": "Number of times to repeat the content 🡢 int",
  "Delimiter string between outputs 🡢 _sep": "Delimiter string between outputs 🡢 _sep",
  "replace": "replace",
  "replace: Updates a string using the arguments for replacement logic.": "replace: Updates a string using the arguments for replacement logic.",
  "Arbitrary replacement arguments in old=new format 🡢 verbatim": "Arbitrary replacement arguments in old=new format 🡢 verbatim",
  "Original value, with advanced expression support 🡢 _from": "Original value, with advanced expression support 🡢 _from",
  "New value, with advanced expression support 🡢 _to": "New value, with advanced expression support 🡢 _to",
  "Maximum number of times the replacement may occur 🡢 _count": "Maximum number of times the replacement may occur 🡢 _count",
  "set": "set",
  "set: Stores a value into a given variable.": "set: Stores a value into a given variable.",
  "Variable name 🡢 verbatim": "Variable name 🡢 verbatim",
  "Only set this variable if it doesn't already exist 🡢 _new": "Only set this variable if it doesn't already exist 🡢 _new",
  "Array of valid values (used in conjunction with _new) 🡢 _choices": "Array of valid values (used in conjunction with _new) 🡢 _choices",
  "Append the content to the variable's current value 🡢 _append": "Append the content to the variable's current value 🡢 _append",
  "Prepend the content to the variable's current value 🡢 _prepend": "Prepend the content to the variable's current value 🡢 _prepend",
  "Print the variable's value 🡢 _out": "Print the variable's value 🡢 _out",
  "sets": "sets",
  "sets: The atomic version of [set] that lets you set multiple variables at once.": "sets: The atomic version of [set] that lets you set multiple variables at once.",
  "Arbitrary arguments in variable=value format 🡢 verbatim": "Arbitrary arguments in variable=value format 🡢 verbatim",
  "singularize": "singularize",
  "singularize: Converts the content into singular form.": "singularize: Converts the content into singular form.",
  "substring: Slices up the content.": "substring: Slices up the content.",
  "Beginning index of the substring 🡢 start": "Beginning index of the substring 🡢 start",
  "Ending index of the substring 🡢 end": "Ending index of the substring 🡢 end",
  "Step size 🡢 step": "Step size 🡢 step",
  "Unit type 🡢 unit": "Unit type 🡢 unit",
  "characters": "characters",
  "words": "words",
  "switch": "switch",
  "switch: Use in conjunction with [case] to run different logic blocks depending on the value of a var.": "switch: Use in conjunction with [case] to run different logic blocks depending on the value of a var.",
  "Variable to test against 🡢 verbatim": "Variable to test against 🡢 verbatim",
  "synonyms": "synonyms",
  "synonyms: Replaces the content with one or more synonyms.": "synonyms: Replaces the content with one or more synonyms.",
  "template: This is used by the Wizard to instantiate a custom template UI. It is bypassed by the normal shortcode parser.": "template: This is used by the Wizard to instantiate a custom template UI. It is bypassed by the normal shortcode parser.",
  "unset": "unset",
  "unset: Removes one or more variables from memory. Generally not needed.": "unset: Removes one or more variables from memory. Generally not needed.",
  "Arbitrary variable names to free from memory 🡢 verbatim": "Arbitrary variable names to free from memory 🡢 verbatim",
  "while": "while",
  "while: Loops content until the condition returns false.": "while: Loops content until the condition returns false.",
  "Arbitrary conditional statement(s) to test against 🡢 verbatim": "Arbitrary conditional statement(s) to test against 🡢 verbatim",
  "Invert evaluation such that a false condition will end the loop 🡢 _not": "Invert evaluation such that a false condition will end the loop 🡢 _not",
  "controlnet": "controlnet",
  "controlnet: A neural network structure to control diffusion models by adding extra conditions. Check manual for setup info.": "controlnet: A neural network structure to control diffusion models by adding extra conditions. Check manual for setup info.",
  "Model name (do not include extension) 🡢 model": "Model name (do not include extension) 🡢 model",
  "Resolution of the detection map 🡢 detect_resolution": "Resolution of the detection map 🡢 detect_resolution",
  "Use low VRAM mode? 🡢 save_memory": "Use low VRAM mode? 🡢 save_memory",
  "DDIM ETA 🡢 eta": "DDIM ETA 🡢 eta",
  "Value Threshold 🡢 value_threhsold": "Value Threshold 🡢 value_threhsold",
  "Distance Threshold 🡢 distance_threhsold": "Distance Threshold 🡢 distance_threhsold",
  "Background Threshold 🡢 bg_threhsold": "Background Threshold 🡢 bg_threhsold",
  "Canny low threshold 🡢 low_threshold": "Canny low threshold 🡢 low_threshold",
  "Canny high threshold 🡢 high_threshold": "Canny high threshold 🡢 high_threshold",
  "Render hands with Openpose? 🡢 openpose_hands": "Render hands with Openpose? 🡢 openpose_hands",
  "enable_multi_images": "enable_multi_images",
  "enable_multi_images: Allows to use multiple init_images or multiple masks": "enable_multi_images: Allows to use multiple init_images or multiple masks",
  "file2mask": "file2mask",
  "file2mask: Modify or replace your img2img mask with arbitrary files.": "file2mask: Modify or replace your img2img mask with arbitrary files.",
  "Path to image file 🡢 str": "Path to image file 🡢 str",
  "Mask blend mode 🡢 mode": "Mask blend mode 🡢 mode",
  "add": "add",
  "subtract": "subtract",
  "discard": "discard",
  "Show mask in output 🡢 show": "Show mask in output 🡢 show",
  "img2img: Runs an img2img task inside of an [after] block.": "img2img: Runs an img2img task inside of an [after] block.",
  "img2img_autosize": "img2img_autosize",
  "img2img_autosize: Automatically adjusts the width and height parameters in img2img mode based on the proportions of the input image.": "img2img_autosize: Automatically adjusts the width and height parameters in img2img mode based on the proportions of the input image.",
  "Minimum pixels of at least one dimension 🡢 target": "Minimum pixels of at least one dimension 🡢 target",
  "Only run this shortcode if using full resolution inpainting mode 🡢 only_full_res": "Only run this shortcode if using full resolution inpainting mode 🡢 only_full_res",
  "img2pez": "img2pez",
  "img2pez: Optimize a hard prompt using the PEZ algorithm and CLIP encoders, AKA Hard Prompts Made Easy.": "img2pez: Optimize a hard prompt using the PEZ algorithm and CLIP encoders, AKA Hard Prompts Made Easy.",
  "Image path 🡢 image_path": "Image path 🡢 image_path",
  "Prompt length 🡢 prompt_length": "Prompt length 🡢 prompt_length",
  "Iterations 🡢 iterations": "Iterations 🡢 iterations",
  "Learning rate 🡢 learning_rate": "Learning rate 🡢 learning_rate",
  "Weight decay 🡢 weight_decay": "Weight decay 🡢 weight_decay",
  "Prompt bs (well, that's what they call it) 🡢 prompt_bs": "Prompt bs (well, that's what they call it) 🡢 prompt_bs",
  "CLIP model 🡢 clip_model": "CLIP model 🡢 clip_model",
  "ViT-L-14": "ViT-L-14",
  "ViT-H-14": "ViT-H-14",
  "CLIP pretrain 🡢 clip_pretrain": "CLIP pretrain 🡢 clip_pretrain",
  "openai": "openai",
  "laion2b_s32b_b79k": "laion2b_s32b_b79k",
  "Try freeing CLIP model from memory? 🡢 free_memory": "Try freeing CLIP model from memory? 🡢 free_memory",
  "init_image": "init_image",
  "init_image: Loads an image from the given path and sets it as the initial image for use with img2img.": "init_image: Loads an image from the given path and sets it as the initial image for use with img2img.",
  "Image path": "Image path",
  "instance2mask": "instance2mask",
  "instance2mask: Creates an image mask from instances of types specified by the content for use with inpainting.": "instance2mask: Creates an image mask from instances of types specified by the content for use with inpainting.",
  "refine": "refine",
  "Run inpaint per instance found 🡢 per_instance": "Run inpaint per instance found 🡢 per_instance",
  "Precision of selected area 🡢 mask_precision": "Precision of selected area 🡢 mask_precision",
  "Padding radius in pixels 🡢 padding": "Padding radius in pixels 🡢 padding",
  "Smoothing radius in pixels 🡢 smoothing": "Smoothing radius in pixels 🡢 smoothing",
  "Precision of instance selection 🡢 instance_precision": "Precision of instance selection 🡢 instance_precision",
  "Number of instance to select 🡢 select": "Number of instance to select 🡢 select",
  "Instance selection mode 🡢 select_mode": "Instance selection mode 🡢 select_mode",
  "overlap": "overlap",
  "relative overlap": "relative overlap",
  "greatest area": "greatest area",
  "invert_mask": "invert_mask",
  "invert_mask: Inverts the mask (great in combination with multiple txt2masks)": "invert_mask: Inverts the mask (great in combination with multiple txt2masks)",
  "pix2pix_zero": "pix2pix_zero",
  "pix2pix_zero: A diffusion-based image-to-image approach that allows users to specify the edit direction on-the-fly.": "pix2pix_zero: A diffusion-based image-to-image approach that allows users to specify the edit direction on-the-fly.",
  "txt2mask": "txt2mask",
  "Use legacy weights 🡢 legacy_weights": "Use legacy weights 🡢 legacy_weights",
  "Precision of selected area 🡢 precision": "Precision of selected area 🡢 precision",
  "Negative mask prompt 🡢 negative_mask": "Negative mask prompt 🡢 negative_mask",
  "Negative mask precision of selected area 🡢 neg_precision": "Negative mask precision of selected area 🡢 neg_precision",
  "Negative mask padding radius in pixels 🡢 neg_padding": "Negative mask padding radius in pixels 🡢 neg_padding",
  "Negative mask smoothing radius in pixels 🡢 neg_smoothing": "Negative mask smoothing radius in pixels 🡢 neg_smoothing",
  "Mask color, enables Inpaint Sketch mode 🡢 sketch_color": "Mask color, enables Inpaint Sketch mode 🡢 sketch_color",
  "Mask alpha, must be used in conjunction with mask color 🡢 sketch_alpha": "Mask alpha, must be used in conjunction with mask color 🡢 sketch_alpha",
  "Save the mask size to the following variable 🡢 size_var": "Save the mask size to the following variable 🡢 size_var",
  "zoom_enhance": "zoom_enhance",
  "zoom_enhance: Upscales a selected portion of the image. ENHANCE!": "zoom_enhance: Upscales a selected portion of the image. ENHANCE!",
  "Final image not showing up? Try using this workaround 🡢 use_workaround": "Final image not showing up? Try using this workaround 🡢 use_workaround",
  "Mask to find 🡢 mask": "Mask to find 🡢 mask",
  "Replacement 🡢 replacement": "Replacement 🡢 replacement",
  "Negative replacement 🡢 negative_replacement": "Negative replacement 🡢 negative_replacement",
  "Mask sorting method 🡢 mask_sort_method": "Mask sorting method 🡢 mask_sort_method",
  "left-to-right": "left-to-right",
  "right-to-left": "right-to-left",
  "top-to-bottom": "top-to-bottom",
  "bottom-to-top": "bottom-to-top",
  "big-to-small": "big-to-small",
  "small-to-big": "small-to-big",
  "unsorted": "unsorted",
  "Blur edges size 🡢 blur_size": "Blur edges size 🡢 blur_size",
  "Minimum CFG scale 🡢 cfg_scale_min": "Minimum CFG scale 🡢 cfg_scale_min",
  "Maximum denoising strength 🡢 denoising_max": "Maximum denoising strength 🡢 denoising_max",
  "Maximum mask size (if a bigger mask is found, it will bypass the shortcode) 🡢 mask_size_max": "Maximum mask size (if a bigger mask is found, it will bypass the shortcode) 🡢 mask_size_max",
  "Force denoising strength to this value 🡢 denoising_strength": "Force denoising strength to this value 🡢 denoising_strength",
  "Force CFG scale to this value 🡢 cfg_scale": "Force CFG scale to this value 🡢 cfg_scale",
  "Mask minimum number of pixels 🡢 min_area": "Mask minimum number of pixels 🡢 min_area",
  "Contour padding in pixels 🡢 contour_padding": "Contour padding in pixels 🡢 contour_padding",
  "Upscale width 🡢 upscale_width": "Upscale width 🡢 upscale_width",
  "Upscale height 🡢 upscale_height": "Upscale height 🡢 upscale_height",
  "Include original image in output window 🡢 include_original": "Include original image in output window 🡢 include_original",
  "Save debug images to WebUI folder 🡢 save": "Save debug images to WebUI folder 🡢 save",
  "Test prompt": "測試提示詞",
  "Process Text": "Process Text",
  "Re-process extra networks after Unprompted is finished (WIP - this is not yet functional!)": "Re-process extra networks after Unprompted is finished (WIP - this is not yet functional!)",
  "unprompted": "unprompted",
  "https://github.com/ThereforeGames/unprompted.git": "https://github.com/ThereforeGames/unprompted.git",
  "Multiplication (2^N)": "倍率 (2^N)",
  "Weight": "權重",
  "Force convert half to float on interpolation (for some platforms)": "在插值時強制將一半賺換為浮點（對於某些平台）",
  "I know what I am doing.": "我知道我在做什麼。",
  "Layers": "圖層",
  "Apply to": "Apply to",
  "Resblock": "Resblock",
  "Transformer": "Transformer",
  "S. Attn.": "S. Attn.",
  "X. Attn.": "X. Attn.",
  "OUT": "OUT",
  "Start steps": "Start steps",
  "Bilinear": "Bilinear",
  "Bicubic": "Bicubic",
  "Enable AA for Upscaling.": "Enable AA for Upscaling.",
  "Downscaling": "Downscaling",
  "Area": "Area",
  "Pooling Max": "Pooling Max",
  "Pooling Avg": "Pooling Avg",
  "Enable AA for Downscaling.": "Enable AA for Downscaling.",
  "interpolation method": "interpolation method",
  "Lerp": "Lerp",
  "SLerp": "SLerp",
  "LLuL Enabled": "LLuL Enabled",
  "LLuL Multiply": "LLuL Multiply",
  "LLuL Weight": "LLuL Weight",
  "LLuL Layers": "LLuL Layers",
  "LLuL Apply to": "LLuL Apply to",
  "LLuL Start steps": "LLuL Start steps",
  "LLuL Max steps": "LLuL Max steps",
  "LLuL Upscaler": "LLuL Upscaler",
  "LLuL Upscaler AA": "LLuL Upscaler AA",
  "LLuL Downscaler": "LLuL Downscaler",
  "LLuL Downscaler AA": "LLuL Downscaler AA",
  "LLuL Interpolation method": "LLuL Interpolation method",
  "sd-webui-llul": "sd-webui-llul",
  "https://github.com/hnmr293/sd-webui-llul.git": "https://github.com/hnmr293/sd-webui-llul.git",
  "✕": "✕",
  "[NPW] Weight": "[NPW] 權重",
  "stable-diffusion-NPW": "stable-diffusion-NPW",
  "https://github.com/muerrilla/stable-diffusion-NPW": "https://github.com/muerrilla/stable-diffusion-NPW",
  "Embedding Editor": "嵌入編輯器",
  "Vector": "向量",
  "Refresh Embeddings": "重新整理多個嵌入",
  "Save Embedding": "儲存嵌入",
  "Enter words and color hexes to mark weights on the sliders for guidance. Hint: Use the txt2img prompt token counter or": "輸入文字和顏色十六進制代碼以在滑桿上標記權重作為引導。 提示：使用文生圖提示詞標記計數器或使用",
  "webui-tokenizer": "標記解析器擴充功能",
  "to see which words are constructed using multiple sub-words, e.g. 'computer' doesn't exist in stable diffusion's CLIP dictionary and instead 'compu' and 'ter' are used (1 word but 2 embedding vectors). Currently buggy and needs a moment to process before pressing the button. If it doesn't work after a moment, try adding a random space to refresh it.": "查看哪些詞是使用多個子詞構成的，例如 Stable Diffusion 的 CLIP 字典中不存在 'computer'，而是使用 'compu' 以及 'ter'（一個單字但使用兩個嵌入向量）。目前這個擴充功能還有點問題，在按下按鈕之前需要一點時間來處理。如果過了一段時間還是不行，試試隨便加個空格重新整理一下",
  "Sampling Steps": "採樣疊代步數",
  "Generate Preview": "產生預覽",
  "stable-diffusion-webui-embedding-editor": "stable-diffusion-webui-embedding-editor",
  "https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor.git": "https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor.git",
  "symbol:color-hex, symbol:color-hex, ...": "文字:顏色代碼, 文字:顏色代碼, ...",
  "e.g. A portrait photo of embedding_name": "示例： A portrait photo of embedding_name",
  "Load Settings": "載入設定",
  "Save Settings": "儲存設定",
  "Generate Ckpt": "產生 Ckpt",
  "Save Weights": "儲存權重",
  "Generate Samples": "產生樣本",
  "Cancel": "取消",
  "Select or create a model to begin.": "選擇或建立一個模型",
  "Select": "選擇模型",
  "Create": "建立",
  "Snapshot to Resume": "從 Snapshot 恢復",
  "Lora Model": "LoRA 模型",
  "Loaded Model:": "載入模型：",
  "Model Revision:": "模型修正：",
  "Model Epoch:": "模型訓練週期：",
  "V2 Model:": "V2 模型：",
  "Has EMA:": "有 EMA：",
  "Source Checkpoint:": "來源模型權重存檔點：",
  "Create Model": "建立模型",
  "Create From Hub": "從 huggingface 建立",
  "512x Model": "512x 模型",
  "Model Path": "模型路徑",
  "HuggingFace Token": "HuggingFace 標記",
  "Source Checkpoint": "源模型權重存檔點",
  "Extract EMA Weights": "提取 EMA 權重",
  "Unfreeze Model": "解凍模型",
  "Resources": "Resources",
  "Beginners guide": "Beginners guide",
  "Release notes": "發布說明",
  "Input": "輸入",
  "Concepts": "概念",
  "Saving": "儲存",
  "Testing": "測試",
  "Performance Wizard (WIP)": "效能嚮導（半成品）",
  "Basic": "基本設定",
  "General": "一般的",
  "Use LORA": "使用 LoRA",
  "Use Lora Extended": "使用 LoRA 擴充功能（Locon）",
  "Train Imagic Only": "僅意象訓練",
  "Train Inpainting Model": "訓練局部重繪模型",
  "Intervals": "訓練週期 / 間隔",
  "Training Steps Per Image (Epochs)": "每張圖像的訓練步數（訓練週期）",
  "Pause After N Epochs": "N 階段後暫停",
  "Amount of time to pause between Epochs (s)": "每訓練週期之間暫停的時間（秒）",
  "Save Model Frequency (Epochs)": "儲存模型頻率（訓練週期）",
  "Save Preview(s) Frequency (Epochs)": "儲存預覽頻率（訓練週期）",
  "Batching": "批次",
  "Batch Size": "每批數量",
  "Gradient Accumulation Steps": "梯度累積疊代步數",
  "Class Batch Size": "類別每批數量",
  "Set Gradients to None When Zeroing": "將梯度設定為 0 的時候設定為無",
  "Gradient Checkpointing": "梯度進度記錄 - 以時間換顯存",
  "Learning Rate": "學習率",
  "Lora UNET Learning Rate": "LoRA UNET 學習率",
  "Lora Text Encoder Learning Rate": "LoRA Text Encoder 學習率",
  "Learning Rate Scheduler": "學習率調度器",
  "linear_with_warmup": "linear_with_warmup",
  "cosine": "餘弦（cosine）",
  "cosine_annealing": "cosine_annealing",
  "cosine_annealing_with_restarts": "cosine_annealing_with_restarts",
  "cosine_with_restarts": "含重啟的餘弦（cosine）",
  "polynomial": "多項式（polynomial）",
  "constant": "常數（constant）",
  "constant_with_warmup": "含預熱的常數（constant）",
  "Min Learning Rate": "最小學習率",
  "Number of Hard Resets": "硬重置數量",
  "Constant/Linear Starting Factor": "常數/線性起始因子",
  "Polynomial Power": "多項式功率",
  "Scale Position": "比例位置",
  "Learning Rate Warmup Steps": "學習率預熱步數",
  "Image Processing": "圖像處理",
  "Max Resolution": "最高解析度",
  "Apply Horizontal Flip": "套用水平翻轉",
  "Tuning": "調整",
  "Use EMA": "使用 EMA",
  "Optimizer": "優化器",
  "Torch AdamW": "Torch AdamW",
  "8bit AdamW": "8bit AdamW",
  "Lion": "Lion",
  "Mixed Precision": "混合精度",
  "no": "否",
  "fp16": "fp16",
  "Memory Attention": "記憶體注意力",
  "default": "default",
  "Cache Latents": "快取潛在變數",
  "Train UNET": "訓練 UNET",
  "Step Ratio of Text Encoder Training": "文字編碼器訓練步驟比率",
  "Offset Noise": "噪聲偏移",
  "Freeze CLIP Normalization Layers": "凍結 CLIP 正規化層",
  "Clip Skip": "Clip 跳過層",
  "Weight Decay": "權重衰減",
  "Pad Tokens": "填充標記",
  "Strict Tokens": "嚴格的提詞",
  "Shuffle Tags": "洗牌標籤",
  "Max Token Length": "最大標記長度",
  "Prior Loss": "先前的損失",
  "Scale Prior Loss": "縮放先前的損失",
  "Prior Loss Weight": "先前損失權重",
  "Prior Loss Target": "先前損失目標",
  "Minimum Prior Loss Weight": "最小先前損失權重",
  "Advanced": "進階的",
  "Sanity Sample Prompt": "樣本提示詞",
  "Sanity Sample Negative Prompt": "樣本反向提示詞",
  "Sanity Sample Seed": "樣本種子",
  "Miscellaneous": "雜項",
  "Pretrained VAE Name or Path": "預訓練 VAE 名稱或路徑",
  "Use Concepts List": "使用概念列表",
  "Concepts List": "概念列表",
  "API Key": "API 金鑰",
  "Discord Webhook": "Discord Webhook",
  "Save and Test Webhook": "儲存並測試 Webhook",
  "Training Wizard (Person)": "訓練嚮導（人物）",
  "Training Wizard (Object/Style)": "訓練嚮導（物件 / 樣式）",
  "Concept 1": "概念 1",
  "Concept 2": "概念 2",
  "Concept 3": "概念 3",
  "Concept 4": "概念 4",
  "Directories": "目錄",
  "Dataset Directory": "實例圖像數據目錄",
  "Classification Dataset Directory": "類別/正則數據集目錄",
  "Filewords": "風格 / 物品名稱",
  "Instance Token": "實例名稱",
  "Class Token": "類別/正則名稱",
  "Training Prompts": "訓練提示詞",
  "Instance Prompt": "實例提示詞",
  "Class Prompt": "類別/正則提示詞",
  "Classification Image Negative Prompt": "類別(正則) 圖像反向提示詞",
  "Sample Prompts": "樣本提示詞",
  "Sample Image Prompt": "樣本圖像提示詞",
  "Sample Negative Prompt": "樣本反向提詞",
  "Sample Prompt Template File": "樣本提示詞範本檔案",
  "Class Image Generation": "生成類別(正則) 圖像",
  "Class Images Per Instance Image": "每個實例圖像的類別(正則) 圖片數量",
  "Classification CFG Scale": "類別(正則) CFG比例",
  "Classification Steps": "類別(正則) 步驟",
  "Sample Image Generation": "生成樣本圖像",
  "Number of Samples to Generate": "產生樣本的數量",
  "Sample Seed": "樣本種子",
  "Sample CFG Scale": "樣本CFG比例",
  "Sample Steps": "樣本步數",
  "Custom Model Name": "自定義模型名稱",
  "Save in .safetensors format": "以 .safetensors 格式保存",
  "Save EMA Weights to Generated Models": "將 EMA 權重儲存到產生的模型中",
  "Use EMA Weights for Inference": "使用EMA權重進行推論",
  "Half Model": "半精度模型",
  "Save Checkpoint to Subdirectory": "保存檢查點到子目錄",
  "Generate a .ckpt file when saving during training.": "在訓練期間儲存時產生 .ckpt 文件。",
  "Generate a .ckpt file when training completes.": "在訓練完成時產生 .ckpt 文件。",
  "Generate a .ckpt file when training is canceled.": "在訓練取消時產生 .ckpt 文件。",
  "Lora UNET Rank": "LoRA UNET等級",
  "Lora Text Encoder Rank": "LoRA 文字編碼器等級",
  "Lora Weight": "LoRA 權重",
  "Lora Text Weight": "LoRA 文本權重",
  "Generate lora weights when saving during training.": "在訓練期間儲存時產生 LoRA。",
  "Generate lora weights when training completes.": "在訓練完成時產生 LoRA。",
  "Generate lora weights when training is canceled.": "在訓練取消時產生 LoRA。",
  "Generate lora weights for extra networks.": "產生附加網路的 LoRA。（警告：如有使用 LoCon功能，需先安裝擴充。）",
  "Diffusion Weights (training snapshots)": "Diffusion Weights (training snapshots)",
  "Save separate diffusers snapshots when saving during training.": "在訓練期間保存獨立的模型。",
  "Save separate diffusers snapshots when training completes.": "訓練完成後保存獨立的模型。",
  "Save separate diffusers snapshots when training is canceled.": "當訓練被取消時保存獨立的模型。",
  "Class Generation Schedulers": "類別(正則) 圖像生成調度器",
  "Image Generation Library": "圖像生成",
  "A1111 txt2img (Euler a)": "A1111 txt2img (Euler a)",
  "Native Diffusers": "Native Diffusers",
  "Image Generation Scheduler": "圖像生成採樣方式",
  "DDPM": "DDPM",
  "PNDM": "PNDM",
  "LMSDiscrete": "LMSDiscrete",
  "EulerDiscrete": "EulerDiscrete",
  "HeunDiscrete": "HeunDiscrete",
  "EulerAncestralDiscrete": "EulerAncestralDiscrete",
  "DPMSolverMultistep": "DPMSolverMultistep",
  "DPMSolverSinglestep": "DPMSolverSinglestep",
  "KDPM2Discrete": "KDPM2Discrete",
  "KDPM2AncestralDiscrete": "KDPM2AncestralDiscrete",
  "DEISMultistep": "DEISMultistep",
  "UniPCMultistep": "UniPCMultistep",
  "Manual Class Generation": "Manual Class Generation",
  "Generate Class Images": "產生類別(正則) 圖片",
  "Generate Graph": "產生圖形",
  "Graph Smoothing Steps": "圖形平滑步驟",
  "Debug Buckets": "除錯",
  "Epochs to Simulate": "要模擬的訓練週期",
  "Batch Size to Simulate": "模擬的批量大小",
  "Generate Sample Images": "產生樣本圖像",
  "Sample Prompt": "樣本提詞",
  "Sample Prompt File": "樣本提示文件",
  "Sample Width": "樣本寬度",
  "Sample Height": "樣本高度",
  "Sample Batch Size": "樣本批次大小",
  "Swap Sample Faces": "交換 Sample Faces",
  "Swap Prompt": "交換提示詞",
  "Swap Negative Prompt": "交換反向提示詞",
  "Swap Steps": "交換疊代步數",
  "Swap Batch": "交換批次",
  "Use txt2img": "使用文生圖",
  "Experimental Settings": "實驗性設定",
  "Deterministic": "確定性的訓練",
  "Use EMA for prediction": "使用 EMA 進行預測",
  "Calculate Split Loss": "計算分割損失",
  "Use TensorFloat 32": "使用TensorFloat 32",
  "Noise scheduler": "Noise scheduler",
  "DEIS": "DEIS",
  "Update Extension and Restart": "更新擴充並重新啟動",
  "Bucket Cropping": "批量裁剪",
  "Source Path": "來源路徑",
  "Dest Path": "目標路徑",
  "Max Res": "最大解析度",
  "Bucket Steps": "批量Steps",
  "Dry Run": "空運行",
  "Start Cropping": "開始裁剪",
  "Output": "輸出",
  "Checkbox": "核取方塊",
  "Check Progress": "查看進度",
  "Update Parameters": "更新參數",
  "Changelog": "更新紀錄",
  "X": "X",
  "sd_dreambooth_extension": "sd_dreambooth_extension",
  "https://github.com/d8ahazard/sd_dreambooth_extension.git": "https://github.com/d8ahazard/sd_dreambooth_extension.git",
  "runwayml/stable-diffusion-v1-5": "runwayml/stable-diffusion-v1-5",
  "A generic prompt used to generate a sample image to verify model fidelity.": "用於產生樣本圖像以驗證模型保真度的通用提示。",
  "A negative prompt for the generic sample image.": "通用圖像的反向提示詞。",
  "Leave blank to use base model VAE.": "留空以使用基本模型 VAE。",
  "Path to JSON file with concepts to train.": "帶有要訓練概念的 JSON 檔案的路徑。",
  "https://discord.com/api/webhooks/XXX/XXXX": "https://discord.com/api/webhooks/XXX/XXXX",
  "(Optional) Path to directory with classification/regularization images": "（可選）帶有類別(正則) 圖像的目錄路徑",
  "When using [filewords], this is the subject to use when building prompts.": "使用 [filewords] 時，構建提示時使用的主題。",
  "When using [filewords], this is the class to use when building prompts.": "使用 [filewords] 時，構建提示時使用的類別(正則)。",
  "Optionally use [filewords] to read image captions from files.": "可以選擇使用 [filewords] 從檔案中讀取圖像標題。",
  "Leave blank to use instance prompt. Optionally use [filewords] to base sample captions on instance images.": "留空以使用實例提示。可以選擇使用 [filewords] 以實例圖像為基礎生成樣本標題。",
  "Enter the path to a txt file containing sample prompts.": "輸入包含樣本提示的 txt 檔案的路徑。",
  "Enter a model name for saving checkpoints and lora models.": "輸入模型名稱以保存檢查點和 lora 模型。",
  "Create aesthetic embedding": "建立美學嵌入",
  "Open for Clip Aesthetic!": "打開以調整 CLIP 美學！",
  "Aesthetic weight": "美學權重",
  "Aesthetic steps": "美術風格疊代步數",
  "Aesthetic learning rate": "美學學習率",
  "Slerp interpolation": "球面線性插值角度",
  "Aesthetic imgs embedding": "美學圖集嵌入",
  "Aesthetic text for imgs": "該圖集的美學描述",
  "Slerp angle": "球面線性插值角度",
  "Is negative text": "是反向提示詞",
  "Create an aesthetic embedding out of any number of images": "從任意數量的圖像中建立美學嵌入",
  "Create images embedding": "建立圖集嵌入",
  "stable-diffusion-webui-aesthetic-gradients": "stable-diffusion-webui-aesthetic-gradients",
  "This text is used to rotate the feature space of the imgs embs": "此文本用於旋轉圖集嵌入的特徵空間",
  "https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git",
  "State": "State",
  "Saved main elements": "Saved main elements",
  "tabs": "tabs",
  "Saved elements from txt2img": "Saved elements from txt2img",
  "prompt": "提示詞",
  "negative_prompt": "反相提示詞",
  "sampling": "sampling",
  "sampling_steps": "sampling_steps",
  "width": "寬度",
  "height": "高度",
  "batch_count": "生成批次",
  "batch_size": "每批數量",
  "cfg_scale": "提示詞相關性（CFG）",
  "seed": "種子",
  "restore_faces": "面部修復",
  "tiling": "可平鋪",
  "hires_fix": "高解析度修正",
  "hires_upscaler": "高解析度放大工具",
  "hires_steps": "高解析步驟",
  "hires_scale": "hires_scale",
  "hires_resize_x": "hires_resize_x",
  "hires_resize_y": "hires_resize_y",
  "hires_denoising_strength": "高解析度修正重繪幅度",
  "Saved elements from img2img": "Saved elements from img2img",
  "resize_mode": "縮放模式",
  "denoising_strength": "重繪幅度",
  "https://github.com/ilian6806/stable-diffusion-webui-state.git": "https://github.com/ilian6806/stable-diffusion-webui-state.git",
  "This extension works well with text captions in comma-separated style (such as the tags generated by DeepBooru interrogator).": "This extension works well with text captions in comma-separated style (such as the tags generated by DeepBooru interrogator).",
  "Save all changes": "Save all changes",
  "Backup original text file (original file will be renamed like filename.000, .001, .002, ...)": "Backup original text file (original file will be renamed like filename.000, .001, .002, ...)",
  "Note:": "Note:",
  "New text file will be created if you are using filename as captions.": "New text file will be created if you are using filename as captions.",
  "Use kohya-ss's finetuning metadata json": "Use kohya-ss's finetuning metadata json",
  "json path": "json path",
  "json input path (Optional, only for append results)": "json input path (Optional, only for append results)",
  "Overwrite if output file exists": "Overwrite if output file exists",
  "Save metadata as caption": "Save metadata as caption",
  "Save metadata image key as fullpath": "Save metadata image key as fullpath",
  "Results": "Results",
  "Reload/Save Settings (config.json)": "Reload/Save Settings (config.json)",
  "Reload settings": "Reload settings",
  "Save current settings": "Save current settings",
  "Restore settings to default": "Restore settings to default",
  "Caption File Ext": "Caption File Ext",
  "Load": "載入",
  "Unload": "Unload",
  "Dataset Load Settings": "Dataset Load Settings",
  "Load from subdirectories": "Load from subdirectories",
  "Load caption from filename if no text file exists": "Load caption from filename if no text file exists",
  "Replace new-line character with comma": "Replace new-line character with comma",
  "Use Interrogator Caption": "Use Interrogator Caption",
  "No": "No",
  "If Empty": "If Empty",
  "Overwrite": "Overwrite",
  "Prepend": "Prepend",
  "Append": "Append",
  "Interrogators": "Interrogators",
  "Interrogator Settings": "Interrogator Settings",
  "Use Custom Threshold (Booru)": "Use Custom Threshold (Booru)",
  "Booru Score Threshold": "Booru Score Threshold",
  "Use Custom Threshold (WDv1.4 Tagger)": "Use Custom Threshold (WDv1.4 Tagger)",
  "WDv1.4 Tagger Score Threshold": "WDv1.4 Tagger Score Threshold",
  "Dataset Filter": "Dataset Filter",
  "Filter Apply": "套用過濾器",
  "hidden_idx_next": "hidden_idx_next",
  "hidden_idx_prev": "hidden_idx_prev",
  "Dataset Images": "Dataset Images",
  "Filter by Tags": "Filter by Tags",
  "Filter by Selection": "Filter by Selection",
  "Batch Edit Captions": "Batch Edit Captions",
  "Edit Caption of Selected Image": "Edit Caption of Selected Image",
  "Move or Delete Files": "Move or Delete Files",
  "Clear tag filters": "Clear tag filters",
  "Clear ALL filters": "Clear ALL filters",
  "Positive Filter": "Positive Filter",
  "Negative Filter": "Negative Filter",
  "Search tags / Filter images by tags": "Search tags / Filter images by tags",
  "(INCLUSIVE)": "(INCLUSIVE)",
  "Search Tags": "Search Tags",
  "Prefix": "Prefix",
  "Suffix": "Suffix",
  "Use regex": "Use regex",
  "Sort by": "Sort by",
  "Alphabetical Order": "Alphabetical Order",
  "Frequency": "Frequency",
  "Length": "Length",
  "Token Length": "Token Length",
  "Sort Order": "Sort Order",
  "Ascending": "Ascending",
  "Descending": "Descending",
  "Filter Logic": "Filter Logic",
  "AND": "AND",
  "OR": "OR",
  "NONE": "NONE",
  "Filter Images by Tags": "Filter Images by Tags",
  "(EXCLUSIVE)": "(EXCLUSIVE)",
  "Number": "數量",
  "Select images from the left gallery.": "Select images from the left gallery.",
  "Add selection [Enter]": "Add selection [Enter]",
  "Add ALL Displayed": "Add ALL Displayed",
  "Filter Images": "Filter Images",
  "Selected Image :": "Selected Image :",
  "Remove selection [Delete]": "Remove selection [Delete]",
  "Invert selection": "Invert selection",
  "Clear selection": "Clear selection",
  "Apply selection filter": "Apply selection filter",
  "Search and Replace": "Search and Replace",
  "Remove": "Remove",
  "Edit common tags.": "Edit common tags.",
  "Show only the tags selected in the Positive Filter": "Show only the tags selected in the Positive Filter",
  "Common Tags": "Common Tags",
  "Edit Tags": "Edit Tags",
  "Prepend additional tags": "Prepend additional tags",
  "Apply changes to filtered images": "Apply changes to filtered images",
  "Show description of how to edit tags": "Show description of how to edit tags",
  "1. The tags common to all displayed images are shown in comma separated style.": "1. The tags common to all displayed images are shown in comma separated style.",
  "2. When changes are applied, all tags in each displayed images are replaced.": "2. When changes are applied, all tags in each displayed images are replaced.",
  "3. If you change some tags into blank, they will be erased.": "3. If you change some tags into blank, they will be erased.",
  "4. If you add some tags to the end, they will be added to the end/beginning of the text file.": "4. If you add some tags to the end, they will be added to the end/beginning of the text file.",
  "5. Changes are not applied to the text files until the \"Save all changes\" button is pressed.": "5. Changes are not applied to the text files until the \"Save all changes\" button is pressed.",
  "ex A.": "ex A.",
  "Original Text = \"A, A, B, C\" Common Tags = \"B, A\" Edit Tags = \"X, Y\"": "Original Text = \"A, A, B, C\" Common Tags = \"B, A\" Edit Tags = \"X, Y\"",
  "Result = \"Y, Y, X, C\" (B->X, A->Y)": "Result = \"Y, Y, X, C\" (B->X, A->Y)",
  "ex B.": "ex B.",
  "Original Text = \"A, B, C\" Common Tags = \"(nothing)\" Edit Tags = \"X, Y\"": "Original Text = \"A, B, C\" Common Tags = \"(nothing)\" Edit Tags = \"X, Y\"",
  "Result = \"A, B, C, X, Y\" (add X and Y to the end (default))": "Result = \"A, B, C, X, Y\" (add X and Y to the end (default))",
  "Result = \"X, Y, A, B, C\" (add X and Y to the beginning (\"Prepend additional tags\" checked))": "Result = \"X, Y, A, B, C\" (add X and Y to the beginning (\"Prepend additional tags\" checked))",
  "ex C.": "ex C.",
  "Original Text = \"A, B, C, D, E\" Common Tags = \"A, B, D\" Edit Tags = \", X, \"": "Original Text = \"A, B, C, D, E\" Common Tags = \"A, B, D\" Edit Tags = \", X, \"",
  "Result = \"X, C, E\" (A->\"\", B->X, D->\"\")": "Result = \"X, C, E\" (A->\"\", B->X, D->\"\")",
  "Search and Replace for all images displayed.": "Search and Replace for all images displayed.",
  "Search Text": "Search Text",
  "Replace Text": "Replace Text",
  "Search and Replace in": "Search and Replace in",
  "Only Selected Tags": "Only Selected Tags",
  "Each Tags": "Each Tags",
  "Entire Caption": "Entire Caption",
  "Selected Tags": "Selected Tags",
  "duplicate": "duplicate",
  "tags from the images displayed.": "tags from the images displayed.",
  "Remove duplicate tags": "Remove duplicate tags",
  "selected": "selected",
  "Remove selected tags": "Remove selected tags",
  "Select visible tags": "Select visible tags",
  "Deselect visible tags": "Deselect visible tags",
  "Select Tags": "Select Tags",
  "Sort tags in the images displayed.": "Sort tags in the images displayed.",
  "Sort tags": "Sort tags",
  "Truncate tags by token count.": "Truncate tags by token count.",
  "Truncate tags by token count": "Truncate tags by token count",
  "hidden_s_or_n": "hidden_s_or_n",
  "Read Caption from Selected Image": "Read Caption from Selected Image",
  "Interrogate Selected Image": "Interrogate Selected Image",
  "Caption of Selected Image": "Caption of Selected Image",
  "Copy and Overwrite": "Copy and Overwrite",
  "Interrogator": "Interrogator",
  "BLIP": "BLIP",
  "DeepDanbooru": "DeepDanbooru",
  "wd-v1-4-vit-tagger": "wd-v1-4-vit-tagger",
  "wd-v1-4-convnext-tagger": "wd-v1-4-convnext-tagger",
  "wd-v1-4-vit-tagger-v2": "wd-v1-4-vit-tagger-v2",
  "wd-v1-4-convnext-tagger-v2": "wd-v1-4-convnext-tagger-v2",
  "wd-v1-4-swinv2-tagger-v2": "wd-v1-4-swinv2-tagger-v2",
  "Interrogate": "Interrogate",
  "Interrogate Result": "Interrogate Result",
  "Copy caption from selected images automatically": "Copy caption from selected images automatically",
  "Sort caption on save": "Sort caption on save",
  "Warn if changes in caption is not saved": "Warn if changes in caption is not saved",
  "Edit Caption": "Edit Caption",
  "Apply changes to selected image": "Apply changes to selected image",
  "Apply changes to ALL displayed images": "Apply changes to ALL displayed images",
  "Changes are not applied to the text files until the \"Save all changes\" button is pressed.": "Changes are not applied to the text files until the \"Save all changes\" button is pressed.",
  "Moved or deleted images will be unloaded.": "Moved or deleted images will be unloaded.",
  "Move or Delete": "Move or Delete",
  "Selected One": "Selected One",
  "All Displayed Ones": "All Displayed Ones",
  "Target": "目標",
  "Image File": "Image File",
  "Caption Text File": "Caption Text File",
  "Caption Backup File": "Caption Backup File",
  "Target dataset num: 0": "Target dataset num: 0",
  "Destination Directory": "Destination Directory",
  "Move File(s)": "Move File(s)",
  "DELETE cannot be undone. The files will be deleted completely.": "DELETE cannot be undone. The files will be deleted completely.",
  "DELETE File(s)": "DELETE File(s)",
  "Number of columns on image gallery": "Number of columns on image gallery",
  "Force image gallery to use temporary files": "Force image gallery to use temporary files",
  "Use raw CLIP token to calculate token count (without emphasis or embeddings)": "Use raw CLIP token to calculate token count (without emphasis or embeddings)",
  "stable-diffusion-webui-dataset-tag-editor": "stable-diffusion-webui-dataset-tag-editor",
  "https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor": "https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor",
  "C:\\path\\to\\metadata.json": "C:\\path\\to\\metadata.json",
  "C:\\directory\\of\\datasets": "C:\\directory\\of\\datasets",
  ".txt (on Load and Save)": ".txt (on Load and Save)",
  "Reconstruct prompt from existing image and put it into the prompt field.": "從現有的圖像中重構出提示詞，並將其放入提示詞的輸入文字方塊",
  "txt": "txt",
  "Shift attention": "轉移注意力",
  "Show generated images in ui": "在用戶介面上顯示產生了的圖像",
  "Save results as video": "儲存結果為影片",
  "Frames per second": "每秒多少幀",
  "Number of frames for lead in/out": "導入／導出幀數",
  "Upscale ratio": "放大比率",
  "https://github.com/yownas/shift-attention.git": "https://github.com/yownas/shift-attention.git",
  "Maximum width or height (whichever is higher)": "最大寬度或高度（無論哪個較高）",
  "Scale to maximum width or height": "放大至最大寬度或高度",
  "-75%": "-75%",
  "-50%": "-50%",
  "-25%": "-25%",
  "+25%": "+25%",
  "+50%": "+50%",
  "+75%": "+75%",
  "+100%": "+100%",
  "Expand by default": "預設展開擴充功能",
  "Show maximum width or height button": "顯示最大寬度或高度按鈕",
  "Maximum width or height default": "最大寬度或高度的預設值",
  "Show predefined percentage buttons": "顯示預設的百分比按鈕",
  "Predefined percentage buttons, applied to dimensions (75, 125, 150)": "預設的百分比按鈕，套用於尺寸（75,125,150）",
  "Predefined percentage display format": "預設百分比顯示格式",
  "Incremental/decremental percentage (-50%, +50%)": "增減百分比（-50％，+50％）",
  "Raw percentage (50%, 150%)": "原始百分比（50％，150％）",
  "Multiplication (x0.5, x1.5)": "倍率 （x0.5, x1.5）",
  "sd-webui-aspect-ratio-helper": "sd-webui-aspect-ratio-helper",
  "https://github.com/thomasasfk/sd-webui-aspect-ratio-helper.git": "https://github.com/thomasasfk/sd-webui-aspect-ratio-helper.git",
  "https://github.com/Bing-su/sd-webui-tunnels.git": "https://github.com/Bing-su/sd-webui-tunnels.git",
  "Additional Networks": "附加網路（LoRA擴充功能）",
  "Separate UNet/Text Encoder weights": "單獨設定 UNet 及文字編碼器的權重",
  "Network module 1": "附加網路類型 1️⃣",
  "LoRA": "LoRA",
  "Model 1": "模型 1️⃣",
  "Weight 1": "權重 1️⃣",
  "UNet Weight 1": "UNet 權重 1️⃣",
  "TEnc Weight 1": "文字編碼器權重 1️⃣",
  "Network module 2": "附加網路類型 2️⃣",
  "Model 2": "模型 2️⃣",
  "Weight 2": "權重 2️⃣",
  "UNet Weight 2": "UNet 權重 2️⃣",
  "TEnc Weight 2": "文字編碼器權重 2️⃣",
  "Network module 3": "附加網路類型 3️⃣",
  "Model 3": "模型 3️⃣",
  "Weight 3": "權重 3️⃣",
  "UNet Weight 3": "UNet 權重 3️⃣",
  "TEnc Weight 3": "文字編碼器權重 3️⃣",
  "Network module 4": "附加網路類型 4️⃣",
  "Model 4": "模型 4️⃣",
  "Weight 4": "權重 4️⃣",
  "UNet Weight 4": "UNet 權重 4️⃣",
  "TEnc Weight 4": "文字編碼器權重 4️⃣",
  "Network module 5": "附加網路類型 5️⃣",
  "Model 5": "模型 5️⃣",
  "Weight 5": "權重 5️⃣",
  "UNet Weight 5": "UNet 權重 5️⃣",
  "TEnc Weight 5": "文字編碼器權重 5️⃣",
  "Extra args": "額外參數",
  "mask image:": "遮罩圖像：",
  "Refresh models": "重新整理模型列表",
  "AddNet Model 1": "[附加網絡] 模型 1️⃣",
  "AddNet Weight 1": "[附加網路] 權重 1️⃣",
  "AddNet UNet Weight 1": "[附加網路] UNet 權重 1️⃣",
  "AddNet TEnc Weight 1": "[附加網路] 文字編碼器權重 1️⃣",
  "AddNet Model 2": "[附加網路] 模型 2️⃣",
  "AddNet Weight 2": "[附加網路] 權重 2️⃣",
  "AddNet UNet Weight 2": "[附加網路] UNet 權重 2️⃣",
  "AddNet TEnc Weight 2": "[附加網路] 文字編碼器權重 2️⃣",
  "AddNet Model 3": "[附加網路] 模型 3️⃣",
  "AddNet Weight 3": "[附加網路] 權重 3️⃣",
  "AddNet UNet Weight 3": "[附加網路] UNet 權重 3️⃣",
  "AddNet TEnc Weight 3": "[附加網路] 文字編碼器權重 3️⃣",
  "AddNet Model 4": "[附加網路] 模型 4️⃣",
  "AddNet Weight 4": "[附加網路] 權重 4️⃣",
  "AddNet UNet Weight 4": "[附加網路] UNet 權重 4️⃣",
  "AddNet TEnc Weight 4": "[附加網路] 文字編碼器權重 4️⃣",
  "AddNet Model 5": "[附加網路] 模型 5️⃣",
  "AddNet Weight 5": "[附加網路] 權重 5️⃣",
  "AddNet UNet Weight 5": "[附加網路] UNet 權重 5️⃣",
  "AddNet TEnc Weight 5": "[附加網路] 文字編碼器權重 5️⃣",
  "Model path filter": "模型路徑過濾器",
  "Filter models by path name": "模型列表將僅顯示此路徑下的模型",
  "Network module": "附加網路類型",
  "Model hash": "模型雜湊值",
  "Legacy hash": "舊雜湊值",
  "Model path": "模型路徑",
  "Send to txt2img:": ">> 文生圖\n（數字對應模型號碼）",
  "Send to img2img:": ">> 圖生圖\n（數字對應模型號碼）",
  "Copy metadata to other models in directory": "複製中繼資料至其他目錄中的模型",
  "Containing directory": "目標模型目錄",
  "All models in this directory will receive the selected model's metadata": "此目錄下的所有模型將被寫入所選模型的中繼資料",
  "Only copy to models with same session ID": "僅複製到具有相同作業階段 ID 的模型",
  "Only copy to models with no metadata": "僅複製到沒有中繼資料的模型（不覆蓋原中繼資料）",
  "Copy Metadata": "複製中繼資料",
  "Display name for this model": "此模型的顯示名稱",
  "Author": "作者",
  "Author of this model": "此模型的作者",
  "Keywords": "觸發提示詞",
  "Activation keywords, comma-separated": "觸發提示詞，以逗號分隔",
  "Model description/readme/notes/instructions": "模型的描述資訊",
  "Source URL where this model could be found": "模型的發布網址",
  "Rating": "評分",
  "Tags": "標記",
  "Comma-separated list of tags (\"artist, style, character, 2d, 3d...\")": "此模型的標記列表（\"artist, style, character, 2d, 3d...\"）",
  "Editing Enabled": "啟用中繼資料編輯",
  "Save Metadata": "儲存中繼資料",
  "Cover image": "封面圖像",
  "Image Parameters": "圖像參數",
  "Training info": "訓練資訊",
  "Most frequent tags in captions": "訓練用描述最常用的標記",
  "Dataset folder structure": "資料集資料夾結構",
  "Image Count": "圖像數",
  "Repeats": "重複",
  "Total Images": "圖像總數",
  "Training parameters": "訓練參數",
  "copy to clipboard": "複製到剪貼簿",
  "Generate Info": "產生資訊",
  "Extra paths to scan for LoRA models, comma-separated. Paths containing commas must be enclosed in double quotes. In the path, \" (one quote) must be replaced by \"\" (two quotes).": "掃描 LoRA模型的額外目錄，以逗號分隔。包含逗號的路徑必須用雙引號括起來。在路徑中，一個引號「\"」必須替換為「\"\"」兩個引號。",
  "Sort LoRA models by": "LoRA 模型的排序方式",
  "name": "名稱",
  "date": "日期",
  "path name": "路徑名",
  "rating": "評分",
  "has user metadata": "有使用者中繼資料",
  "Reverse model sort order": "反向排序",
  "LoRA model name filter": "LoRA 模型名稱過濾器",
  "Metadata to show in XY-Grid label for Model axes, comma-separated (example: \"ss_learning_rate, ss_num_epochs\")": "顯示於 X/Y 圖表的中繼資料，以逗號分隔（例如：\"ss_learning_rate, ss_num_epochs\"）",
  "# of threads to use for hash calculation (increase if using an SSD)": "用於雜湊值計算的線程數（如果使用 SSD 可適量增加）",
  "Make a backup copy of the model being edited when saving its metadata.": "儲存中繼資料時，備份正在編輯的模型",
  "Only show .safetensors format models": "僅顯示 .safetensors 檔案格式的模型",
  "Only show models that have/don't have user-added metadata": "僅顯示（有 / 無）使用者中繼資料",
  "has metadata": "有中繼資料",
  "missing metadata": "缺少中繼資料",
  "Max number of top tags to show": "最多顯示幾個常用標記",
  "Max number of dataset folders to show": "最多顯示幾個數據集資料夾",
  "sd-webui-additional-networks": "sd-webui-additional-networks",
  "https://github.com/kohya-ss/sd-webui-additional-networks.git": "https://github.com/kohya-ss/sd-webui-additional-networks.git",
  "Tag Autocomplete": "標記自動補齊",
  "Tag filename": "標記檔檔名",
  "Enable Tag Autocompletion": "啟用標記自動補齊",
  "Active in txt2img (Requires restart)": "在文生圖中啟用（需要儲存設定並重新啟動）",
  "Active in img2img (Requires restart)": "在圖生圖中啟用（需要儲存設定並重新啟動）",
  "Active in negative prompts (Requires restart)": "在反向提示詞中啟用（需要儲存設定並重新啟動）",
  "Active in third party textboxes [Dataset Tag Editor] (Requires restart)": "在第三方擴充功能「數據集標記編輯器」的文字方塊中啟用（需要儲存設定並重新啟動）",
  "List of model names (with file extension) or their hashes to use as black/whitelist, separated by commas.": "要用作黑名單/白名單的模型名稱清單（包括檔案副檔名）或其雜湊值，用逗號分隔。",
  "Mode to use for model list": "模型名稱清單的使用模式",
  "Blacklist": "黑名單",
  "Whitelist": "白名單",
  "Move completion popup together with text cursor": "移動彈出視窗至文字游標處",
  "Maximum results": "最大結果",
  "Show all results": "顯示所有結果",
  "How many results to load at once": "一次載入多少個結果",
  "Time in ms to wait before triggering completion again (Requires restart)": "在再次觸發完成之前等待的毫秒數（需要儲存設定並重新啟動）",
  "Search for wildcards": "搜尋萬用字元",
  "Search for embeddings": "搜尋嵌入",
  "Search for hypernetworks": "搜尋超網絡",
  "Search for Loras": "搜尋 LoRA",
  "Show '?' next to tags, linking to its Danbooru or e621 wiki page (Warning: This is an external site and very likely contains NSFW examples!)": "在標記旁顯示「？」，連結到其 Danbooru 或 e621 wiki 頁面（警告：這是外部網站，很可能包含 NSFW 內容！）",
  "Replace underscores with spaces on insertion": "插入時將下橫線替換成空格",
  "Escape parentheses on insertion": "插入時轉義括號",
  "Append comma on tag autocompletion": "自動完成標記時加入逗號",
  "Search by alias": "以別名搜尋",
  "Only show alias": "僅顯示別名",
  "Translation filename": "翻譯檔檔名",
  "Translation file uses old 3-column translation format instead of the new 2-column one": "翻譯檔使用舊的三欄位翻譯格式，而非新的兩欄位格式",
  "Search by translation": "以翻譯搜尋",
  "Extra filename (for small sets of custom tags)": "追加標記檔檔名（用於小型的自定義標記集）",
  "Mode to add the extra tags to the main tag list": "將追加標記加入主標記清單的模式",
  "Insert before": "前綴插入",
  "Insert after": "後綴插入",
  "a1111-sd-webui-tagcomplete": "a1111-sd-webui-tagcomplete",
  "https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git": "https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git",
  "Training Picker": "訓練圖挑選器",
  "Video to extract frames from:": "要從中提取幀的影片：",
  "Only extract keyframes (recommended)": "只提取關鍵幀（推薦）",
  "Extract every nth frame": "每第 n 幀提取一次",
  "Extract Frames": "提取幀",
  "Extracted Frame Set": "提取好的幀",
  "Resize crops to 512x512": "縮放裁剪至 512x512",
  "Outfill method:": "填充方法：",
  "Don't outfill": "不進行填充",
  "Stretch image": "拉伸圖像",
  "Transparent": "透明",
  "Solid color": "純色",
  "Average image color": "平均圖像顏色",
  "Dominant image color": "圖像主色",
  "Stretch pixels at border": "延伸邊緣的畫素",
  "Reflect image around border": "從邊緣鏡像圖像內容",
  "Blurred & stretched overlay": "模糊拉伸的疊加層",
  "Reuse original image": "復用原圖",
  "Reset Aspect Ratio": "重置縱橫比",
  "Image border outfill method:": "圖像邊緣的填充方法：",
  "Black outfill": "填黑",
  "Outfill border color:": "填充顏色：",
  "Blur amount:": "模糊量：",
  "Number of clusters:": "簇數：",
  "Save crops to:": "儲存裁剪好的成品到：",
  "Fixed size to resize images to": "調整圖像大小到固定大小",
  "Path to read videos from": "讀取影片的路徑",
  "Path to store extracted frame sets in": "儲存截取幀的路徑",
  "Default cropped image output directory": "裁切後的成品的默認輸出目錄",
  "https://github.com/Maurdekye/training-picker.git": "https://github.com/Maurdekye/training-picker.git",
  "CLIP_test": "CLIP_test",
  "Create Beta hypernetwork": "Create Beta hypernetwork",
  "Train_Gamma": "Train_Gamma",
  "Train_Tuning": "Train_Tuning",
  "Show advanced options": "Show advanced options",
  "Weight initialization seed, set -1 for default": "Weight initialization seed, set -1 for default",
  "Standard Deviation for Normal weight initialization": "Standard Deviation for Normal weight initialization",
  "Use dropout. Might improve training when dataset is small / limited.": "Use dropout. Might improve training when dataset is small / limited.",
  "Use skip-connection. Won't work without extension!": "Use skip-connection. Won't work without extension!",
  "Optional information about Hypernetwork": "Optional information about Hypernetwork",
  "Setting file name": "Setting file name",
  "Save hypernetwork setting to file": "Save hypernetwork setting to file",
  "Train an embedding or Hypernetwork; you must specify a directory": "Train an embedding or Hypernetwork; you must specify a directory",
  "Show advanced learn rate scheduler options": "Show advanced learn rate scheduler options",
  "Show advanced adamW parameter options)": "Show advanced adamW parameter options)",
  "Show Gradient Clipping Options(for both)": "Show Gradient Clipping Options(for both)",
  "Show Noise Scheduler Options(for both)": "Show Noise Scheduler Options(for both)",
  "Uses D-Adaptation(LR Free) AdamW. Recommended LR is 1.0 at base": "Uses D-Adaptation(LR Free) AdamW. Recommended LR is 1.0 at base",
  "AdamW weight decay parameter": "AdamW weight decay parameter",
  "AdamW beta1 parameter": "AdamW beta1 parameter",
  "AdamW beta2 parameter": "AdamW beta2 parameter",
  "AdamW epsilon parameter": "AdamW epsilon parameter",
  "Growth factor limiting, use value like 1.02 or leave it as -1": "Growth factor limiting, use value like 1.02 or leave it as -1",
  "Use CosineAnnealingWarmupRestarts Scheduler": "Use CosineAnnealingWarmupRestarts Scheduler",
  "Steps for cycle": "Steps for cycle",
  "Step multiplier per cycle": "Step multiplier per cycle",
  "Warmup step per cycle": "Warmup step per cycle",
  "Minimum learning rate": "Minimum learning rate",
  "Decays learning rate every cycle": "Decays learning rate every cycle",
  "Saves when every cycle finishes": "Saves when every cycle finishes",
  "Generates image when every cycle finishes": "Generates image when every cycle finishes",
  "Gradient Clipping Options": "Gradient Clipping Options",
  "limit": "limit",
  "Limiting value": "Limiting value",
  "Norm type": "Norm type",
  "Use Noise training scheduler(test)": "Use Noise training scheduler(test)",
  "Restarts noise scheduler, or linear": "Restarts noise scheduler, or linear",
  "Restarts noise scheduler every nth epoch": "Restarts noise scheduler every nth epoch",
  "Unload Optimizer when generating preview(hypernetwork)": "Unload Optimizer when generating preview(hypernetwork)",
  "Standard deviation for sampling": "Standard deviation for sampling",
  "loss type": "loss type",
  "loss": "loss",
  "loss_simple": "loss_simple",
  "loss_vlb": "loss_vlb",
  "Save training setting": "Save training setting",
  "File name to save setting as": "File name to save setting as",
  "Load training option from saved json file. This will override settings above": "Load training option from saved json file. This will override settings above",
  "Train Hypernetwork; you must specify a directory": "Train Hypernetwork; you must specify a directory",
  "Hypernetwork name to create, leave it empty to use selected": "Hypernetwork name to create, leave it empty to use selected",
  "Load Hypernetwork creation option from saved json file": "Load Hypernetwork creation option from saved json file",
  "Load training option(s) from saved json file": "Load training option(s) from saved json file",
  "Save a copy of model to log directory every N steps, 0 to disable": "Save a copy of model to log directory every N steps, 0 to disable",
  "Manual dataset seed": "Manual dataset seed",
  "CLIP-test": "CLIP-test",
  "CLIP Text models. Set to empty to not change.": "CLIP Text models. Set to empty to not change.",
  "Enable clip model change. This will be triggered from next model changes.": "Enable clip model change. This will be triggered from next model changes.",
  "Detach grad from conditioning models": "Detach grad from conditioning models",
  "Hypernetwork-MonkeyPatch-Extension": "Hypernetwork-MonkeyPatch-Extension",
  "must be positive float": "must be positive float",
  "Training information, dateset, etc": "Training information, dateset, etc",
  "default = 0.01": "default = 0.01",
  "default = 0.9": "default = 0.9",
  "default = 0.99": "default = 0.99",
  "default = 1e-8": "default = 1e-8",
  "Cycles every nth Step": "Cycles every nth Step",
  "Step length multiplier every cycle": "Step length multiplier every cycle",
  "CosineAnnealing lr increase step": "CosineAnnealing lr increase step",
  "restricts decay value, but does not restrict gamma rate decay": "restricts decay value, but does not restrict gamma rate decay",
  "Value should be in (0-1]": "Value should be in (0-1]",
  ". filename cannot have ',' inside, and files should be splitted by ','.": ". filename cannot have ',' inside, and files should be splitted by ','.",
  "https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension.git": "https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension.git",
  "Ultimate SD upscale": "終極 SD 放大",
  "Will upscale the image depending on the selected target size type": "將根據選擇的目標尺寸類型對圖像進行放大。",
  "Target size type": "圖像尺寸類型",
  "From img2img2 settings": "依照圖生圖設定",
  "Custom size": "自訂尺寸",
  "Scale from image size": "從圖像大小縮放",
  "Custom width": "自訂寬度",
  "Custom height": "自訂高度",
  "Scale": "放大倍率",
  "Redraw options:": "重繪選項：",
  "Type": "類型",
  "Chess": "棋盤狀",
  "Tile width": "圖塊寬度",
  "Tile height": "圖塊高度",
  "Padding": "內距",
  "Seams fix:": "儲存接縫修復圖像",
  "Band pass": "帶通",
  "Half tile offset pass": "半圖塊偏移過濾",
  "Half tile offset pass + intersections": "半圖塊偏移過濾 + 交集",
  "Denoise": "重繪幅度",
  "Save options:": "輸出到 output 的圖像：",
  "Upscaled": "儲存 SD 放大的圖像",
  "Seams fix": "儲存接縫修復圖像",
  "ultimate-upscale-for-automatic1111": "ultimate-upscale-for-automatic1111",
  "https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git": "https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git",
  "Enable Bilingual Localization": "啟用雙語翻譯對照",
  "Localization file (Please leave `User interface` - `Localization` as None)": "本地化翻譯（請將使用者介面下的本地化翻譯設為無）",
  "Translation display order": "翻譯顯示順序",
  "Translation First": "翻譯優先",
  "Original First": "原文優先",
  "Localization dirs": "本地化路徑",
  "sd-webui-bilingual-localization": "sd-webui-bilingual-localization",
  "https://github.com/journey-ad/sd-webui-bilingual-localization.git": "https://github.com/journey-ad/sd-webui-bilingual-localization.git",
  "Enable pixelization": "啟用像素化",
  "Keep resolution": "保持解析度",
  "Pixel size": "像素尺寸",
  "stable-diffusion-webui-pixelization": "stable-diffusion-webui-pixelization",
  "https://github.com/AUTOMATIC1111/stable-diffusion-webui-pixelization.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-pixelization.git",
  "stable-diffusion-webui-depthmap-script": "stable-diffusion-webui-depthmap-script",
  "Compute on": "計算於",
  "GPU": "GPU",
  "CPU": "CPU",
  "Match input size (size is ignored when using boost)": "符合輸入大小（當使用加速器時，大小將被忽略）",
  "BOOST (multi-resolution merging)": "提升（多分辨率合併）",
  "Invert DepthMap (black=near, white=far)": "Invert DepthMap (black=near, white=far)",
  "Clip and renormalize": "Clip and renormalize",
  "Far clip": "Far clip",
  "Near clip": "Near clip",
  "Combine into one image.": "Combine into one image.",
  "Combine axis": "Combine axis",
  "Vertical": "垂直",
  "Horizontal": "水平",
  "Save DepthMap": "儲存深度圖",
  "Show DepthMap": "顯示深度圖",
  "Show HeatMap": "顯示熱度圖",
  "Generate Stereo side-by-side image": "Generate Stereo side-by-side image",
  "Generate Stereo anaglyph image (red/cyan)": "Generate Stereo anaglyph image (red/cyan)",
  "Divergence (3D effect)": "Divergence (3D effect)",
  "Gap fill technique": "Gap fill technique",
  "Balance between eyes": "Balance between eyes",
  "Generate 3D inpainted mesh. (Sloooow)": "Generate 3D inpainted mesh. (Sloooow)",
  "Generate 4 demo videos with 3D inpainted mesh.": "Generate 4 demo videos with 3D inpainted mesh.",
  "Remove background": "移除背景",
  "Save the foreground masks": "儲存前景遮罩",
  "pre-depth background removal": "pre-depth background removal",
  "Rembg Model": "Rembg Model",
  "Information, comment and share @": "Information, comment and share @",
  "Input Mesh (.ply)": "Input Mesh (.ply)",
  "Generate video from inpainted mesh.": "Generate video from inpainted mesh.",
  "A file on the same machine where the server is running.": "A file on the same machine where the server is running.",
  "Number of frames": "Number of frames",
  "Framerate": "偵率",
  "Format": "格式",
  "Trajectory": "Trajectory",
  "Translate: x, y, z": "Translate: x, y, z",
  "Crop: top, left, bottom, right": "Crop: top, left, bottom, right",
  "Dolly": "Dolly",
  "Generate Video": "產生影片",
  "https://github.com/thygate/stable-diffusion-webui-depthmap-script.git": "https://github.com/thygate/stable-diffusion-webui-depthmap-script.git",
  "Create inspiration images": "建立靈感圖像",
  "Artist or styles name list. '.txt' files with one name per line": "Artist or styles name list. '.txt' files with one name per line",
  "Prompt Placeholder, which can be used at the top of prompt input": "Prompt Placeholder, which can be used at the top of prompt input",
  "To activate inspiration function, you need get \"inspiration\" images first.": "To activate inspiration function, you need get \"inspiration\" images first.",
  "You can create these images by run \"Create inspiration images\" script in txt2img page,": "You can create these images by run \"Create inspiration images\" script in txt2img page,",
  "you can get the artists or art styles list from here": "you can get the artists or art styles list from here",
  "download these files, and select these files in the \"Create inspiration images\" script UI": "download these files, and select these files in the \"Create inspiration images\" script UI",
  "There about 6000 artists and art styles in these files.": "There about 6000 artists and art styles in these files.",
  "This takes server hours depending on your GPU type and how many pictures  you generate for each artist/style": "This takes server hours depending on your GPU type and how many pictures  you generate for each artist/style",
  "I suggest at least four images for each": "I suggest at least four images for each",
  "You can also download generated pictures from here:": "You can also download generated pictures from here:",
  "unzip the file to": "unzip the file to",
  "/extections/stable-diffusion-webui-inspiration": "/extections/stable-diffusion-webui-inspiration",
  "and restart webui, and enjoy the joy of creation!": "and restart webui, and enjoy the joy of creation!",
  "Checkbox Group": "Checkbox Group",
  "artists": "藝術家",
  "flavors": "flavors",
  "mediums": "mediums",
  "movements": "movements",
  "Exclude abandoned": "Exclude abandoned",
  "Abandoned": "Abandoned",
  "Key word": "Key word",
  "Get inspiration": "Get inspiration",
  "to txt2img": "to txt2img",
  "to img2img": "to img2img",
  "Collect": "Collect",
  "Don't show again": "Don't show again",
  "Maximum number of samples, used to determine which folders to skip when continue running the create script": "Maximum number of samples, used to determine which folders to skip when continue running the create script",
  "Number of rows on the page": "每頁行數",
  "Minimum number of pages per load": "每次載入的最小頁數",
  "stable-diffusion-webui-inspiration": "stable-diffusion-webui-inspiration",
  "https://github.com/yfszzx/stable-diffusion-webui-inspiration.git": "https://github.com/yfszzx/stable-diffusion-webui-inspiration.git",
  "u2net": "u2net",
  "u2netp": "u2netp",
  "u2net_human_seg": "u2net_human_seg",
  "u2net_cloth_seg": "u2net_cloth_seg",
  "silueta": "silueta",
  "Return mask": "Return mask",
  "Alpha matting": "Alpha matting",
  "Erode size": "Erode size",
  "Foreground threshold": "Foreground threshold",
  "Background threshold": "Background threshold",
  "https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg.git",
  "Smart Preprocess": "智慧預處理",
  "sd_smartprocess": "sd_smartprocess",
  "Rename images": "重新命名圖像",
  "Cropping": "裁切",
  "Output Size": "輸出尺寸",
  "Pad Images": "Pad Images",
  "Crop Images": "裁切圖像",
  "Captions": "描述",
  "Generate Captions": "產生描述",
  "Max Caption Length (0=unlimited)": "最大描述長度（設 0 為無限制）",
  "Existing Caption Action": "既有描述處理",
  "Add CLIP results to Caption": "將 CLIP 結果加入描述",
  "Number of CLIP beams": "Number of CLIP beams",
  "CLIP Minimum length": "最小 CLIP 長度",
  "CLIP Maximum length": "最小 CLIP 長度",
  "Use v2 CLIP Model": "使用 v2 CLIP 模型",
  "Append Flavor tags from CLIP": "Append Flavor tags from CLIP",
  "Max flavors to append.": "Max flavors to append.",
  "Append Medium tags from CLIP": "Append Medium tags from CLIP",
  "Append Movement tags from CLIP": "Append Movement tags from CLIP",
  "Append Artist tags from CLIP": "Append Artist tags from CLIP",
  "Append Trending tags from CLIP": "Append Trending tags from CLIP",
  "Add WD14 Tags to Caption": "Add WD14 Tags to Caption",
  "Minimum Score for WD14 Tags": "Minimum Score for WD14 Tags",
  "Minimum Score for DeepDanbooru Tags": "Minimum Score for DeepDanbooru Tags",
  "Tags To Ignore": "要忽略的標記",
  "Replace Class with Subject in Caption": "在描述中將類別取代為主題",
  "Subject Class": "主題類別",
  "Subject class to crop (leave blank to auto-detect)": "要裁切的主題類別（留空以自動偵測）",
  "Subject Name": "主題名稱",
  "Subject Name to replace class with in captions": "要在描述中將類別取代的主題名稱",
  "Post-Processing": "後處理",
  "Face Restore Model": "面部修復模型",
  "Upscale and Resize": "放大並縮放比例",
  "https://github.com/d8ahazard/sd_smartprocess.git": "https://github.com/d8ahazard/sd_smartprocess.git",
  "Cutoff": "Cutoff",
  "Target tokens (comma separated)": "Target tokens (comma separated)",
  "Details": "Details",
  "Disable for Negative prompt.": "Disable for Negative prompt.",
  "Cutoff strongly.": "Cutoff strongly.",
  "Padding token (ID or single token)": "Padding token (ID or single token)",
  "Interpolation method": "Interpolation method",
  "Debug log": "Debug log",
  "Cutoff Enabled": "Cutoff Enabled",
  "Cutoff Targets": "Cutoff Targets",
  "Cutoff Weight": "Cutoff Weight",
  "Cutoff Disable for Negative Prompt": "Cutoff Disable for Negative Prompt",
  "Cutoff Strong": "Cutoff Strong",
  "Cutoff Padding": "Cutoff Padding",
  "Cutoff Interpolation": "Cutoff Interpolation",
  "sd-webui-cutoff": "sd-webui-cutoff",
  "https://github.com/hnmr293/sd-webui-cutoff.git": "https://github.com/hnmr293/sd-webui-cutoff.git",
  "red, blue": "red, blue",
  "HakuImg": "HakuImg",
  "Send to Blend": ">> 混合器",
  "Send to Layer5": ">> 圖層 5",
  "Send to Layer4": ">> 圖層 4",
  "Send to Layer3": ">> 圖層 3",
  "Send to Layer2": ">> 圖層 2",
  "Send to Layer1": ">> 圖層 1",
  "Send to Effect": ">> 效果器",
  "Blend": "Blend",
  "Effect": "效果器",
  "Other": "其他",
  "Image preview height": "圖像預覽高度",
  "Layer5": "圖層 5",
  "Layer4": "圖層 4",
  "Layer3": "圖層 3",
  "Layer2": "圖層 2",
  "Layer1": "圖層 1",
  "Layer5 opacity": "圖層 5 透明度",
  "Layer5 mask blur": "圖層 5 遮罩模糊",
  "Layer5 mask strength": "圖層 5 遮罩強度",
  "Blend mode": "混合模式",
  "normal": "普通",
  "darken": "變暗",
  "multiply": "色彩增值",
  "color_burn": "加深顏色",
  "linear_burn": "線性加深",
  "lighten": "變亮",
  "screen": "濾色",
  "color_dodge": "加亮顏色",
  "linear_dodge": "線性加亮",
  "overlay": "覆蓋",
  "soft_light": "柔光",
  "hard_light": "實光",
  "vivid_light": "強烈光線",
  "linear_light": "線性光線",
  "pin_light": "小光源",
  "difference": "差異化",
  "exclusion": "排除",
  "Layer4 opacity": "圖層 4 透明度",
  "Layer4 mask blur": "圖層 4 遮罩模糊",
  "Layer4 mask strength": "圖層 4 遮罩強度",
  "Layer3 opacity": "圖層 3 透明度",
  "Layer3 mask blur": "圖層 3 遮罩模糊",
  "Layer3 mask strength": "圖層 3 遮罩強度",
  "Layer2 opacity": "圖層 2 透明度",
  "Layer2 mask blur": "圖層 2 遮罩模糊",
  "Layer2 mask strength": "圖層 2 遮罩強度",
  "Layer1 opacity": "圖層 1 透明度",
  "Layer1 mask blur": "圖層 1 遮罩模糊",
  "Layer1 mask strength": "圖層 1 遮罩強度",
  "background color": "背景顏色",
  "refresh": "重新整理",
  "img": "img",
  "Color": "色彩",
  "Tone Curve": "Tone Curve",
  "Blur": "Blur",
  "Pixelize": "Pixelize",
  "Glow": "Glow",
  "temparature": "temparature",
  "hue": "hue",
  "brightness": "brightness",
  "contrast": "contrast",
  "saturation": "saturation",
  "Gamma": "Gamma",
  "reset": "reset",
  "All": "所有",
  "R": "R",
  "G": "G",
  "point1 x": "point1 x",
  "point1 y": "point1 y",
  "point2 x": "point2 x",
  "point2 y": "point2 y",
  "point3 x": "point3 x",
  "point3 y": "point3 y",
  "blur": "模糊",
  "kernel size": "kernel size",
  "sigma": "sigma",
  "k_sigma": "k_sigma",
  "epsilon": "epsilon",
  "phi": "phi",
  "gamma": "gamma",
  "color mode": "color mode",
  "gray": "gray",
  "rgb": "rgb",
  "use scale": "use scale",
  "colors": "colors",
  "dot size": "dot size",
  "outline inflating": "outline inflating",
  "Smoothing": "Smoothing",
  "Color reduce algo": "Color reduce algo",
  "kmeans": "kmeans",
  "dithering": "dithering",
  "kmeans with dithering": "kmeans with dithering",
  "Glow mode": "Glow mode",
  "BS": "BS",
  "BMBL": "BMBL",
  "range": "range",
  "strength": "strength",
  "InOutPaint": "InOutPaint",
  "fill up": "fill up",
  "fill down": "fill down",
  "fill left": "fill left",
  "fill right": "fill right",
  "Resolution": "解析度",
  "haku_output": "haku_output",
  "Send to inpaint upload": ">> 局部重繪",
  "Total num of layers (reload required)": "Total num of layers (reload required)",
  "Total num of point for curve (reload required)": "Total num of point for curve (reload required)",
  "a1111-sd-webui-haku-img": "a1111-sd-webui-haku-img",
  "https://github.com/KohakuBlueleaf/a1111-sd-webui-haku-img.git": "https://github.com/KohakuBlueleaf/a1111-sd-webui-haku-img.git",
  "Save score as EXIF or PNG Info Chunk": "將分數儲存為 EXIF 或 PNG Info Chunk",
  "aesthetic_score": "美學分數",
  "sampler": "取樣器",
  "sd_model_hash": "SD模型雜湊值",
  "hash": "雜湊值",
  "Save tags (Windows only)": "儲存標籤（僅限Windows）",
  "Save category (Windows only)": "儲存類別（僅限Windows）",
  "Save generation params text": "儲存生成參數文本",
  "Force CPU (Requires Custom Script Reload)": "強制使用 CPU（需要重新加載自定義腳本）",
  "stable-diffusion-webui-aesthetic-image-scorer": "stable-diffusion-webui-aesthetic-image-scorer",
  "https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer.git": "https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer.git",
  "NAIConvert": "NAI轉換",
  "History": "歷史記錄",
  "https://github.com/animerl/novelai-2-local-prompt.git": "https://github.com/animerl/novelai-2-local-prompt.git",
  "MultiDiffusion": "MultiDiffusion",
  "Enable MultiDiffusion": "啟用 MultiDiffusion",
  "Overwrite image size": "覆寫圖像尺寸",
  "Keep input image size": "維持輸入圖像尺寸",
  "Image width": "圖像寬度",
  "Image height": "圖像高度",
  "Latent tile width": "潛在變數分塊寬度",
  "Latent tile height": "潛在變數分塊高度",
  "Latent tile overlap": "潛在變數分塊重疊",
  "Latent tile batch size": "潛在變數分塊批次數量",
  "Move ControlNet images to CPU (if applicable)": "將 ControlNet 圖像移至 CPU（如果可使用）",
  "Tiled VAE": "分塊 VAE",
  "Move VAE to GPU": "將 VAE 移至 GPU",
  "Please use smaller tile size when see CUDA error: out of memory.": "如果看到 CUDA 錯誤：out of memory ，請降低分塊尺寸。",
  "Encoder Tile Size": "編碼器分塊尺寸",
  "Decoder Tile Size": "解碼器分塊尺寸",
  "Reset Tile Size": "重置分塊尺寸",
  "Fast Encoder": "快速編碼器",
  "Fast Decoder": "快速解碼器",
  "Fast Encoder may change colors; Can fix it with more RAM and lower speed.": "快速編碼器會導致顏色變更；可以使用更多記憶體與時間來修復。",
  "Encoder Color Fix": "編碼器顏色修復",
  "multidiffusion-upscaler-for-automatic1111": "multidiffusion-upscaler-for-automatic1111",
  "https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111.git": "https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111.git",
  "BLIP2 Captioner": "BLIP2 Captioner",
  "Generated Caption": "已產生的描述",
  "Output Caption Extension": "Output Caption Extension",
  "Unload models": "Unload models",
  "Nucleus": "Nucleus",
  "Top-K": "Top-K",
  "Number of beams (0 = no beam search)": "Number of beams (0 = no beam search)",
  "Caption min length": "描述最小長度",
  "Caption max length": "描述最大長度",
  "Top p": "Top p",
  "stable-diffusion-webui-blip2-captioner": "stable-diffusion-webui-blip2-captioner",
  "https://github.com/p1atdev/stable-diffusion-webui-blip2-captioner": "https://github.com/p1atdev/stable-diffusion-webui-blip2-captioner",
  "path/to/caption": "path/to/caption",
  "Attention Heatmap": "注意力熱度圖",
  "Attention texts for visualization. (comma separated)": "視覺化的注意文字（以逗號分隔）",
  "Hide heatmap images": "隱藏熱度圖",
  "Do not save heatmap images": "不儲存熱度圖",
  "Hide caption": "隱藏描述",
  "Use grid (output to grid dir)": "使用網格（輸出到網格目錄）",
  "Grid layout": "網格布局",
  "Auto": "自動",
  "Prevent Empty Spot": "防止空白區域",
  "Batch Length As Row": "批次長度作為一列",
  "Heatmap blend alpha": "熱度圖混合透明度",
  "Heatmap image scale": "熱度圖縮放比例",
  "Trace each layers": "追蹤每個層級",
  "Use layers as row instead of Batch Length": "將圖層作為行而非批次長度使用",
  "stable-diffusion-webui-daam": "stable-diffusion-webui-daam",
  "https://github.com/toriato/stable-diffusion-webui-daam.git": "https://github.com/toriato/stable-diffusion-webui-daam.git",
  "stable-diffusion-webui-two-shot": "stable-diffusion-webui-two-shot",
  "Divisions": "分割",
  "Positions": "位置",
  "Weights": "權重",
  "end at this step": "在此疊代步數停止",
  "Visualize": "視覺化",
  "Regions": "區域",
  "Extra generation params": "附加生成參數",
  "Apply": "套用",
  "https://github.com/opparco/stable-diffusion-webui-two-shot.git": "https://github.com/opparco/stable-diffusion-webui-two-shot.git",
  "sd-webui-regional-prompter": "sd-webui-regional-prompter",
  "https://github.com/hako-mikan/sd-webui-regional-prompter.git": "https://github.com/hako-mikan/sd-webui-regional-prompter.git",
  "Active": "Active",
  "Divide mode": "Divide mode",
  "Generation mode": "Generation mode",
  "Attention": "Attention",
  "Divide Ratio": "Divide Ratio",
  "Base Ratio": "Base Ratio",
  "Use base prompt": "Use base prompt",
  "Use common prompt": "Use common prompt",
  "Use common negative prompt": "Use common negative prompt",
  "visualize and make template": "visualize and make template",
  "template": "template",
  "Presets": "Presets",
  "disable convert 'AND' to 'BREAK'": "disable convert 'AND' to 'BREAK'",
  "debug": "debug",
  "Apply Presets": "Apply Presets",
  "Preset Name": "Preset Name",
  "Save to Presets": "Save to Presets",
  "Seed travel": "種子變遷",
  "Destination seed(s) (Comma separated)": "目標種子（逗號分割）",
  "Only use Random seeds (Unless comparing paths)": "只用隨機種子（除非需要對比變遷軌跡）",
  "Number of random seed(s)": "隨機種子數量",
  "Compare paths (Separate travels from 1st seed to each destination)": "對比變遷軌跡（從第一個種子分別變遷到每一個目標種子）",
  "Steps (Number of images between each seed)": "步數（每個種子之間的圖像數量）",
  "Loop back to initial seed": "再變遷回初始種子",
  "Bump seed (If > 0 do a Compare Paths but only one image. No video will be generated.)": "提高種子值（如果大於 0，則進行對比變遷軌跡，但僅產生一張圖像而非影片。）",
  "Use cache": "使用快取",
  "Interpolation rate": "插值速率",
  "Hug-the-middle": "保留核心（Hug-the-middle）",
  "Slow start": "緩慢開始（Slow start）",
  "Quick start": "快速開始（Quick start）",
  "Rate strength": "速率強度",
  "Allow the default Euler a Sampling method. (Does not produce good results)": "允許使用默認的 Eular a 採樣方法.（通常不會產生好的結果）",
  "seed_travel": "seed_travel",
  "https://github.com/yownas/seed_travel.git": "https://github.com/yownas/seed_travel.git",
  "Artists To Study": "藝術家圖庫",
  "dog": "dog",
  "house": "house",
  "portrait": "portrait",
  "spaceship": "spaceship",
  "anime": "anime",
  "cartoon": "cartoon",
  "digipa-high-impact": "digipa-high-impact",
  "digipa-med-impact": "digipa-med-impact",
  "digipa-low-impact": "digipa-low-impact",
  "fareast": "fareast",
  "fineart": "fineart",
  "scribbles": "scribbles",
  "special": "special",
  "ukioe": "ukioe",
  "weird": "weird",
  "black-white": "black-white",
  "nudity": "nudity",
  "c": "c",
  "n": "n",
  "Get Images": "Get Images",
  "dog-anime": "dog-anime",
  "dog-cartoon": "dog-cartoon",
  "dog-digipa-high-impact": "dog-digipa-high-impact",
  "dog-digipa-med-impact": "dog-digipa-med-impact",
  "dog-digipa-low-impact": "dog-digipa-low-impact",
  "dog-fareast": "dog-fareast",
  "dog-fineart": "dog-fineart",
  "dog-scribbles": "dog-scribbles",
  "dog-special": "dog-special",
  "dog-ukioe": "dog-ukioe",
  "dog-weird": "dog-weird",
  "dog-black-white": "dog-black-white",
  "dog-nudity": "dog-nudity",
  "dog-c": "dog-c",
  "dog-n": "dog-n",
  "house-anime": "house-anime",
  "house-cartoon": "house-cartoon",
  "house-digipa-high-impact": "house-digipa-high-impact",
  "house-digipa-med-impact": "house-digipa-med-impact",
  "house-digipa-low-impact": "house-digipa-low-impact",
  "house-fareast": "house-fareast",
  "house-fineart": "house-fineart",
  "house-scribbles": "house-scribbles",
  "house-special": "house-special",
  "house-ukioe": "house-ukioe",
  "house-weird": "house-weird",
  "house-black-white": "house-black-white",
  "house-nudity": "house-nudity",
  "house-c": "house-c",
  "house-n": "house-n",
  "portrait-anime": "portrait-anime",
  "portrait-cartoon": "portrait-cartoon",
  "portrait-digipa-high-impact": "portrait-digipa-high-impact",
  "portrait-digipa-med-impact": "portrait-digipa-med-impact",
  "portrait-digipa-low-impact": "portrait-digipa-low-impact",
  "portrait-fareast": "portrait-fareast",
  "portrait-fineart": "portrait-fineart",
  "portrait-scribbles": "portrait-scribbles",
  "portrait-special": "portrait-special",
  "portrait-ukioe": "portrait-ukioe",
  "portrait-weird": "portrait-weird",
  "portrait-black-white": "portrait-black-white",
  "portrait-nudity": "portrait-nudity",
  "portrait-c": "portrait-c",
  "portrait-n": "portrait-n",
  "spaceship-anime": "spaceship-anime",
  "spaceship-cartoon": "spaceship-cartoon",
  "spaceship-digipa-high-impact": "spaceship-digipa-high-impact",
  "spaceship-digipa-med-impact": "spaceship-digipa-med-impact",
  "spaceship-digipa-low-impact": "spaceship-digipa-low-impact",
  "spaceship-fareast": "spaceship-fareast",
  "spaceship-fineart": "spaceship-fineart",
  "spaceship-scribbles": "spaceship-scribbles",
  "spaceship-special": "spaceship-special",
  "spaceship-ukioe": "spaceship-ukioe",
  "spaceship-weird": "spaceship-weird",
  "spaceship-black-white": "spaceship-black-white",
  "spaceship-nudity": "spaceship-nudity",
  "spaceship-c": "spaceship-c",
  "spaceship-n": "spaceship-n",
  "artists to study extension by camenduru |": "artists to study extension by camenduru |",
  "github": "github",
  "|": "|",
  "twitter": "twitter",
  "youtube": "youtube",
  "hi-res images": "hi-res images",
  "All images generated with CompVis/stable-diffusion-v1-4 +": "All images generated with CompVis/stable-diffusion-v1-4 +",
  "artists.csv": "artists.csv",
  "| License: Attribution 4.0 International (CC BY 4.0)": "| License: Attribution 4.0 International (CC BY 4.0)",
  "stable-diffusion-webui-artists-to-study": "stable-diffusion-webui-artists-to-study",
  "https://github.com/camenduru/stable-diffusion-webui-artists-to-study.git": "https://github.com/camenduru/stable-diffusion-webui-artists-to-study.git",
  "Text2Prompt": "文生提示詞",
  "Input Theme": "輸入情境",
  "Input Negative Theme": "輸入反向情境",
  "Negative strength": "反向情境強度",
  "Replace underscore in tag with whitespace": "將標記內下橫線替換成空格",
  "Escape brackets in tag": "轉義標記內括號",
  "Generation Settings": "生成設定",
  "Database": "資料庫",
  "Tag count filter": "Tag count filter",
  "Tag range:": "Tag range:",
  "≥ 0 tagged": "≥ 0 tagged",
  "(14589 tags total)": "(14589 tags total)",
  "Method to convert similarity into probability": "Method to convert similarity into probability",
  "Cutoff and Power": "Cutoff and Power",
  "Softmax": "Softmax",
  "Power": "Power",
  "Top-k": "Top-k",
  "Top-p (Nucleus)": "Top-p (Nucleus)",
  "Max number of tags": "標記最大數量",
  "k value": "k 值",
  "p value": "p 值",
  "Use weighted choice": "Use weighted choice",
  "stable-diffusion-webui-text2prompt": "stable-diffusion-webui-text2prompt",
  "https://github.com/toshiaki1729/stable-diffusion-webui-text2prompt.git": "https://github.com/toshiaki1729/stable-diffusion-webui-text2prompt.git",
  "Model Pre​views": "模型預覽器",
  "Embeddings": "嵌入",
  "Filter": "過濾器",
  "Notes": "備註",
  "Model Preview XD": "模型預覽器",
  "Name matching rule for preview files": "預覽檔的名稱符合規則",
  "Loose": "寬鬆",
  "Strict": "嚴格",
  "Folder": "檔案夾",
  "Index": "索引",
  "Limit the height of preivews to the height of the browser window (.html preview files are always limited regardless of this setting)": "將預覽的高度限制為瀏覽器視窗高度（.html 預覽檔始終受此設定的限制）",
  "sd-model-preview-xd": "sd-model-preview-xd",
  "No Preview Found": "查無預覽檔",
  "https://github.com/CurtisDS/sd-model-preview-xd.git": "https://github.com/CurtisDS/sd-model-preview-xd.git",
  "auto-sd-paint-ext Guide/Panel": "auto-sd-paint-ext Guide/Panel",
  "Generate Krita Plugin Symlink Command": "Generate Krita Plugin Symlink Command",
  "Launch Krita.": "Launch Krita.",
  "On the menubar, go to": "On the menubar, go to",
  "Settings > Manage Resources...": "Settings > Manage Resources...",
  "In the window that appears, click": "In the window that appears, click",
  "Open Resource Folder": "Open Resource Folder",
  "In the file explorer that appears, look for a folder called": "In the file explorer that appears, look for a folder called",
  "pykrita": "pykrita",
  "or create it.": "or create it.",
  "Enter the": "Enter the",
  "folder and copy the folder location from the address bar.": "folder and copy the folder location from the address bar.",
  "Paste the folder location below.": "Paste the folder location below.",
  "Pykrita Folder Location": "Pykrita Folder Location",
  "Search for \"Command Prompt\" in the Start Menu, right-click and click \"Run as Administrator...\", paste the follow commands and hit Enter:": "Search for \"Command Prompt\" in the Start Menu, right-click and click \"Run as Administrator...\", paste the follow commands and hit Enter:",
  "mklink /j \"<path_to_pykrita>\\krita_diff\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\"\nmklink \"<path_to_pykrita>\\krita_diff.desktop\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\"": "mklink /j \"<path_to_pykrita>\\krita_diff\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\"\nmklink \"<path_to_pykrita>\\krita_diff.desktop\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\"",
  "Linux command:": "Linux command:",
  "ln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\" \"<path_to_pykrita>/krita_diff\"\nln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\" \"<path_to_pykrita>/krita_diff.desktop\"": "ln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\" \"<path_to_pykrita>/krita_diff\"\nln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\" \"<path_to_pykrita>/krita_diff.desktop\"",
  "NOTE": "NOTE",
  ": Symlinks will break if you move or rename the repository or any\nof its parent folders or otherwise change the path such that the symlink\nbecomes invalid. In which case, repeat the above steps with the new": ": Symlinks will break if you move or rename the repository or any\nof its parent folders or otherwise change the path such that the symlink\nbecomes invalid. In which case, repeat the above steps with the new",
  "folder location and (auto-detected) repository location.": "folder location and (auto-detected) repository location.",
  ": Ensure": ": Ensure",
  "webui-user.bat": "webui-user.bat",
  "/": "/",
  "webui-user.sh": "webui-user.sh",
  "contains": "contains",
  "--api": "--api",
  "in": "in",
  "COMMANDLINE_ARGS": "COMMANDLINE_ARGS",
  "!": "!",
  "Enabling the Krita Plugin": "Enabling the Krita Plugin",
  "Restart Krita.": "Restart Krita.",
  "Settings > Configure Krita...": "Settings > Configure Krita...",
  "On the left sidebar, go to": "On the left sidebar, go to",
  "Python Plugin Manager": "Python Plugin Manager",
  "Look for": "Look for",
  "Stable Diffusion Plugin": "Stable Diffusion Plugin",
  "and tick the checkbox.": "and tick the checkbox.",
  "Restart Krita again for changes to take effect.": "Restart Krita again for changes to take effect.",
  "The": "The",
  "SD Plugin": "SD Plugin",
  "docked window should appear on the left of the Krita window. If it does not, look on the menubar under": "docked window should appear on the left of the Krita window. If it does not, look on the menubar under",
  "Settings > Dockers": "Settings > Dockers",
  "Next Steps": "Next Steps",
  "Troubleshooting": "Troubleshooting",
  "Update Guide": "Update Guide",
  "Usage Guide": "Usage Guide",
  "TODO: Control/status panel": "TODO: Control/status panel",
  "https://github.com/Interpause/auto-sd-paint-ext.git": "https://github.com/Interpause/auto-sd-paint-ext.git",
  "The untranslated characters will be translated automatically and will not affect the old translations. Use the function in the lower right corner to easily check and quickly modify the current translation.1,Save the setting;2,Click start button;3,Reload your browser.": "未被翻譯的字句將會自動翻譯且不會影響原有的翻譯。使用右下角的功能來簡單的查看並快速編輯正確的翻譯：1. 儲存設定 2. 點選開始按鈕 3. 重新載入 UI",
  "Translated Status": "翻譯狀態",
  "Start Auto Translate": "開始自動翻譯",
  "Text": "文字",
  "-->": "→",
  "<--": "←",
  "Translated Text": "翻譯文字",
  "To Language": "翻譯為：",
  "zh-CN": "zh-CN",
  "af": "af",
  "sq": "sq",
  "am": "am",
  "ar": "ar",
  "hy": "hy",
  "az": "az",
  "eu": "eu",
  "be": "be",
  "bn": "bn",
  "bs": "bs",
  "bg": "bg",
  "ca": "ca",
  "ceb": "ceb",
  "ny": "ny",
  "co": "co",
  "hr": "hr",
  "cs": "cs",
  "da": "da",
  "nl": "nl",
  "en": "en",
  "eo": "eo",
  "et": "et",
  "tl": "tl",
  "fi": "fi",
  "fr": "fr",
  "fy": "fy",
  "gl": "gl",
  "ka": "ka",
  "de": "de",
  "el": "el",
  "gu": "gu",
  "ht": "ht",
  "ha": "ha",
  "haw": "haw",
  "iw": "iw",
  "hi": "hi",
  "hmn": "hmn",
  "hu": "hu",
  "is": "is",
  "ig": "ig",
  "id": "id",
  "ga": "ga",
  "it": "it",
  "ja": "ja",
  "jw": "jw",
  "kn": "kn",
  "kk": "kk",
  "km": "km",
  "rw": "rw",
  "ko": "ko",
  "ku": "ku",
  "ky": "ky",
  "lo": "lo",
  "la": "la",
  "lv": "lv",
  "lt": "lt",
  "lb": "lb",
  "mk": "mk",
  "mg": "mg",
  "ms": "ms",
  "ml": "ml",
  "mt": "mt",
  "mi": "mi",
  "mr": "mr",
  "mn": "mn",
  "ne": "ne",
  "ps": "ps",
  "fa": "fa",
  "pl": "pl",
  "pt": "pt",
  "pa": "pa",
  "ro": "ro",
  "ru": "ru",
  "sm": "sm",
  "gd": "gd",
  "sr": "sr",
  "st": "st",
  "sn": "sn",
  "sd": "sd",
  "si": "si",
  "sk": "sk",
  "sl": "sl",
  "so": "so",
  "es": "es",
  "su": "su",
  "sw": "sw",
  "sv": "sv",
  "tg": "tg",
  "ta": "ta",
  "tt": "tt",
  "te": "te",
  "th": "th",
  "tr": "tr",
  "tk": "tk",
  "uk": "uk",
  "ur": "ur",
  "ug": "ug",
  "uz": "uz",
  "vi": "vi",
  "cy": "cy",
  "xh": "xh",
  "yi": "yi",
  "yo": "yo",
  "zu": "zu",
  "Select Translater": "翻譯引擎：",
  "free_google": "free_google",
  "free_youdao_zh": "free_youdao_zh",
  "tp_alibaba": "tp_alibaba",
  "tp_argos": "tp_argos",
  "tp_baidu": "tp_baidu",
  "tp_bing": "tp_bing",
  "tp_caiyun": "tp_caiyun",
  "tp_deepl": "tp_deepl",
  "tp_google": "tp_google",
  "tp_iciba": "tp_iciba",
  "tp_iflytek": "tp_iflytek",
  "tp_iflyrec": "tp_iflyrec",
  "tp_itranslate": "tp_itranslate",
  "tp_lingvanex": "tp_lingvanex",
  "tp_mglip": "tp_mglip",
  "tp_modernMt": "tp_modernMt",
  "tp_myMemory": "tp_myMemory",
  "tp_niutrans": "tp_niutrans",
  "tp_papago": "tp_papago",
  "tp_qqFanyi": "tp_qqFanyi",
  "tp_qqTranSmart": "tp_qqTranSmart",
  "tp_reverso": "tp_reverso",
  "tp_sogou": "tp_sogou",
  "tp_translateCom": "tp_translateCom",
  "tp_utibet": "tp_utibet",
  "tp_volcEngine": "tp_volcEngine",
  "tp_yandex": "tp_yandex",
  "tp_youdao": "tp_youdao",
  "tp__alibaba": "tp__alibaba",
  "tp__argos": "tp__argos",
  "tp__baidu": "tp__baidu",
  "tp__bing": "tp__bing",
  "tp__caiyun": "tp__caiyun",
  "tp__deepl": "tp__deepl",
  "tp__google": "tp__google",
  "tp__iciba": "tp__iciba",
  "tp__iflytek": "tp__iflytek",
  "tp__iflyrec": "tp__iflyrec",
  "tp__itranslate": "tp__itranslate",
  "tp__lingvanex": "tp__lingvanex",
  "tp__mglip": "tp__mglip",
  "tp__modernMt": "tp__modernMt",
  "tp__myMemory": "tp__myMemory",
  "tp__niutrans": "tp__niutrans",
  "tp__papago": "tp__papago",
  "tp__qqFanyi": "tp__qqFanyi",
  "tp__qqTranSmart": "tp__qqTranSmart",
  "tp__reverso": "tp__reverso",
  "tp__sogou": "tp__sogou",
  "tp__translateCom": "tp__translateCom",
  "tp__utibet": "tp__utibet",
  "tp__volcEngine": "tp__volcEngine",
  "tp__yandex": "tp__yandex",
  "tp__youdao": "tp__youdao",
  "display both english and target language": "同時顯示原文與翻譯",
  "Save Setting": "儲存設定",
  "Remove Auto Trans": "移除自動翻譯的文字",
  "stable-diffusion-webui-auto-translate-language": "stable-diffusion-webui-auto-translate-language",
  "https://github.com/hyd998877/stable-diffusion-webui-auto-translate-language": "https://github.com/hyd998877/stable-diffusion-webui-auto-translate-language",
  "your select language": "選擇的語言",
  "english": "英語",
  "translate prompt.": "翻譯提示詞。",
  "en2": "en2",
  "translate negative prompt.": "翻譯反向提示詞。",
  "N2": "N2",
  "ui text": "使用者介面文字",
  "translated text": "翻譯",
  "load": "載入",
  "translate": "翻譯",
  "save": "儲存",
  "Image Browser": "圖庫瀏覽器",
  "txt2img-grids": "文生圖網格",
  "img2img-grids": "img2img-網格",
  "Favorites": "收藏夾",
  "Others": "其他",
  "Favorites path from settings: log/images": "Favorites path from settings: log/images",
  "Images directory": "圖像目錄",
  "Sub directory depth": "子目錄深度",
  "Add to / replace in saved directories": "加入至或取代已儲存的目錄",
  "Saved directories": "已儲存的目錄",
  "Remove from saved directories": "從已儲存的目錄移除",
  "Sub directories": "子目錄",
  "Nothing selected": "未選取",
  "Get sub directories": "讀取子目錄",
  "Maintenance": "維護",
  "⚠ Caution: You should only use these options if you know what you are doing. ⚠": "⚠ 警告：只有您知道在做什麼時才使用這些選項。⚠",
  "Status:": "Status:",
  "Last message": "Last message",
  "Rebuild exif cache": "Rebuild exif cache",
  "Delete 0-entries from exif cache": "Delete 0-entries from exif cache",
  "Update directory names in database": "Update directory names in database",
  "From (full path)": "From (full path)",
  "to (full path)": "to (full path)",
  "Reapply ranking after moving files": "Reapply ranking after moving files",
  "Dropdown": "下拉式清單",
  "First Page": "首頁",
  "Prev Page": "上一頁",
  "Page Index": "頁數",
  "Next Page": "下一頁",
  "End Page": "尾頁",
  "ranking": "評等",
  "Next Image After Ranking (To be implemented)": "Next Image After Ranking (To be implemented)",
  "delete next": "刪除後 N 張",
  "Delete": "刪除",
  "also delete off-screen images": "also delete off-screen images",
  "Additional Generation Info": "Additional Generation Info",
  "sort by": "排序方式",
  "cfg scale": "提示詞相關性",
  "steps": "疊代步數",
  "size": "尺寸",
  "model": "模型",
  "model hash": "模型雜湊值",
  "filename keyword": "檔名關鍵字",
  "Filename keyword search": "Filename keyword search",
  "exif keyword": "exif 關鍵字",
  "EXIF keyword search": "EXIF keyword search",
  "Search negative prompt": "搜尋反向提示詞",
  "Yes": "是",
  "Only": "只有",
  "case sensitive": "case sensitive",
  "regex - e.g. ^(?!.*Hires).*$": "regex - e.g. ^(?!.*Hires).*$",
  "ranking filter": "以評等篩選",
  "Ranking filter": "Ranking filter",
  "minimum aesthetic_score": "最小美學分數",
  "Minimum aesthetic_score": "Minimum aesthetic_score",
  "Maximum aesthetic_score": "Maximum aesthetic_score",
  "Generation Info": "Generation Info",
  "File Name": "檔案名",
  "Move to favorites": "移動到收藏夾",
  "Send to txt2img ControlNet": "Send to txt2img ControlNet",
  "Send to img2img ControlNet": "Send to img2img ControlNet",
  "ControlNet number": "ControlNet number",
  "Directory path": "目錄路徑",
  "Move to directory": "移動到目錄",
  "Renew Page": "刷新頁面",
  "set_index": "設定索引",
  "load_switch": "載入開關",
  "to_dir_load_switch": "to_dir_load_switch",
  "turn_page_switch": "翻頁開關",
  "List of active tabs (separated by commas). Available options are txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others. Custom folders are also supported by specifying their path.": "List of active tabs (separated by commas). Available options are txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others. Custom folders are also supported by specifying their path.",
  "Select components to hide": "Select components to hide",
  "Include images in sub directories": "包含子目錄的圖像",
  "Preload images at startup": "在啟動時預加載圖像",
  "Move buttons copy instead of move": "將移動按鈕以複製取代",
  "Print image deletion messages to the console": "將圖像刪除訊息打印到控制台",
  "Move/Copy/Delete matching .txt files": "Move/Copy/Delete matching .txt files",
  "Print warning logs to the console": "在控制台顯示警告訊息",
  "Print debug logs to the console": "在控制台顯示除錯訊息。",
  "Use recycle bin when deleting images": "刪除圖像時丟入資源回收桶",
  "Scan Exif-/.txt-data (initially slower, but required for many features to work)": "Scan Exif-/.txt-data (initially slower, but required for many features to work)",
  "Scan Exif-/.txt-data (slower, but required for exif-keyword-search)": "Scan Exif-/.txt-data (slower, but required for exif-keyword-search)",
  "Change CTRL keybindings to SHIFT": "將 Ctrl 改成 Shift 按鍵",
  "or to CTRL+SHIFT": "或是 Ctrl + Shift",
  "Enable Maintenance tab": "Enable Maintenance tab",
  "Save ranking in image's pnginfo": "Save ranking in image's pnginfo",
  "Number of columns on the page": "每頁列數",
  "stable-diffusion-webui-images-browser": "stable-diffusion-webui-images-browser",
  "https://github.com/AlUlkesh/stable-diffusion-webui-images-browser.git": "https://github.com/AlUlkesh/stable-diffusion-webui-images-browser.git",
  "Input images directory": "輸入圖像目錄",
  "Info, Links and Help": "資訊、連結與幫助",
  "Made by": "製作者：",
  "deforum.github.io": "deforum.github.io",
  ", port for AUTOMATIC1111's webui maintained by": "，由 AUTOMATIC1111 的 WebUI 維護的端口",
  "kabachuha": "kabachuha",
  "FOR HELP CLICK HERE": "需要幫助請點擊這裡",
  "The code for this extension:": "此擴充功能的程式碼：",
  "here": "這裡",
  "Join the": "加入我們",
  "official Deforum Discord": "官方 Deforum Discord",
  "to share your creations and suggestions.": "來分享您的創作和建議。",
  "Official Deforum Wiki:": "官方 Deforum Wiki：",
  "Anime-inclined great guide (by FizzleDorf) with lots of examples:": "充滿動漫風格的詳細指南（由 FizzleDorf 製作），內含許多範例：",
  "For advanced keyframing with Math functions, see": "若欲進階使用數學函數進行關鍵幀動畫，請參考：",
  "Alternatively, use": "或者，您也可以使用",
  "sd-parseq": "sd-parseq",
  "as a UI to define your animation schedules (see the Parseq section in the Keyframes tab).": "作為一個用來定義動畫時間軸的使用者介面（UI），您可以使用 sd-parseq（請參考「關鍵幀（Keyframes）」標籤中的 Parseq 部分）",
  "framesync.xyz": "framesync.xyz",
  "is also a good option, it makes compact math formulae for Deforum keyframes by selecting various waveforms.": "是一個不錯的選擇，它透過選擇不同的波形為 Deforum 關鍵幀生成簡潔的數學公式。",
  "The other site allows for making keyframes using": "另一個網站允許使用",
  "interactive splines and Bezier curves": "互動式的曲線和貝茲曲線進行關鍵幀的製作。",
  "(select Disco output format).": "（選擇Disco輸出格式）。",
  "If you want to use Width/Height which are not multiples of 64, please change noise_type to 'Uniform', in Keyframes --> Noise.": "如果您想使用非 64 的倍數作為寬度/高度，請在關鍵幀 --> 噪音中將 噪音類型（noise_type） 設置為 '均勻分佈（Uniform）'。",
  "If you liked this extension, please": "如果您喜歡這個擴展，請",
  "give it a star on GitHub": "在 GitHub 上給它一顆星星",
  "Keyframes": "關鍵格",
  "Prompts": "提示詞",
  "Init": "初始化",
  "Hybrid Video": "混合影片",
  "Batch name": "批次名稱",
  "Restore Faces, Tiling & more": "恢復臉部、平鋪和更多功能",
  "Restore Faces": "面部修復",
  "DDIM Eta": "DDIM Eta",
  "Pix2Pix img CFG schedule": "Pix2Pix 圖像CFG排程",
  "Resume & Run from file": "繼續執行並從檔案運行",
  "Run from Settings file": "從設定檔運行",
  "Resume Animation": "繼續動畫",
  "Custom settings file": "自訂設定檔",
  "Resume from timestring": "從時間字串繼續執行",
  "Resume timestring": "從時間字串繼續執行",
  "Animation mode": "動畫模式",
  "2D": "2D",
  "3D": "3D",
  "Interpolation": "插值",
  "Video Input": "影片輸入",
  "Border": "邊界",
  "replicate": "複製",
  "wrap": "包裹",
  "Cadence": "節奏",
  "Max frames": "最大幀數量",
  "Guided Images": "Guided Images",
  "*READ ME before you use this mode!*": "*READ ME before you use this mode!*",
  "You can use this as a guided image tool or as a looper depending on your settings in the keyframe images field. \n                               Set the keyframes and the images that you want to show up. \n                               Note: the number of frames between each keyframe should be greater than the tweening frames.": "You can use this as a guided image tool or as a looper depending on your settings in the keyframe images field. \n                               Set the keyframes and the images that you want to show up. \n                               Note: the number of frames between each keyframe should be greater than the tweening frames.",
  "Prerequisites and Important Info:": "Prerequisites and Important Info:",
  "This mode works ONLY with 2D/3D animation modes. Interpolation and Video Input modes aren't supported.": "This mode works ONLY with 2D/3D animation modes. Interpolation and Video Input modes aren't supported.",
  "Set Init tab's strength slider greater than 0. Recommended value (.65 - .80).": "Set Init tab's strength slider greater than 0. Recommended value (.65 - .80).",
  "Set 'seed_behavior' to 'schedule' under the Seed Scheduling section below.": "Set 'seed_behavior' to 'schedule' under the Seed Scheduling section below.",
  "Looping recommendations:": "Looping recommendations:",
  "seed_schedule should start and end on the same seed.": "seed_schedule should start and end on the same seed.",
  "Example: seed_schedule could use 0:(5), 1:(-1), 219:(-1), 220:(5)": "Example: seed_schedule could use 0:(5), 1:(-1), 219:(-1), 220:(5)",
  "The 1st and last keyframe images should match.": "The 1st and last keyframe images should match.",
  "Set your total number of keyframes to be 21 more than the last inserted keyframe image.": "Set your total number of keyframes to be 21 more than the last inserted keyframe image.",
  "Example: Default args should use 221 as total keyframes.": "Example: Default args should use 221 as total keyframes.",
  "Prompts are stored in JSON format. If you've got an error, check it in validator,": "Prompts are stored in JSON format. If you've got an error, check it in validator,",
  "like here": "like here",
  "Enable guided images mode": "Enable guided images mode",
  "Images to use for keyframe guidance": "Images to use for keyframe guidance",
  "Guided images schedules": "Guided images schedules",
  "Image strength schedule": "Image strength schedule",
  "Blend factor max": "Blend factor max",
  "Blend factor slope": "Blend factor slope",
  "Tweening frames schedule": "Tweening frames schedule",
  "Color correction factor": "Color correction factor",
  "Strength": "Strength",
  "CFG": "提示詞相關性",
  "SubSeed": "SubSeed",
  "Step": "Step",
  "Checkpoint": "模型權重存檔點",
  "CLIP Skip": "CLIP Skip",
  "Strength schedule": "Strength schedule",
  "CFG scale schedule": "CFG scale schedule",
  "Seed behavior": "Seed behavior",
  "iter": "iter",
  "fixed": "fixed",
  "ladder": "ladder",
  "alternate": "alternate",
  "schedule": "schedule",
  "Seed iter N": "Seed iter N",
  "Seed schedule": "Seed schedule",
  "Enable Subseed scheduling": "Enable Subseed scheduling",
  "Subseed schedule": "Subseed schedule",
  "Subseed strength schedule": "Subseed strength schedule",
  "Enable steps scheduling": "Enable steps scheduling",
  "Steps schedule": "Steps schedule",
  "Enable sampler scheduling": "啟用取樣器排程",
  "Sampler schedule": "取樣器排程",
  "Enable checkpoint scheduling": "Enable checkpoint scheduling",
  "Checkpoint schedule": "Checkpoint schedule",
  "Enable CLIP skip scheduling": "Enable CLIP skip scheduling",
  "CLIP skip schedule": "CLIP skip schedule",
  "Motion": "Motion",
  "Noise": "Noise",
  "Coherence": "Coherence",
  "Anti Blur": "Anti Blur",
  "Angle": "Angle",
  "Zoom": "Zoom",
  "Translation X": "平移 X",
  "Translation Y": "平移 Y",
  "Translation Z": "平移 Z",
  "Rotation 3D X": "3D 旋轉 X",
  "Rotation 3D Y": "3D 旋轉 Y",
  "Rotation 3D Z": "3D 旋轉 Z",
  "Depth Warping & FOV": "Depth Warping & FOV",
  "Depth Warping": "Depth Warping",
  "Field Of View": "Field Of View",
  "Use depth warping": "Use depth warping",
  "MiDaS weight": "MiDaS weight",
  "Padding mode": "Padding mode",
  "border": "border",
  "reflection": "reflection",
  "zeros": "zeros",
  "Sampling mode": "Sampling mode",
  "bicubic": "bicubic",
  "bilinear": "bilinear",
  "nearest": "nearest",
  "FOV schedule": "FOV schedule",
  "Near schedule": "Near schedule",
  "Far schedule": "Far schedule",
  "Perspective Flip": "Perspective Flip",
  "Enable perspective flip": "Enable perspective flip",
  "Perspective flip theta": "Perspective flip theta",
  "Perspective flip phi": "Perspective flip phi",
  "Perspective flip gamma": "Perspective flip gamma",
  "Perspective flip fv": "Perspective flip fv",
  "Noise type": "Noise type",
  "perlin": "perlin",
  "Noise schedule": "Noise schedule",
  "Perlin octaves": "Perlin octaves",
  "Perlin persistence": "Perlin persistence",
  "Color coherence": "Color coherence",
  "Match Frame 0 HSV": "Match Frame 0 HSV",
  "Match Frame 0 LAB": "Match Frame 0 LAB",
  "Match Frame 0 RGB": "Match Frame 0 RGB",
  "Color force Grayscale": "Color force Grayscale",
  "Color coherence video every N frames": "Color coherence video every N frames",
  "Contrast schedule": "Contrast schedule",
  "Reroll blank frames": "Reroll blank frames",
  "reroll": "reroll",
  "interrupt": "interrupt",
  "Kernel schedule": "Kernel schedule",
  "Sigma schedule": "Sigma schedule",
  "Amount schedule": "Amount schedule",
  "Threshold schedule": "Threshold schedule",
  "*Important* notes on Prompts": "*Important* notes on Prompts",
  "Please always keep values in math functions above 0.": "Please always keep values in math functions above 0.",
  "There is *no* Batch mode like in vanilla deforum. Please Use the txt2img tab for that.": "There is *no* Batch mode like in vanilla deforum. Please Use the txt2img tab for that.",
  "For negative prompts, please write your positive prompt, then --neg ugly, text, assymetric, or any other negative tokens of your choice. OR:": "For negative prompts, please write your positive prompt, then --neg ugly, text, assymetric, or any other negative tokens of your choice. OR:",
  "Use the negative_prompts field to automatically append all words as a negative prompt. *Don't* add --neg in the negative_prompts field!": "Use the negative_prompts field to automatically append all words as a negative prompt. *Don't* add --neg in the negative_prompts field!",
  "Prompts are stored in JSON format. If you've got an error, check it in a": "Prompts are stored in JSON format. If you've got an error, check it in a",
  "JSON Validator": "JSON Validator",
  "Prompts positive": "Prompts positive",
  "Prompts negative": "Prompts negative",
  "Composable Mask scheduling": "Composable Mask scheduling",
  "To enable, check use_mask in the Init tab": "To enable, check use_mask in the Init tab",
  "Supports boolean operations: (! - negation, & - and, | - or, ^ - xor, \\ - difference, () - nested operations)": "Supports boolean operations: (! - negation, & - and, | - or, ^ - xor, \\ - difference, () - nested operations)",
  "default variables: in \\{\\}, like \\{init_mask\\}, \\{video_mask\\}, \\{everywhere\\}": "default variables: in \\{\\}, like \\{init_mask\\}, \\{video_mask\\}, \\{everywhere\\}",
  "masks from files: in [], like [mask1.png]": "masks from files: in [], like [mask1.png]",
  "description-based:": "description-based:",
  "word masks": "word masks",
  "in <>, like <apple>, <hair>": "in <>, like <apple>, <hair>",
  "Mask schedule": "Mask schedule",
  "Use noise mask": "Use noise mask",
  "Noise mask schedule": "Noise mask schedule",
  "Image Init": "Image Init",
  "Video Init": "Video Init",
  "Mask Init": "Mask Init",
  "Use init": "Use init",
  "Strength 0 no init": "Strength 0 no init",
  "Init image": "Init image",
  "Video init path": "Video init path",
  "Extract from frame": "Extract from frame",
  "Extract to frame": "Extract to frame",
  "Extract nth frame": "Extract nth frame",
  "Overwrite extracted frames": "Overwrite extracted frames",
  "Use mask video": "Use mask video",
  "Video mask path": "Video mask path",
  "Use mask": "Use mask",
  "Use alpha as mask": "Use alpha as mask",
  "Invert mask": "Invert mask",
  "Overlay mask": "Overlay mask",
  "Mask file": "Mask file",
  "Mask overlay blur": "Mask overlay blur",
  "Mask fill": "Mask fill",
  "Full res mask": "Full res mask",
  "Full res mask padding": "Full res mask padding",
  "Parseq": "Parseq",
  "Use an": "Use an",
  "sd-parseq manifest": "sd-parseq manifest",
  "for your animation (leave blank to ignore).": "for your animation (leave blank to ignore).",
  "Note that parseq overrides:": "Note that parseq overrides:",
  "Run: seed, subseed, subseed strength.": "Run: seed, subseed, subseed strength.",
  "Keyframes: generation settings (noise, strength, contrast, scale).": "Keyframes: generation settings (noise, strength, contrast, scale).",
  "Keyframes: motion parameters for 2D and 3D (angle, zoom, translation, rotation, perspective flip).": "Keyframes: motion parameters for 2D and 3D (angle, zoom, translation, rotation, perspective flip).",
  "Parseq does": "Parseq does",
  "not": "not",
  "override:": "override:",
  "Run: Sampler, Width, Height, tiling, resize seed.": "Run: Sampler, Width, Height, tiling, resize seed.",
  "Keyframes: animation settings (animation mode, max frames, border)": "Keyframes: animation settings (animation mode, max frames, border)",
  "Keyframes: coherence (color coherence & cadence)": "Keyframes: coherence (color coherence & cadence)",
  "Keyframes: depth warping": "Keyframes: depth warping",
  "Output settings: all settings (including fps and max frames)": "Output settings: all settings (including fps and max frames)",
  "Parseq Manifest (JSON or URL)": "Parseq Manifest (JSON or URL)",
  "Use delta values for movement parameters": "Use delta values for movement parameters",
  "Requires the": "Requires the",
  "extension to be installed.": "extension to be installed.",
  "Due to ControlNet base extension's inner works it needs its models to be located at 'extensions/deforum-for-automatic1111-webui/models'. So copy, symlink or move them there until a more elegant solution is found. And, as of now, it requires use_init checked for the first run. The ControlNet extension version used in the dev process is a24089a62e70a7fae44b7bf35b51fd584dd55e25, if even with all the other options above used it still breaks, upgrade/downgrade your CN version to this one.": "Due to ControlNet base extension's inner works it needs its models to be located at 'extensions/deforum-for-automatic1111-webui/models'. So copy, symlink or move them there until a more elegant solution is found. And, as of now, it requires use_init checked for the first run. The ControlNet extension version used in the dev process is a24089a62e70a7fae44b7bf35b51fd584dd55e25, if even with all the other options above used it still breaks, upgrade/downgrade your CN version to this one.",
  "ControlNet not found. Please install it :)": "ControlNet not found. Please install it :)",
  "Please, change animation mode to 2D or 3D to enable Hybrid Mode": "Please, change animation mode to 2D or 3D to enable Hybrid Mode",
  "Info & Help": "Info & Help",
  "Hybrid Video Compositing in 2D/3D Mode": "Hybrid Video Compositing in 2D/3D Mode",
  "by": "by",
  "reallybigname": "reallybigname",
  "Composite video with previous frame init image in": "Composite video with previous frame init image in",
  "2D or 3D animation_mode": "2D or 3D animation_mode",
  "(not for Video Input mode)": "(not for Video Input mode)",
  "Uses your": "Uses your",
  "settings for": "settings for",
  "video_init_path, extract_nth_frame, overwrite_extracted_frames": "video_init_path, extract_nth_frame, overwrite_extracted_frames",
  "In Keyframes tab, you can also set": "In Keyframes tab, you can also set",
  "color_coherence": "color_coherence",
  "= '": "= '",
  "'": "'",
  "color_coherence_video_every_N_frames": "color_coherence_video_every_N_frames",
  "lets you only match every N frames": "lets you only match every N frames",
  "Color coherence may be used with hybrid composite off, to just use video color.": "Color coherence may be used with hybrid composite off, to just use video color.",
  "Hybrid motion may be used with hybrid composite off, to just use video motion.": "Hybrid motion may be used with hybrid composite off, to just use video motion.",
  "Hybrid Video Schedules": "Hybrid Video Schedules",
  "The alpha schedule controls overall alpha for video mix, whether using a composite mask or not.": "The alpha schedule controls overall alpha for video mix, whether using a composite mask or not.",
  "hybrid_comp_mask_blend_alpha_schedule": "hybrid_comp_mask_blend_alpha_schedule",
  "only affects the 'Blend'": "only affects the 'Blend'",
  "hybrid_comp_mask_type": "hybrid_comp_mask_type",
  "Mask contrast schedule is from 0-255. Normal is 1. Affects all masks.": "Mask contrast schedule is from 0-255. Normal is 1. Affects all masks.",
  "Autocontrast low/high cutoff schedules 0-100. Low 0 High 100 is full range.": "Autocontrast low/high cutoff schedules 0-100. Low 0 High 100 is full range.",
  "(": "(",
  "hybrid_comp_mask_auto_contrast": "hybrid_comp_mask_auto_contrast",
  "must be enabled": "must be enabled",
  ")": ")",
  "Click Here": "Click Here",
  "for more info/ a Guide.": "for more info/ a Guide.",
  "Hybrid Settings": "Hybrid Settings",
  "Generate inputframes": "Generate inputframes",
  "Hybrid composite": "Hybrid composite",
  "First frame as init image": "First frame as init image",
  "Motion use prev img": "Motion use prev img",
  "Hybrid motion": "Hybrid motion",
  "Optical Flow": "Optical Flow",
  "Perspective": "Perspective",
  "Affine": "Affine",
  "Flow method": "Flow method",
  "DIS Medium": "DIS Medium",
  "Farneback": "Farneback",
  "Comp mask type": "Comp mask type",
  "Depth": "Depth",
  "Video Depth": "Video Depth",
  "Difference": "Difference",
  "Comp mask equalize": "Comp mask equalize",
  "Before": "Before",
  "After": "After",
  "Both": "Both",
  "Comp mask auto contrast": "Comp mask auto contrast",
  "Comp mask inverse": "Comp mask inverse",
  "Comp save extra frames": "Comp save extra frames",
  "Hybrid Schedules": "Hybrid Schedules",
  "Comp alpha schedule": "Comp alpha schedule",
  "Comp mask blend alpha schedule": "Comp mask blend alpha schedule",
  "Comp mask contrast schedule": "Comp mask contrast schedule",
  "Comp mask auto contrast cutoff high schedule": "Comp mask auto contrast cutoff high schedule",
  "Comp mask auto contrast cutoff low schedule": "Comp mask auto contrast cutoff low schedule",
  "Humans Masking": "Humans Masking",
  "Generate human masks": "Generate human masks",
  "PNGs": "PNGs",
  "Video Output Settings": "Video Output Settings",
  "FPS": "FPS",
  "Output format": "Output format",
  "FFMPEG mp4": "FFMPEG mp4",
  "Add soundtrack": "Add soundtrack",
  "Init Video": "Init Video",
  "Soundtrack path": "Soundtrack path",
  "Skip video for run all": "Skip video for run all",
  "Store frames in ram": "Store frames in ram",
  "Save depth maps": "Save depth maps",
  "Make GIF": "Make GIF",
  "Upscale": "Upscale",
  "Upscale model": "Upscale model",
  "realesr-animevideov3": "realesr-animevideov3",
  "realesrgan-x4plus": "realesrgan-x4plus",
  "realesrgan-x4plus-anime": "realesrgan-x4plus-anime",
  "Upscale factor": "Upscale factor",
  "x2": "x2",
  "x3": "x3",
  "x4": "x4",
  "Keep Imgs": "Keep Imgs",
  "FFmpeg settings": "FFmpeg settings",
  "CRF": "CRF",
  "Preset": "Preset",
  "veryslow": "veryslow",
  "slower": "slower",
  "slow": "slow",
  "medium": "medium",
  "fast": "fast",
  "faster": "faster",
  "veryfast": "veryfast",
  "superfast": "superfast",
  "ultrafast": "ultrafast",
  "Location": "Location",
  "Frame Interoplation": "Frame Interoplation",
  "Video Upscaling": "Video Upscaling",
  "Frames to Video": "Frames to Video",
  "Important notes and Help": "Important notes and Help",
  "Use": "Use",
  "RIFE": "RIFE",
  "FILM": "FILM",
  "Frame Interpolation to smooth out, slow-mo (or both) any video.": "Frame Interpolation to smooth out, slow-mo (or both) any video.",
  "Supported engines:": "Supported engines:",
  "RIFE v4.6 and FILM.": "RIFE v4.6 and FILM.",
  "Important notes:": "Important notes:",
  "Frame Interpolation will *not* run if any of the following are enabled: 'Store frames in ram' / 'Skip video for run all'.": "Frame Interpolation will *not* run if any of the following are enabled: 'Store frames in ram' / 'Skip video for run all'.",
  "Audio (if provided) will *not* be transferred to the interpolated video if Slow-Mo is enabled.": "Audio (if provided) will *not* be transferred to the interpolated video if Slow-Mo is enabled.",
  "'add_soundtrack' and 'soundtrack_path' aren't being honoured in \"Interpolate an existing video\" mode. Original vid audio will be used instead with the same slow-mo rules above.": "'add_soundtrack' and 'soundtrack_path' aren't being honoured in \"Interpolate an existing video\" mode. Original vid audio will be used instead with the same slow-mo rules above.",
  "Engine": "Engine",
  "RIFE v4.6": "RIFE v4.6",
  "Slow Mo": "Slow Mo",
  "Interp X": "Interp X",
  "Slow-Mo X": "Slow-Mo X",
  "Interpolate an existing video": "Interpolate an existing video",
  "Video to Interpolate": "Video to Interpolate",
  "In Frame Count": "In Frame Count",
  "In FPS": "In FPS",
  "Interpolated Vid FPS": "Interpolated Vid FPS",
  "*Interpolate uploaded video*": "*Interpolate uploaded video*",
  "* check your CLI for outputs": "* check your CLI for outputs",
  "Video to Upscale": "Video to Upscale",
  "Upscale V2": "Upscale V2",
  "Upscale V1": "Upscale V1",
  "In Res": "In Res",
  "Out Res": "Out Res",
  "*Upscale uploaded video*": "*Upscale uploaded video*",
  "Path name modifier": "Path name modifier",
  "x0_pred": "x0_pred",
  "x": "x",
  "Important Notes:": "Important Notes:",
  "Enter relative to webui folder or Full-Absolute path, and make sure it ends with something like this: '20230124234916_%05d.png', just replace 20230124234916 with your batch ID. The %05d is important, don't forget it!": "Enter relative to webui folder or Full-Absolute path, and make sure it ends with something like this: '20230124234916_%05d.png', just replace 20230124234916 with your batch ID. The %05d is important, don't forget it!",
  "MP4 path": "MP4 path",
  "Render steps": "Render steps",
  "*Stitch frames to video*": "*Stitch frames to video*",
  "INVISIBLE": "INVISIBLE",
  "Mask contrast adjust": "Mask contrast adjust",
  "Mask brightness adjust": "Mask brightness adjust",
  "from_img2img_instead_of_link": "from_img2img_instead_of_link",
  "Perlin W": "Perlin W",
  "Perlin H": "Perlin H",
  "Filename format": "Filename format",
  "save_settings": "save_settings",
  "save_samples": "save_samples",
  "display_samples": "display_samples",
  "Subseed controls & More": "Subseed controls & More",
  "Enable subseed controls": "Enable subseed controls",
  "N Batch": "N Batch",
  "Save sample per step": "Save sample per step",
  "Show sample per step": "Show sample per step",
  "Click here after the generation to show the video": "Click here after the generation to show the video",
  "Close the video": "Close the video",
  "Deforum extension for auto1111 — version 2.2b": "Deforum extension for auto1111 — version 2.2b",
  "* Paths can be relative to webui folder OR full - absolute": "* Paths can be relative to webui folder OR full - absolute",
  "General Settings File": "General Settings File",
  "Video Settings File": "Video Settings File",
  "Save Video Settings": "Save Video Settings",
  "Load Video Settings": "Load Video Settings",
  "deforum-for-automatic1111-webui": "Deforum",
  "https://github.com/deforum-art/deforum-for-automatic1111-webui.git": "https://github.com/deforum-art/deforum-for-automatic1111-webui.git",
  "Latent Mirror mode": "鏡像潛在變數模式",
  "Alternate Steps": "交替疊代",
  "Blend Average": "平均混合",
  "Latent Mirror style": "潛在變數鏡像樣式",
  "Vertical Mirroring": "垂直鏡像",
  "Horizontal Mirroring": "水平鏡像",
  "Horizontal+Vertical Mirroring": "垂直+水平鏡像",
  "90 Degree Rotation": "90 度旋轉",
  "180 Degree Rotation": "180 度旋轉",
  "Roll Channels": "三原色頻道輪替",
  "X panning": "沿 X 軸滾動",
  "Y panning": "沿 Y 軸滾動",
  "Maximum steps fraction to mirror at": "鏡像干涉止步於總疊代步數的",
  "SD-latent-mirroring": "SD-latent-mirroring",
  "https://github.com/dfaker/SD-latent-mirroring.git": "https://github.com/dfaker/SD-latent-mirroring.git",
  "Plot": "圖表",
  "Max Image Size": "最大圖像尺寸",
  "Max Batch Count": "最大批次數量",
  "Run benchmark": "執行效能評測",
  "Load results": "載入結果",
  "a1111-stable-diffusion-webui-vram-estimator": "a1111-stable-diffusion-webui-vram-estimator",
  "https://github.com/space-nuko/a1111-stable-diffusion-webui-vram-estimator.git": "https://github.com/space-nuko/a1111-stable-diffusion-webui-vram-estimator.git",
  "Posex": "Posex",
  "Send this image to ControlNet.": ">> ControlNet",
  "Target ControlNet number": "目標 ControlNet 號碼",
  "https://github.com/hnmr293/posex.git": "https://github.com/hnmr293/posex.git",
  "Add": "加入",
  "Reset": "重置",
  "Load from JSON": "從 JSON 載入",
  "Detect from image": "從圖像偵測",
  "Add Background image": "加入背景圖像",
  "json": "json",
  "Save JSON": "儲存為 JSON",
  "Save PNG": "儲存為 PNG",
  "Send to": "發送至",
  "openpose-editor": "openPose 編輯器",
  "https://github.com/fkunn1326/openpose-editor.git": "https://github.com/fkunn1326/openpose-editor.git",
  "Tagger": "Tagger",
  "Single process": "Single process",
  "Batch from directory": "Batch from directory",
  "Use recursive with glob pattern": "Use recursive with glob pattern",
  "Output filename format": "Output filename format",
  "Output filename formats": "Output filename formats",
  "Related to original file": "Related to original file",
  "[name]": "[name]",
  ": Original filename without extension": ": Original filename without extension",
  "[extension]": "[extension]",
  ": Original extension": ": Original extension",
  "[hash:<algorithms>]": "[hash:<algorithms>]",
  ": Original extension\nAvailable algorithms:": ": Original extension\nAvailable algorithms:",
  "sha1, blake2s, shake_256, sha256, md5-sha1, sha512_256, shake_128, mdc2, ripemd160, whirlpool, md5, sha3_384, sha512, sha3_512, blake2b, sha224, sm3, sha512_224, sha3_224, sha384, md4, sha3_256": "sha1, blake2s, shake_256, sha256, md5-sha1, sha512_256, shake_128, mdc2, ripemd160, whirlpool, md5, sha3_384, sha512, sha3_512, blake2b, sha224, sm3, sha512_224, sha3_224, sha384, md4, sha3_256",
  "Related to output file": "Related to output file",
  "[output_extension]": "[output_extension]",
  ": Output extension (has no dot)": ": Output extension (has no dot)",
  "Examples": "Examples",
  "Original filename without extension": "Original filename without extension",
  "[name].[output_extension]": "[name].[output_extension]",
  "Original file's hash (good for deleting duplication)": "Original file's hash (good for deleting duplication)",
  "[hash:sha1].[output_extension]": "[hash:sha1].[output_extension]",
  "Action on existing caption": "Action on existing caption",
  "Remove duplicated tag": "Remove duplicated tag",
  "Save with JSON": "Save with JSON",
  "default.json": "default.json",
  "wd14-convnext": "wd14-convnext",
  "wd14-convnext-v2": "wd14-convnext-v2",
  "wd14-convnext-v2-git": "wd14-convnext-v2-git",
  "wd14-swinv2-v2": "wd14-swinv2-v2",
  "wd14-swinv2-v2-git": "wd14-swinv2-v2-git",
  "wd14-vit": "wd14-vit",
  "wd14-vit-v2": "wd14-vit-v2",
  "wd14-vit-v2-git": "wd14-vit-v2-git",
  "Unload all interrogate models": "Unload all interrogate models",
  "Threshold": "Threshold",
  "Additional tags (split by comma)": "Additional tags (split by comma)",
  "Exclude tags (split by comma)": "Exclude tags (split by comma)",
  "Sort by alphabetical order": "Sort by alphabetical order",
  "Include confident of tags matches in results": "Include confident of tags matches in results",
  "Use spaces instead of underscore": "Use spaces instead of underscore",
  "Excudes (split by comma)": "Excudes (split by comma)",
  "Escape brackets": "Escape brackets",
  "Unload model after running": "Unload model after running",
  "Rating confidents": "Rating confidents",
  "Tag confidents": "Tag confidents",
  "stable-diffusion-webui-wd14-tagger": "stable-diffusion-webui-wd14-tagger",
  "https://github.com/toriato/stable-diffusion-webui-wd14-tagger.git": "https://github.com/toriato/stable-diffusion-webui-wd14-tagger.git",
  "/path/to/images or /path/to/images/**/*": "/path/to/images or /path/to/images/**/*",
  "Leave blank to save images to the same path.": "Leave blank to save images to the same path.",
  "Leave blank to use same filename as original.": "Leave blank to use same filename as original.",
  "Found tags": "Found tags",
  "Main": "Main",
  "LAB Tools": "LAB Tools",
  "Guide": "Guide",
  "Abysz LAB 0.1.9 Temporal coherence tools": "Abysz LAB 0.1.9 Temporal coherence tools",
  "DFI Render": "DFI Render",
  "Original frames folder": "Original frames folder",
  "Generated frames folder": "Generated frames folder",
  "Output folder": "Output folder",
  "Info": "資訊",
  "The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.": "The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.",
  "Source denoise:": "Source denoise:",
  "A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.": "A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.",
  "(This is a demanding algorithm)": "(This is a demanding algorithm)",
  "DFI Tolerance:": "DFI Tolerance:",
  "Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.": "Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.",
  "This parameter commands the new dynamic algorithm.": "This parameter commands the new dynamic algorithm.",
  "DFI Expand:": "DFI Expand:",
  "DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.": "DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.",
  "Source Denoise": "Source Denoise",
  "DFI Tolerance": "DFI Tolerance",
  "DFI Expand": "DFI Expand",
  "Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.": "Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.",
  "The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).": "The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).",
  "Preview DFI Map": "Preview DFI Map",
  "Preview amount. 0 = Quick shoot": "Preview amount. 0 = Quick shoot",
  "Inter Denoise:": "Inter Denoise:",
  "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.": "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.",
  "Inter Blur:": "Inter Blur:",
  "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.": "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.",
  "Corruption Refresh:": "Corruption Refresh:",
  "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.": "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.",
  "Corruption Preserve:": "Corruption Preserve:",
  "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.": "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.",
  "Smooth:": "Smooth:",
  "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.": "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.",
  "Inter Denoise": "Inter Denoise",
  "Inter Denoise Size": "Inter Denoise Size",
  "Inter Denoise FPD": "Inter Denoise FPD",
  "Inter Blur": "Inter Blur",
  "The new dynamic algorithm will handle these parameters. Activate them only for manual control.": "The new dynamic algorithm will handle these parameters. Activate them only for manual control.",
  "Corruption Refresh (Lower = Faster)": "Corruption Refresh (Lower = Faster)",
  "Corruption Preserve": "Corruption Preserve",
  "Smooth": "Smooth",
  "Frames to render. 0=ALL": "Frames to render. 0=ALL",
  "Run DFI": "Run DFI",
  "Show output folder video": "Show output folder video",
  "Deflickers Playground": "Deflickers Playground",
  "Frames folder": "Frames folder",
  "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.": "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.",
  "Blend:": "Blend:",
  "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.": "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.",
  "Overlay:": "Overlay:",
  "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.": "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.",
  "Normalize:": "Normalize:",
  "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.": "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.",
  "BLEND (0=Off)": "BLEND (0=Off)",
  "OVERLAY (0=Off)": "OVERLAY (0=Off)",
  "NORMALIZE (0=Off))": "NORMALIZE (0=Off))",
  "Deflickers": "Deflickers",
  "Style Fuse": "Style Fuse",
  "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.": "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.",
  "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.": "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.",
  "Style frames": "Style frames",
  "Video frames": "Video frames",
  "Fuse Strength": "Fuse Strength",
  "Fuse": "Fuse",
  "Video extract": "Video extract",
  "Video path": "Video path",
  "Fps. 0=Original": "Fps. 0=Original",
  "Extract": "Extract",
  "What DFI does?": "What DFI does?",
  "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext": "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext",
  "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.": "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.",
  "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.": "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.",
  "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.": "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.",
  "Usage strategies": "Usage strategies",
  "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.": "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.",
  "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.": "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.",
  "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.": "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.",
  "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.": "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.",
  "Abysz-LAB-Ext": "Abysz-LAB-Ext",
  "https://github.com/AbyszOne/Abysz-LAB-Ext": "https://github.com/AbyszOne/Abysz-LAB-Ext",
  "The RAW frames you have used as base for IA generation.": "The RAW frames you have used as base for IA generation.",
  "The frames of AI generated video": "The frames of AI generated video",
  "Remember that each generation overwrites previous frames in the same folder.": "Remember that each generation overwrites previous frames in the same folder.",
  "STAND BY...": "STAND BY...",
  "Frames to process": "Frames to process",
  "Processed frames": "Processed frames",
  "Style to fuse": "Style to fuse",
  "Remember to use same fps as generated video for DFI": "Remember to use same fps as generated video for DFI",
  "Tokenizer": "標記解析器",
  "Before your text is sent to the neural network, it gets turned into numbers in a process called tokenization. These tokens are how the neural network reads and interprets text. Thanks to our great friends at Shousetsu愛 for inspiration for this feature.": "在你的文本被發送到神經網路之前，它在一個稱為標記化的過程中被轉化為數字。這些標記是神經網路閱讀和解釋文本的方式。感謝我們的好朋友 Shousetsu愛 為這個功能帶來的靈感",
  "Text input": "文本輸入",
  "ID input": "ID 輸入",
  "Tokenize": "標記拆分",
  "Tokens": "標記",
  "stable-diffusion-webui-tokenizer": "stable-diffusion-webui-tokenizer",
  "Prompt for tokenization": "給標記化準備的提示詞",
  "Ids for tokenization (example: 9061, 631, 736)": "用於標記化的 ID（例：9061，631，736）",
  "https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer.git",
  "3D Model Loader": "3D 模型載入器",
  "Light": "Light",
  "Position/Rotate X": "Position/Rotate X",
  "Position/Rotate Y": "Position/Rotate Y",
  "Position/Rotate Z": "Position/Rotate Z",
  "Show Ground": "顯示地面",
  "Show Grid": "顯示網格",
  "Show Axis": "顯示軸",
  "Background Color": "背景顏色",
  "Ground Color": "地面顏色",
  "Light Color": "Light Color",
  "Model Scale": "Model Scale",
  "Load Model": "Load Model",
  "Play/Pause": "Play/Pause",
  "Stop": "停止",
  "3D Model": "3D 模型",
  "Canvas Background Color": "畫布背景顏色",
  "Canvas Ground Color": "畫布地面顏色",
  "sd-3dmodel-loader": "sd-3dmodel-loader",
  "https://github.com/jtydhr88/sd-3dmodel-loader.git": "https://github.com/jtydhr88/sd-3dmodel-loader.git",
  "Conditioning Highres": "調整高解析度",
  "Conditioning Highres.fix strength (for sd-v1-5-inpainting)": "高解析度修復原圖調節強度（專為 sd-v1-5-inpainting 設計）",
  "Cond.fix: Disabled (none)": "條件修復：停用（無）",
  "Cond.fix: Empty": "條件修復： 無",
  "Cond.fix: Lowest": "條件修復： 最小",
  "Cond.fix: Low": "條件修復： 小",
  "Cond.fix: Medium": "條件修復： 中",
  "Cond.fix: High (recommended)": "條件修復： 高（推薦）",
  "Cond.fix: Highest": "條件修復： 最高",
  "Cond.fix: Full": "條件修復： 完全",
  "stable-diffusion-webui-conditioning-highres-fix": "stable-diffusion-webui-conditioning-highres-fix",
  "https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix.git": "https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix.git",
  "Wildcards Manager": "萬用字元管理器",
  "Dynamic Prompts enabled": "啟用動態提示詞",
  "Combinatorial generation": "組合生成",
  "Max generations (0 = all combinations - the batch count value is ignored)": "最大產生數（0 = 所有組合 - 忽略批次數值）",
  "Combinatorial batches": "組合批次",
  "Prompt Magic": "提示詞魔法",
  "Magic prompt": "魔法提示詞",
  "Max magic prompt length": "魔法提示詞最大長度",
  "Magic prompt creativity": "魔法提示詞創意",
  "Magic prompt model": "魔法提示詞模型",
  "Gustavosta/MagicPrompt-Stable-Diffusion": "Gustavosta/MagicPrompt-Stable-Diffusion",
  "daspartho/prompt-extend": "daspartho/prompt-extend",
  "succinctly/text2image-prompt-generator": "succinctly/text2image-prompt-generator",
  "microsoft/Promptist": "microsoft/Promptist",
  "AUTOMATIC/promptgen-lexart": "AUTOMATIC/promptgen-lexart",
  "AUTOMATIC/promptgen-majinai-safe": "AUTOMATIC/promptgen-majinai-safe",
  "AUTOMATIC/promptgen-majinai-unsafe": "AUTOMATIC/promptgen-majinai-unsafe",
  "kmewhort/stable-diffusion-prompt-bolster": "kmewhort/stable-diffusion-prompt-bolster",
  "Gustavosta/MagicPrompt-Dalle": "Gustavosta/MagicPrompt-Dalle",
  "Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator": "Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator",
  "Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator": "Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator",
  "crumb/bloom-560m-RLHF-SD2-prompter-aesthetic": "crumb/bloom-560m-RLHF-SD2-prompter-aesthetic",
  "Meli/GPT2-Prompt": "Meli/GPT2-Prompt",
  "DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M": "DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M",
  "Magic prompt blocklist regex": "魔法提示詞黑名單。",
  "Magic Prompt batch size": "魔法提示詞批次大小",
  "I'm feeling lucky": "手氣不錯",
  "Attention grabber": "隨機關鍵詞吸引註意力",
  "Minimum attention": "最小注意力",
  "Maximum attention": "最大注意力",
  "Don't apply to negative prompts": "不用於反向提示詞。",
  "Need help?": "需要幫助？",
  "Syntax cheatsheet": "語法速查表",
  "Tutorial": "教學",
  "Discussions": "討論串",
  "Report a bug": "回報錯誤",
  "Combinations": "組合",
  "Choose a number of terms from a list, in this case we choose two artists:": "從列表中選幾項，這裡選了兩個藝術家",
  "{2$$artist1|artist2|artist3}": "{2$$artist1|artist2|artist3}",
  "If $$ is not provided, then 1$$ is assumed.": "若沒提供 $$，默認為 1$$",
  "If the chosen number of terms is greater than the available terms, then some terms will be duplicated, otherwise chosen terms will be unique. This is useful in the case of wildcards, e.g.": "選的項數多於提供的項數時，有些項會重複，其餘情況各選項會保持唯一；\n重複對於萬用字元很有用，例如：",
  "{2$$__artist__}": "{2$$__artist__}",
  "is equivalent to": "等同於",
  "{2$$__artist__|__artist__}": "{2$$__artist__|__artist__}",
  "A range can be provided:": "項數可以有範圍",
  "{1-3$$artist1|artist2|artist3}": "{1-3$$artist1|artist2|artist3}",
  "In this case, a random number of artists between 1 and 3 is chosen.": "此例中，會從中隨機選 1 至 3 個藝術家",
  "Options can be given weights:": "可以給選項權重：",
  "{2::artist1|artist2}": "{2::artist1|artist2}",
  "In this case, artist1 will be chosen twice as often as artist2.": "此例中，藝術家 1 將會比藝術家 2 高兩倍的機會被選中",
  "Wildcards can be used and the joiner can also be specified:": "可以用萬用字元，也可以指定拼接符",
  "{{1-$$and$$__adjective__}}": "{{1-3$$and$$__adjective__}}",
  "Here, a random number between 1 and 3 words from adjective.txt will be chosen and joined together with the word 'and' instead of the default comma.": "此處，會從 adjective.txt 中選取隨機 1 至 3 行，以 'and'（而不是默認的逗號）拼接",
  "Wildcards": "萬用字元",
  "Find and manage wildcards in the Wildcards Manager tab.": "在萬用字元管理器分頁中尋找並管理萬用字元",
  "__<folder>/mywildcards__": "__<folder>/mywildcards__",
  "will then become available.": "目錄內的文字檔案將可以被讀取。",
  "Find more settings on the": "尋找更多設定請前往",
  "Jinja2 templates": "Jinja2 模板",
  "Enable Jinja2 templates": "啟用 Jinja2 模板",
  "Help for Jinja2 templates": "Jinja2 模板幫助",
  "Jinja2 templates is an experimental feature for advanced template generation. It is not recommended for general use unless you are comfortable with writing scripts.": "Jinja2 範本是一個用於進階範本產生的實驗性特性。如果不熟悉編寫指令碼，正常使用時不建議啟用",
  "Literals": "字面值",
  "I love red roses": "I love red roses",
  "Random choices": "隨機選擇",
  "I love {{ choice('red', 'blue', 'green') }} roses": "I love {{ choice('red', 'blue', 'green') }} roses",
  "This will randomly choose one of the three colors.": "會隨機從三種顏色中選一個",
  "Iterations": "迭代次數",
  "{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}": "{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}",
  "This will produce three prompts, one for each color. The prompt tag is used to mark the text that will be used as the prompt. If no prompt tag is present then only one prompt is assumed": "會產生三條提示詞，每個顏色各一條；\n 提示詞標籤用於標記作為提示詞的文字；\n 如果沒有提示詞標籤則默認為僅一條提示詞",
  "{% for colour in wildcard(\"__colours__\") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}": "{% for colour in wildcard(\"__colours__\") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}",
  "This will produce one prompt for each colour in the wildcard.txt file.": "會為 colours.txt 中的每個顏色產生一條提示詞",
  "Conditionals": "條件",
  "{% for colour in [\"red\", \"blue\", \"green\"] %}\n        {% if colour == \"red\"}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}": "{% for colour in [\"red\", \"blue\", \"green\"] %}\n        {% if colour == \"red\"}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}",
  "This will produce the following prompts:": "會產生下列提示詞",
  "I hate blue roses": "I hate blue roses",
  "I hate green roses": "I hate green roses",
  "Jinja2 templates are based on the Jinja2 template engine. For more information see the": "Jinja2 模板基於 Jinja2 模板引擎，更多訊息參考",
  "Jinja2 documentation.": "Jinja2 文件資料。",
  "If you are using these templates, please let me know if they are useful.": "如果你在用這些模板，請告訴我它們是否有用",
  "Advanced options": "進階選項",
  "Some settings have been moved to the settings tab. Find them in the Dynamic Prompts section.": "一些選像已移至設定。 位於動態提示詞部分。",
  "Unlink seed from prompt": "將隨機種子與提示詞解綁",
  "Fixed seed": "固定隨機種子",
  "Write raw prompt to image": "將提示詞寫入圖像",
  "Don't generate images": "不產生圖像",
  "Write prompts to file": "將提示詞寫入檔案",
  "Manage wildcards for Dynamic Prompts": "管理動態提示詞擴充功能的萬用字元",
  "1. Create your wildcard library by copying a collection using the dropdown below.": "1. 使用下方的下拉選單選擇一個選集，並按下複製選集來創建您的萬用字源庫。",
  "2. Click on any of the files that appear in the tree to edit them.": "2. 點擊上方選項中出現的文件進行編輯。",
  "3. Use the wildcard in your script by typing the name of the file or copying the text from the Wildcards file text box": "3. 在提示詞中使用萬用字元，輸入檔案名稱或從萬用字元檔案檔案編輯器中複製文字。",
  "Select a collection": "選擇選集",
  "devilkkw": "devilkkw",
  "jumbo": "jumbo",
  "nai": "nai",
  "nsp": "nsp",
  "parrotzone": "parrotzone",
  "Copy collection": "複製選集",
  "Overwrite existing": "覆寫既有",
  "Refresh wildcards": "重新整理萬用字元",
  "Delete all wildcards": "刪除全部萬用字元",
  "Wildcards file": "萬用字元檔案",
  "File editor": "檔案編輯器",
  "Save wildcards": "儲存萬用字元",
  "Ignore whitespace in prompts: All newlines, tabs, and multiple spaces are replaced by a single space": "忽略提示中的空格：所有換行符號、定位點和多個空格都會被替換為一個空格。",
  "Save template to metadata: Write prompt template into the PNG metadata": "將範本保存至元數據：將提示詞範本寫入PNG數據中",
  "Write prompts to file: Create a new .txt file for every batch containing the prompt template as well as the generated prompts.": "將提示寫入文件：為每個批次創建一個新的 .txt 文件，其中包含提示範本和產生的提示詞。",
  "String to use as left bracket for parser variants, .e.g {variant1|variant2|variant3}": "作為解析器變體左括號的字符串，例如 {variant1|variant2|variant3}",
  "String to use as right bracket for parser variants, .e.g {variant1|variant2|variant3}": "作為解析器變體右括號的字符串，例如 {variant1|variant2|variant3}",
  "String to use as wrap for parser wildcard, .e.g __wildcard__": "用作解析萬用字元的字串命令，例如 __wildcard__",
  "Limit Jinja prompts: Limit the number of prompts to batch_count * batch_size. The default is to generate batch_count * barch_size * number of prompts generated by Jinja": "將提示的數量限制為 batch_count * batch_size。預設是產生 batch_count * batch_size * Jinja 產生的提示數量。",
  "sd-dynamic-prompts": "sd-dynamic-prompts",
  "https://github.com/adieyal/sd-dynamic-prompts.git": "https://github.com/adieyal/sd-dynamic-prompts.git",
  "Disable dynamic prompts by unchecking this box.": "取消勾選以停用動態提示詞",
  "Instead of generating random prompts from a template, combinatorial generation produces every possible prompt from the given string.\nThe prompt 'I {love|hate} {New York|Chicago} in {June|July|August}' will produce 12 variants in total.\n\nThe value of the 'Seed' field is only used for the first image. To change this, look for 'Fixed seed' in the 'Advanced options' section.": "使用組合產生而非從範本產生隨機提示，會從給定的字串中產生所有可能的提示。\n例如提示字串'I {love|hate} {New York|Chicago} in {June|July|August}'，會總共產生12種不同的提示。\n\n「Seed」欄位的值僅會用於生成第一張圖片。若要更改此值，請尋找「Advanced options」區塊中的「Fixed seed」選項。",
  "Limit the maximum number of prompts generated. 0 (default) will generate all images. Useful to prevent an unexpected combinatorial explosion.": "限制產生的提示詞數量的上限，預設為0，表示產生所有圖像。這個選項可以防止過多的組合。",
  "Re-run your combinatorial batch this many times with a different seed each time.": "這個選項表示用不同的種子重新運行組合產生的批次數據。在每次運行中，種子值都會改變，這樣可以產生不同的隨機順序或排列組合。",
  "Magic Prompt adds interesting modifiers to your prompt for a little bit of extra spice.\nThe first time you use it, the MagicPrompt model is downloaded so be patient.\nIf you're running low on VRAM, you might get a CUDA error.": "魔法提示詞在提示詞中加入有趣的修飾，額外增添趣味\n首次使用時會下載 MagicPrompt 模型，請耐心等待\n在低顯存情況下可能會導致 CUDA 報錯",
  "Controls the maximum length in tokens of the generated prompt.": "按標記數控制已產生的提示詞最大長度",
  "Adjusts the generated prompt. You will need to experiment with this setting.": "調整已產生的提示詞，使用時要嘗試調整此設定",
  "Regular expression pattern for blocking terms out of the generated prompt. Applied case-insensitively. For instance, to block both \"purple\" and \"interdimensional\", you could use the pattern \"purple|interdimensional\".": "用於排除提示詞語的表達式。忽略大小寫。例如，要封鎖 'purple' 和 'interdimensional'，可以使用 'purple | interdimensional'",
  "The number of prompts to generate per batch. Increasing this can speed up prompt generation at the expense of slightly increased VRAM usage.": "每個批次要產生的提示詞數量。增加此數量可以加快提示詞產生速度，但會略微增加 VRAM 的使用。",
  "Uses the lexica.art API to create random prompts.\nThe prompt in the main prompt box is used as a search string.\nLeaving the prompt box blank returns a list of completely randomly chosen prompts.\nTry it out, it can be quite fun.": "用 lexica.art API 生成隨機提示詞\n提示詞框中的內容會作為搜索字串\n留空提示詞框會得到一組完全隨機選擇的提示詞\n用用看，它會很有趣",
  "Randomly selects a keyword from the prompt and adds emphasis to it. Try this with Fixed Seed enabled.": "隨機強調提示詞中的一個關鍵詞，嘗試前要啟用固定隨機種子",
  "Don't use prompt magic on negative prompts.": "不要對反向提示詞使用提示詞魔法。",
  "Jinja2 templates are an expressive alternative to the standard syntax. See the Help section below for instructions.": "Jinja2 模板是標準語法富有表現力的一種替代品，相關說明參見下方幫助欄",
  "Check this if you want to generate random prompts, even if your seed is fixed": "勾選此選項以在固定隨機種子的情況下依然產生隨機提示詞",
  "Select this if you want to use the same seed for every generated image.\nThis is useful if you want to test prompt variations while using the same seed.\nIf there are no wildcards then all the images will be identical.": "勾選此選項以對每張產生的圖像用同樣的隨機種子。\n這在想用同樣的隨機種子測試提示詞變化時會有用。\n沒有萬用字元則所有圖像會相同。",
  "Write the prompt template into the image metadata": "將提示詞範本寫入圖片數據。",
  "Be sure to check the 'Write prompts to file' checkbox if you don't want to lose the generated prompts. Note, one image is still generated.": "不想失去產生的提示詞的話，需確保勾選 「將提示詞寫入檔案」。注意，依然會生成一張圖像。",
  "The generated file is a slugified version of the prompt and can be found in the same directory as the generated images.\nE.g. in ./outputs/txt2img-images/.": "產生的檔案包含處理過的提示詞，和產生的圖像在同一目錄。\n例如 ./outputs/txt2img-images/",
  "Complete documentation is available at https://github.com/adieyal/sd-dynamic-prompts. Please report any issues on GitHub.": "完整說明請在 https://github.com/adieyal/sd-dynamic-prompts 上取得。 任何問提請在 GitHub 上報告。",
  "Generate all possible prompt combinations.": "產生所有可能的提示詞組合。",
  "Automatically update your prompt with interesting modifiers. (Runs slowly the first time)": "使用有趣的修飾符自動更新你的提示詞。（第一次運行會比較慢）",
  "Generate random prompts from lexica.art (your prompt is used as a search query).": "從 lexica.art 產生隨機提示詞（你的提示詞會被用作搜尋查詢）",
  "Use the same seed for all prompts in this batch": "對這批次中的所有提示詞使用相同的種子",
  "Write all generated prompts to a file": "將所有產生的提示詞寫入檔案",
  "If this is set, then random prompts are generated, even if the seed is the same.": "如果設定了此項，則會產生隨機提示詞，即使種子相同。",
  "Disable image generation. Useful if you only want to generate text prompts. (1 image will still be generated to keep Auto1111 happy.).": "停用圖像產生。這很有用，如果你只想產生文字提示。（仍將生成 1 張圖像以使 Auto1111 保持運行）",
  "Add emphasis to a randomly selected keyword in the prompt.": "在提示詞中隨機選擇一個關鍵字加上強調符",
  "Write template into image metadata.": "將範本寫入圖像中繼資料。",
  "Note: Each model will download between 300mb and 1.4gb of data on first use.": "註記：每個模型第一次使用時會下載 300MB 到 1.4GB 的檔案。"
}